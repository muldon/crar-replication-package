Query: How do I transform a multi-level list into a list of strings in Python?
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/35015732)
 Use https://docs.python.org/3.5/library/stdtypes.html#str.join in a list comprehension (works in both Python 2.x and 3.x): 

  >>> a = [('A', 'V', 'C'), ('A', 'D', 'D')]
>>> [''.join(x) for x in a]
['AVC', 'ADD']
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/35016510)
 You could map  str.join  to each  tuple  in  a : 

 Python 2: 

  >>> map(''.join, a)
['AVC', 'ADD']
  

 In Python 3,  map  is an iterable object so you'd need to materialise it as a  list : 

  >>> list(map(''.join, a))
['AVC', 'ADD']
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/35016193)
 Using  reduce  is another option: 

  >>> a = [('A','V','C'), ('A','D','D')]
  

 In Python 2: 

  >>> [reduce(lambda x, y: x + y , i) for i in a]
['AVC', 'ADD']
  

 In Python 3 (Thanks for eugene's suggestion): 

  >>> from functools import reduce
>>> [reduce(lambda x, y: x + y , i) for i in a]
['AVC', 'ADD']
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/43748353)
 Use  transform  

  df.fillna(df.groupby(level=0).transform('mean'))

         2    3  4    5    6
0  1                        
S1 D1  1.0  2.0  3  4.0  5.0
   D2  2.0  3.0  3  4.0  5.0
   D3  3.0  4.0  5  4.0  6.0
S2 D4  6.0  3.0  4  5.0  6.0
   D5  6.0  7.0  8  9.0  0.0
S3 D6  3.0  4.0  5  6.0  7.0
   D7  4.0  5.0  6  7.0  7.0
   D8  5.0  6.0  7  7.0  8.0
   D9  2.0  3.0  4  5.0  6.0
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/48094374)
 You can use: 

  for i, j in str_cord:
    idx = pd.IndexSlice
    df.loc[idx[:, i], idx[:, j]] = 1
  

  

  L = list('ABCDEFGHIJ')
mux = pd.MultiIndex.from_product([['Cat1','Cat2'], L])

df = pd.DataFrame(0, index=mux, columns=mux)
print (df)
       Cat1                            Cat2                           
          A  B  C  D  E  F  G  H  I  J    A  B  C  D  E  F  G  H  I  J
Cat1 A    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     B    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     C    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     D    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     E    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     F    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     G    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     H    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     I    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     J    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
Cat2 A    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     B    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     C    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     D    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     E    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     F    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     G    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     H    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     I    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     J    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
  

 

  str_cord = [('A','B'),('A','H'),('A','I'),('B','H'),('B','I'),('H','I')]

for i, j in str_cord:
    idx = pd.IndexSlice
    df.loc[idx[:, i], idx[:, j]] = 1
  

 

  print (df)
       Cat1                            Cat2                           
          A  B  C  D  E  F  G  H  I  J    A  B  C  D  E  F  G  H  I  J
Cat1 A    0  1  0  0  0  0  0  1  1  0    0  1  0  0  0  0  0  1  1  0
     B    0  0  0  0  0  0  0  1  1  0    0  0  0  0  0  0  0  1  1  0
     C    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     D    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     E    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     F    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     G    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     H    0  0  0  0  0  0  0  0  1  0    0  0  0  0  0  0  0  0  1  0
     I    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     J    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
Cat2 A    0  1  0  0  0  0  0  1  1  0    0  1  0  0  0  0  0  1  1  0
     B    0  0  0  0  0  0  0  1  1  0    0  0  0  0  0  0  0  1  1  0
     C    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     D    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     E    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     F    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     G    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     H    0  0  0  0  0  0  0  0  1  0    0  0  0  0  0  0  0  0  1  0
     I    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
     J    0  0  0  0  0  0  0  0  0  0    0  0  0  0  0  0  0  0  0  0
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/48785860)
 If for first level are same combinations of another levels like in sample is possible use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reindex.html to  MultiIndex  in columns with http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.div.html: 

  #same as Maarten Fabr√© answer
np.random.seed(42)

from  itertools import combinations

#get combination of second level values
c = pd.MultiIndex.from_tuples(list(combinations(df.index.levels[1], 2)))

#reshape to unique columns of second level
print (df['idx'].unstack(1))
lvl_2                    a         b         c         d
lvl_1 lvl_3                                             
first 2018-02-12  0.731994  0.601115  0.155995  0.969910
      2018-02-13  0.950714  0.866176  0.156019  0.020584
      2018-02-14  0.374540  0.058084  0.598658  0.708073

#reindex by both levels
df1 = df['idx'].unstack(1).reindex(columns=c, level=0)
print (df1)
                         a                             b                   c
                         b         c         d         c         d         d
lvl_1 lvl_3                                                                 
first 2018-02-12  0.731994  0.731994  0.731994  0.601115  0.601115  0.155995
      2018-02-13  0.950714  0.950714  0.950714  0.866176  0.866176  0.156019
      2018-02-14  0.374540  0.374540  0.374540  0.058084  0.058084  0.598658


df2 = df['idx'].unstack(1).reindex(columns=c, level=1)
print (df2)
                         a                             b                   c
                         b         c         d         c         d         d
lvl_1 lvl_3                                                                 
first 2018-02-12  0.601115  0.155995  0.969910  0.155995  0.969910  0.969910
      2018-02-13  0.866176  0.156019  0.020584  0.156019  0.020584  0.020584
      2018-02-14  0.058084  0.598658  0.708073  0.598658  0.708073  0.708073
  

 

  #divide with flatten MultiIndex    
df3 = df1.div(df2)
df3.columns = df3.columns.map('/'.join)
#reshape back and change order of levels, sorting indices
df3 = df3.stack().reorder_levels([0,2,1]).sort_index()
  

 

  print (df3)
lvl_1       lvl_3     
first  a/b  2018-02-12     1.217727
            2018-02-13     1.097599
            2018-02-14     6.448292
       a/c  2018-02-12     4.692434
            2018-02-13     6.093594
            2018-02-14     0.625632
       a/d  2018-02-12     0.754703
            2018-02-13    46.185944
            2018-02-14     0.528957
       b/c  2018-02-12     3.853437
            2018-02-13     5.551748
            2018-02-14     0.097023
       b/d  2018-02-12     0.619764
            2018-02-13    42.079059
            2018-02-14     0.082031
       c/d  2018-02-12     0.160834
            2018-02-13     7.579425
            2018-02-14     0.845476
dtype: float64
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/48294937)
  

  #filter only one and two values by second level
df = df.loc[pd.IndexSlice[:, ['one','two']], :]
#filter by length
df = df[df.groupby(level=0)[df.columns[0]].transform('size') == 2]
print (df)
                0         1         2         3
key nm                                         
bar one -0.424972  0.567020  0.276232 -1.087401
    two -0.673690  0.113648 -1.478427  0.524988
baz one  0.404705  0.577046 -1.715002 -1.039268
    two -0.370647 -1.157892 -1.344312  0.844885
qux one -1.294524  0.413738  0.276662 -0.472035
    two -0.013960 -0.362543 -0.006154 -0.923061
  

 Another solution is compare sets: 

  mask = df.reset_index()
         .groupby('key')['nm']
         .transform(lambda x: set(x) == set(['one','two']))
         .values 
df = df[mask]
print (df)
                0         1         2         3
key nm                                         
bar one -0.424972  0.567020  0.276232 -1.087401
    two -0.673690  0.113648 -1.478427  0.524988
baz one  0.404705  0.577046 -1.715002 -1.039268
    two -0.370647 -1.157892 -1.344312  0.844885
qux one -1.294524  0.413738  0.276662 -0.472035
    two -0.013960 -0.362543 -0.006154 -0.923061
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/49862550)
 You can use  groupby.transform  for a vectorised solution: 

  res = data[data.groupby(data.index.get_level_values(0))['Count'].transform('min') > 10]

print(res)

#             0  Count
# B M  0.143501     15
#   F  0.964689     17
# D M  0.092362     11
#   F  0.981470     20
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/49223840)
 Maybe apply  list   

  pd.get_dummies(s.apply(list).apply(pd.Series).stack()).sum(level=0)
Out[222]: 
   1  3  5  8  a  b  e  i  j  n  s  u  w  z
0  1  0  0  0  1  0  0  0  0  0  0  0  0  1
1  0  0  1  1  0  1  0  0  0  0  0  0  1  0
2  0  0  0  0  0  0  0  1  1  0  1  1  0  0
3  0  1  0  0  0  0  1  0  0  1  0  0  0  0
  

   

  s.apply(list).str.join(',').str.get_dummies(',')
Out[224]: 
   1  3  5  8  a  b  e  i  j  n  s  u  w  z
0  1  0  0  0  1  0  0  0  0  0  0  0  0  1
1  0  0  1  1  0  1  0  0  0  0  0  0  1  0
2  0  0  0  0  0  0  0  1  1  0  1  1  0  0
3  0  1  0  0  0  0  1  0  0  1  0  0  0  0
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/46141950)
 Based on the answer to https://stackoverflow.com/q/46134827/512652, we can use a MultiIndex. First, create the MultiIndex and a flattened DataFrame. 

  A = np.random.randint(0, 1000, (5, 4, 3))

names = ['x', 'y', 'z']
index = pd.MultiIndex.from_product([range(s)for s in A.shape], names=names)
df = pd.DataFrame({'A': A.flatten()}, index=index)['A']
  

  

  df = df.unstack(level='x').swaplevel().sort_index()
df.columns = ['A', 'B', 'C']
df.index.names = ['DATE', 'i']
  

 This is the result: 

            A    B    C
DATE i           
0    0  715  226  632
     1  895  837  431
     2  520  692  230
     3  286  358  462
     4   44  119  757
1    0  305   97  534
     1  649  717   39
     2  452  816  887
     3  831   26  332
     4  908  937  728
2    0   88  592  902
     1  363  121  274
     2  688  509  770
     3  424  178  642
     4  809   28  442
3    0  172  932  263
     1  334  359  816
     2  290  856  584
     3  955   42  938
     4  832  220  348
  



