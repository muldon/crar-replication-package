Query: Parsing HTML
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/35488639)
 It's because  lxml  is having trouble parsing invalid  HTML . 

 Use  html.parser  instead of  lxml . 

  #!/usr/bin/env python
# -*- coding: utf-8 -*-

from bs4 import BeautifulSoup

html = ' </td></tr><tr><td colspan="3">   Data I want  </td></tr><tr>  <td colspan="3">   Data I want  </td> </tr> <tr><td colspan="3">   Data I want  </td> </tr></table>'
soup = BeautifulSoup(html, 'html.parser')

print soup.getText()
  

 Output: 

   Data I want      Data I want       Data I want   
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/5406716)
 htql is good at handling malformed html:  

 http://htql.net/ 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/5120162)
 You can use http://www.crummy.com/software/BeautifulSoup/ to parse HTML in Python. 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/12765708)
 Use an HTML parsing library to parse the HTML. Two popular, good ones are http://www.crummy.com/software/BeautifulSoup/ and http://lxml.de/. 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/904655)
 http://www.crummy.com/software/BeautifulSoup/ does a good job with invalid/broken HTML 

  >>> from BeautifulSoup import BeautifulSoup
>>> soup = BeautifulSoup("<htm@)($*><body><table <tr><td>hi</tr></td></body><html")
>>> print soup.prettify()
<htm>
 <body>
  <table>
   <tr>
    <td>
     hi
    </td>
   </tr>
  </table>
 </body>
</htm>
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/7655171)
 For parsing HTML I would suggest you take a look at Beautiful Soup. It's pretty powerful and can deal with some messed up markup as well. 

<p 

 Check this out and see if it helps you out! . 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/5957573)
 Consider PyQuery: 

<p 

  >>> from pyquery import PyQuery as pq
>>> from lxml import etree
>>> import urllib
>>> d = pq("<html></html>")
>>> d = pq(etree.fromstring("<html></html>"))
>>> d = pq(url='http://google.com/')
>>> d = pq(url='http://google.com/', opener=lambda url: urllib.urlopen(url).read())
>>> d = pq(filename=path_to_html_file)
>>> d("#hello")
[<p#hello.hello>]
>>> p = d("#hello")
>>> p.html()
'Hello world !'
>>> p.html("you know <a href='http://python.org/'  rocks")
[<p#hello.hello>]
>>> p.html()
u'you know http://python.org/ rocks'
>>> p.text()
'you know Python rocks'
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/12765707)
 http://www.crummy.com/software/BeautifulSoup/ is the best HTML parsing library I've used, take a look at it. 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/3051310)
 The http://lxml.de/ library supports http://lxml.de/cssselect.html. 


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/7655195)
 I've been using lxml ( http://lxml.de/lxmlhtml.html ).  It relatively fast for normal sized html documents and has support for using BeautifulSoup.  As I understand it, BeautifulSoup is no longer supported so for all new projects I've used lxml. 



