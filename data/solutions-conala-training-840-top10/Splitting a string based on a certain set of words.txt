Query: Splitting a string based on a certain set of words
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/34410495)
  >>> [re.split(r"_(?:f?or|and)_", s) for s in l]
[['happy_feet'],
 ['happy_hats', 'cats'],
 ['sad_fox', 'mad_banana'],
 ['sad_pandas', 'happy_cats', 'people']]
  

 To combine them into a single list, you can use 

  result = []
for s in l:
    result.extend(re.split(r"_(?:f?or|and)_", s))
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/34410532)
  >>> pat = re.compile("_(?:%s)_"%"|".join(sorted(split_list,key=len)))
>>> list(itertools.chain(pat.split(line) for line in data))
  

 will give you the desired output for the example dataset provided 

 actually with the  _  delimiters you dont really need to sort it by length so you could just do  

  >>> pat = re.compile("_(?:%s)_"%"|".join(split_list))
>>> list(itertools.chain(pat.split(line) for line in data))
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/34422519)
 Another way of doing this, using only built-in method, is to replace all occurrence of what's in  ['for', 'or', 'and']  in every string with a replacement string, say for example  _1_  (it could be any string), then at then end of each iteration, to split over this replacement string: 

  l = ['happy_feet', 'happy_hats_for_cats', 'sad_fox_or_mad_banana','sad_pandas_and_happy_cats_for_people'] 
replacement_s = '_1_'
lookup = ['for', 'or', 'and']
lookup = [x.join('_'*2) for x in lookup] #Changing to: ['_for_', '_or_', '_and_']
results = []
for i,item in enumerate(l):
    for s in lookup:
        if s in item:
            l[i] = l[i].replace(s,'_1_')
    results.extend(l[i].split('_1_'))
  

  OUTPUT:  

  ['happy_feet', 'happy_hats', 'cats', 'sad_fox', 'mad_banana', 'sad_pandas', 'happy_cats', 'people']
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/34410585)
 You could use a regular expression: 

  from itertools import chain
import re

pattern = re.compile(r'_(?:{})_'.format('|'.join([re.escape(w) for w in keywords])))

result = list(chain.from_iterable(pattern.split(w) for w in input_list))
  

 The pattern is dynamically created from your list of keywords. The string  'happy_hats_for_cats'  is split on  '_for_' : 

  >>> re.split(r'_for_', 'happy_hats_for_cats')
['happy_hats', 'cats']
  

 but because we actually produced a set of alternatives (using the  |  metacharacter) you get to split on any of the keywords: 

  >>> re.split(r'_(?:for|or|and)_', 'sad_pandas_and_happy_cats_for_people')
['sad_pandas', 'happy_cats', 'people']
  

 Each split result gives you a list of strings (just one if there was nothing to split on); using https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable lets us treat all those lists as one long iterable. 

  

  >>> from itertools import chain
>>> import re
>>> keywords = ['for', 'or', 'and']
>>> input_list = ['happy_feet', 'happy_hats_for_cats', 'sad_fox_or_mad_banana','sad_pandas_and_happy_cats_for_people']
>>> pattern = re.compile(r'_(?:{})_'.format('|'.join([re.escape(w) for w in keywords])))    
>>> list(chain.from_iterable(pattern.split(w) for w in input_list))
['happy_feet', 'happy_hats', 'cats', 'sad_fox', 'mad_banana', 'sad_pandas', 'happy_cats', 'people']
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/37453059)
  Python Code  

 You can use  re.split  with  strip  like ( assuming there can be spaces in middle of word ) 

  >>> item_list = [('apple OR ora nge AND NOT pineapple'), ('(sugar and salt) or (pepper and vinegar)')]
>>> [[x.strip() for x in re.split(r'(?i)(?:\b(?:AND|OR|NOT)\b|[]\[()])', x) if x.strip()] for x in item_list]
[['apple', 'ora nge', 'pineapple'], ['sugar', 'salt', 'pepper', 'vinegar']]
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/37453681)
 Here's another take using list comprehensions: 

  item_list = [('apple OR orange AND NOT pineapple'), ('(sugar and salt) or (pepper and vinegar)')]
delimeters = ['OR','AND','NOT','and','or','not']
[[i.replace('(','').replace(')','') for i in x.split() if i not in delimeters] for x in item_list]
  

  

  [['apple', 'orange', 'pineapple'], ['sugar', 'salt', 'pepper', 'vinegar']]
  

 And pretty simple to follow IMO 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/31410912)
 If you're splitting the text file into words based on whitespace, just use  split()  on the whole thing. There's nothing to be gained by reading each line and stripping it, because  split()  already handles all that. 

 So to get the initial list of words, all you need is this: 

  filename = raw_input("Enter file name: ")
openedfile = open(filename)
wordlist = openedfile.read().split()
  

 Then to remove duplicates, convert the word list to a set: 

  wordset = set(wordlist)
  

  

  words = sorted(wordset)
  

 This can all be simplified to three lines, like so: 

  filename = raw_input("Enter file name: ")
with open(filename) as stream:
    words = sorted(set(stream.read().split()))
  

 (NB: the  with  statement will automatically close the file for you) 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/53877665)
 You could do https://docs.python.org/3/library/re.html#re.split with a  positive lookahead : 

  In [3]: re.split(r", (?=[a-zA-Z])", s)
Out[3]: ["[word in IN ('hello', 'world')", 'key1=1100', 'key2=1200]']
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/35695347)
 If the words are from  completely  different script within  Unicode  like  CJK  characters or Greek, Cyrillic, Thai, you could use  unicodedata.category  to see if they're letters to begin with (category starts with  L ): 

  >>> import unicodedata
>>> unicodedata.category('a')
'Ll'
>>> unicodedata.category('E')
'Lu'
>>> unicodedata.category('中')
'Lo'
>>> [unicodedata.category(i).startswith('L') for i in 'aE中,']
[True, True, True, False]
  

 Then you can use the  unicodedata.name  to see that they're Latin letters: 

  >>> 'LATIN' in unicodedata.name('a')
True
>>> 'LATIN' in unicodedata.false('中')
False
  

 Presumably it is not an English-language word if it has non-Latin letters in it. 

 

 Otherwise, you could use a letter bigram/trigram classifier to find out if there is a high probability these are English words. For example  OnKxnXecCINJ  contains  Kxn  which is a trigram that neither very probably exist in any single English language word, nor any concatenation of 2 words. 

 You can build one yourself from the corpus by splitting words into character trigrams, or you can use any of the existing libraries like https://pypi.python.org/pypi/langdetect or https://pypi.python.org/pypi/langid or so. 

 Also, see that the corpus is a  set  for fast  in  operations; only after the algorithm tells that there is a high probability it is in English, and the word fails to be found in the  set , consider that it is alike to  infonewsletter  - a concatenation of several words; split it recursively into smaller chunks and see that each part thereof is found in the corpus. 



