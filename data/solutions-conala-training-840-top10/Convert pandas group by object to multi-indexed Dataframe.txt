Query: Convert pandas group by object to multi-indexed Dataframe
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/14306921)
 Since you're not aggregating similarly indexed rows, try setting the index with a list of column names. 

  In [2]: df.set_index(['Name', 'Destination'])
Out[2]: 
                   Length
Name  Destination        
Bob   Athens            3
      Rome              5
      Athens            2
Alice Rome              1
      Athens            3
      Rome              5
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/53832386)
 Use: 

  # Converting ser to a dataframe 
ndf = pd.DataFrame(ser).reset_index()

# Fetching B values against which C values needs to be mapped to NaN
idx = ndf[ndf.iloc[:,2] == True].B.values

# Fetching df index where C values needs to be mapped to NaN
idx_ = df[df.B.isin(idx)].index

# Mapping of C values to NaN
df.loc[idx_,'C'] = np.NaN


+---+------+---+-----+-----+
|   |   A  | B |  C  |  D  |
+---+------+---+-----+-----+
| 0 |  188 | 1 | 2.0 | foo |
| 1 |  750 | 2 | 5.0 | foo |
| 2 | 1330 | 4 | 7.0 | foo |
| 3 | 1385 | 5 | NaN | foo |
| 4 |  188 | 1 | 5.0 | bar |
| 5 |  750 | 2 | 5.0 | bar |
| 6 |  810 | 3 | NaN | bar |
| 7 | 1330 | 4 | 7.0 | bar |
| 8 | 1385 | 5 | NaN | bar |
+---+------+---+-----+-----+
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/40236466)
 You need http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html: 

  data = data.set_index(['name','take'])
print (data)
            ping     score
name  take                
sasha one     46  0.509177
      two     77  0.828984
asa   one     51  0.637451
      two     51  0.658616
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/53832732)
 Use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.isin.html for check membership between both  MultiIndex : 

  #convert columns to strings for same types of levels
df[['A','B']] = df[['A','B']].astype(str)
df.loc[df.set_index(['A','B']).index.isin(ser.index[ser]), 'C'] = np.nan
print (df)
      A  B    C    D
0   188  1  2.0  foo
1   750  2  5.0  foo
2  1330  4  7.0  foo
3  1385  5  NaN  foo
4   188  1  5.0  bar
5   750  2  5.0  bar
6   810  3  NaN  bar
7  1330  4  7.0  bar
8  1385  5  NaN  bar
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/41054193)
 I think you can use  nlevels  for find  length  of  levels  in  MultiIndex , then create  range  with  stack : 

  print (d.columns.nlevels)
2

#for python 3 add `list`
print (list(range(d.columns.nlevels)))
[0, 1]

print (d.stack(list(range(d.columns.nlevels))))
   a  b
a  0  0    0
      1    0
   1  0    0
      1    0
b  0  0    1
      1    2
   1  0    3
      1    4
c  0  0    2
      1    4
   1  0    6
      1    8
dtype: int64
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/51333889)
 You can always add suffix to your column name and reset index after converting to dataframe.  

 Let's say I have pandas.series.Series object "s" 

  >> s = train.groupby('column_name').item_id.value_counts()
>> type(s)
pandas.core.series.Series
>> y = x.to_frame()
>> data = y.add_suffix('_Count').reset_index()
>> data.head() #It will be pandas dataframe with column updates with suffix "_Count"
  

 I converted multi index series object to single level indexed dataframe. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/38728733)
 Adding a comma after your  ('c','b')  tuple seems to work:  

  df.groupby([('c','a')])[('c','b'),].sum()
  

 I'm guessing that without the comma, pandas is just interpreting them as separate items. 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/46187186)
 Simply use https://pandas.pydata.org/pandas-docs/stable/groupby.html#transformation for inline aggregation or any group-specific computations that returns a like-indexed object: 

  merge['pet_age_group_mean'] = merge.groupby('user_id')['pet_age'].transform('mean')
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/32453517)
 Your  d  is no longer a  groupby  object it is a multi-indexed df which is why you get the error: 

  In [61]:
for col in d:
    print(col)

City
H
subindex
  

 this is what  d  is now: 

  Out[52]:
       City    H  subindex
City                      
AMS  0  AMS  1.1         1
     2  AMS  0.9         2
     1  AMS  0.8         3
BOS  3  BOS  0.9         1
     6  BOS  0.8         2
     4  BOS  0.7         3
     5  BOS  0.6         4
  

 If you had not called  apply  on the  groupby  object then you could access the  groups : 

  In [69]:
g = df.groupby('City')
g.groups

Out[69]:
{'AMS': [0, 1, 2], 'BOS': [3, 4, 5, 6]}
  

 You could've iterated over the  groupby  object correctly as before: 

  In [71]:
for i, group in g:
    print(i)
    print(group)

AMS
  City    H
0  AMS  1.1
1  AMS  0.8
2  AMS  0.9
BOS
  City    H
3  BOS  0.9
4  BOS  0.7
5  BOS  0.6
6  BOS  0.8
  

 As such what you want to do now is to use the index levels to filter your df and plot them: 

  for city in d.index.get_level_values(0).unique():
    d[d['City']==city].plot(x='subindex', y='H')
  

 yields following plots: 

 https://i.stack.imgur.com/scgPU.png 

 and 

 <a href="https://i.stack.imgur.com/Bud9e.png"  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/38599152)
 Use  groupby(level=0)  then  bfill  and  update : 

  df.update(df.groupby(level=0).bfill())
df
  

 Note:  update  changes  df  inplace. 

 https://i.stack.imgur.com/XQU4B.png 

 Other alternatives</h3>

  df = df.groupby(level='group').bfill()

df = df.unstack(0).bfill().stack().swaplevel(0, 1).reindex_like(df)
  

 Column specific</h3>

  df.Value = df.groupby(level=0).Value.bfill()
  



