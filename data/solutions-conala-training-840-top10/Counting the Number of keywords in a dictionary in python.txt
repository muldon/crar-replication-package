Query: Counting the Number of keywords in a dictionary in python
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/2212442)
  len(yourdict.keys())
  

  

  len(yourdict)
  

 If you like to count unique words in the file, you could just use http://docs.python.org/library/sets.html#module-sets and do like 

  len(set(open(yourdictfile).read().split()))
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/48452582)
 If the question is about counting the number of keywords then would recommend something like 

  def countoccurrences(store, value):
    try:
        store[value] = store[value] + 1
    except KeyError as e:
        store[value] = 1
    return
  

 in the main function have something that loops through the data and pass the values to countoccurrences function 

  if __name__ == "__main__":
    store = {}
    list = ('a', 'a', 'b', 'c', 'c')
    for data in list:
        countoccurrences(store, data)
    for k, v in store.iteritems():
        print "Key " + k + " has occurred "  + str(v) + " times"
  

 The code outputs  

  Key a has occurred 2 times
Key c has occurred 2 times
Key b has occurred 1 times
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/2212437)
 The number of distinct words (i.e. count of entries in the dictionary) can be found using the  len()  function. 

  > a = {'foo':42, 'bar':69}
> len(a)
2
  

 To get all the distinct words (i.e. the keys), use the  .keys()  method. 

  > list(a.keys())
['foo', 'bar']
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/54848797)
  keywords  is a list,  STR.count()  accepts a string. If  keywords  is a list of strings, you could insert another for loop 

  for keyword in keywords:
    # count
  

 otherwise, if you don't know what it contains, flatten the list and then iterate over all the items, wrapping the  .count()  in a try-except block 

  for keywords in flattened_KEYWORDS:
    try:
         # count
    except: pass
  

 Do note that you could simplify your overall logic to something like 

  sum(STR.count(keyword) for keyword in KEYWORDS)
  

 -after fixing the  list  to  str  issues. 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/52135729)
 You can use  ast.parse  to parse the code, create a  ast.NodeTransformer  subclass to clear all the string nodes (no need to clear comments because comments are automatically ignored by  ast.parse  already), install the https://github.com/simonpercivall/astunparse to turn the node back to source code, and then count the keywords: 

  import ast
import astunparse
import keyword
import re

class clear_strings(ast.NodeTransformer):
    def visit_Str(self, node):
        node.s = ''
        return node

n = ast.parse('''
a = 'True'
assert False
# [[] for _ in range(9)]
"""if"""
''')

clear_strings().visit(n)
print(sum(map(keyword.iskeyword, re.findall(r'\w+', astunparse.unparse(n)))))
  

 This outputs:  2  (because only  assert  and  False  are counted as keywords) 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/25837249)
 You get the error 

  TypeError: Can't convert 'list' object to str implicitly
  

 because with  line.find(keywords)  you're passing a list ( keywords ) to  find()  which expects a string. 

 You need to search for each keyword individually instead using a loop: 

  def index(filepath, keywords):
    with open(filepath) as f:
        for lineno, line in enumerate(f, start=1):
            matches = [k for k in keywords if k in line]
            if matches:
                result = "{:<15} {}".format(','.join(matches), lineno)
                print(result)


index('file.txt', ['network', 'device', 'local'])
  

 Here I also used https://docs.python.org/2/library/functions.html#enumerate to simplify line counting and https://docs.python.org/2/library/stdtypes.html#str.format to make the output https://stackoverflow.com/questions/12684368/how-to-left-align-a-fixed-width-string like in your example. The expression  matches = [k for k in keywords if k in line]  is a https://docs.python.org/2/tutorial/datastructures.html#list-comprehensions that builds a list of all the keywords that are a substring of  line . 

 Example output: 

  network,device  1
network         2
device          3
local           4
device,local    5
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/33716101)
 To mapping multiple line number from words, you need to mapping to  list , instead of  int : 

  def index(filename, word_lst):

    dic = {}
    line_count = 0

    for word in word_lst:
        dic[word] = []   # <---

    with open(filename) as infile:
        for line in infile:
            line_count += 1
            for word in word_lst:
                if word in line:
                    dic[word].append(line_count)  # <----

    print(dic)
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/35679185)
 Assuming your file is named 'data.txt' 

  from collections import defaultdict

def get_data():
    d = defaultdict(list)
    with open('data.txt') as f:
        key = None
        for line in f:
            if line.startswith('*'):
                key = line.rstrip()
                continue
            d[key].append(line.rstrip())
    return d
  

 The returned defaultdict looks like this: 

  defaultdict(list,
            {'*EDGES': ['1 1 2', '2 1 4', '3 2 3', '4 3 4'],
             '*VERTICES': ['1 0 0 0', '2 10 0 0', '3 10 10 0', '4 0 10 0']})
  

 You access the data just like a normal dictionary 

  d['*EDGES']
['1 1 2', '2 1 4', '3 2 3', '4 3 4']
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/35679141)
 The fact that they are unordered I think lends itself well for parsing into a dictionary from which you can access values later. I wrote a function that you may find useful for this task: 

  features = ['POINTS','EDGES']

def parseFile(dictionary, f, features):
    """
    Creates a format where you can access a shape feature like:
        dictionary[shapeID][feature] = [  [1 1 1], [1,1,1] ... ]

    Assumes: all features although out of order occurs in the order
        shape1
            *feature1
                .
                .
                .
            *featuren
    Assumes all possible features are in in the list features

    f is input file handle
    """
    shapeID = 0
    found = []
    for line in f:

        if line[0] == '*' and found != features:
            found.append(line[1:]) #appends feature like POINTS to found
            feature = line[1:]

        elif line[0] == '*' and found == features:
            found = []
            shapeID += 1
            feature = line[1:] #current feature

        else:
            dictionary[shapeID][feature].append(
                [int(i) for i in line.split(' ')]
                )

    return dictionary

#to access the shape features you can get vertices like:

for vertice in dictionary[shapeID]['POINTS']:
    print vertice

#to access edges

for edge in dictionary[shapeID]['EDGES']:
    print edge
  



