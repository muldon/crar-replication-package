Query: Get data from the meta tags using BeautifulSoup
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/41788736)
 I think here use regexp should be better:
example: 

  resp = requests.get('url')
soup = BeautifulSoup(resp.text)
desc = soup.find_all(attrs={"name": re.compile(r'Description', re.I)})
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/33645942)
 Try (based on http://blog.davidziegler.net/post/122176962/a-python-script-to-automatically-extract-excerpts blog post) 

  from bs4 import BeautifulSoup
...
desc = ""
for meta in soup.findAll("meta"):
    metaname = meta.get('name', '').lower()
    metaprop = meta.get('property', '').lower()
    if 'description' == metaname or metaprop.find("description")>0:
        desc = meta['content'].strip()
  

 Tested against the following variants: 

 
  <meta name="description" content="blah blah" />  (http://www.ouc.com/) 
  <meta id="MetaDescription" name="DESCRIPTION" content="blah blah" />  (<a href="http://www.firstorlando.com/" ) 
  <meta property="og:description" content="blah blah" />  (<a href="http://zevross.com/blog/2014/05/16/using-the-python-library-beautifulsoup-to-extract-data-from-a-webpage-applied-to-world-cup-rankings/" ) 
 

 Used BeautifulSoup version  4.4.1  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/27716495)
 You can use http://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all to get all the  meta  tags with  itemprop="datePublished" : 

  import urllib2
from bs4 import BeautifulSoup

url = 'http://www.homedepot.com/p/Husky-41-in-16-Drawer-Tool-Chest-and-Cabinet-Set-HOTC4016B1QES/205080371'
soup = BeautifulSoup(urllib2.urlopen(url=url))

print [meta.get('content') for meta in soup.find_all('meta', itemprop='datePublished')]
  

  

  [
    '2014-11-27', 
    '2014-11-20', 
    '2014-12-15', 
    '2014-10-28', 
    '2014-10-10'
]
  

 Or, with a http://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors: 

  print [meta.get('content') for meta in soup.select('meta[itemprop="datePublished"]')]
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/23007810)
 Using  BeautifulSoup  get 'anchor' tag  href=  

          import urllib
        from BeautifulSoup import *
        url = raw_input('Enter - ')
        html = urllib.urlopen(url).read()
        soup = BeautifulSoup(html)
        tags = soup('a')
        for tag in tags:
           print tag.get('href', None)
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/29780523)
 Use https://www.python.org/dev/peps/pep-0274/ and https://docs.python.org/2/library/collections.html#collections.Counter to get counts of  tags  that are instance of  bs4.element.Tag . 

  from collections import Counter
import requests
import bs4
from bs4 import BeautifulSoup
url = "http://www.amazon.in"
r = requests.get(url)
html = BeautifulSoup(r.content)
Counter(tag.name for tag in html.descendants if isinstance(tag, bs4.element.Tag))
  

  output  

  Counter({'div': 462, 'a': 448, 'span': 395, 'li': 288, 'br': 78, 'img': 60, 'td': 57, 'script': 48, 'ul': 39, 'option': 27, 'tr': 22, 'table': 17, 'meta': 13, 'map': 12, 'area': 12, 'link': 11, 'style': 10, 'p': 10, 'b': 9, 'h2': 7, 'strong': 5, 'input': 2, 'body': 1, 'title': 1, 'html': 1, 'header': 1, 'form': 1, 'head': 1, 'label': 1, 'select': 1})
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/43295670)
 You can try something like this: 

  from bs4 import BeautifulSoup as bs

data = '<div class="post contentTemplate" itemprop="text">Data to extract<div class="clear"></div></div>'
soup = bs(data)
m = soup.findAll("div", {"class": "post contentTemplate"})
for k in m:
    print(k.get_text())
  

 Output: 

  Data to extract
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/40509775)
 https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser would handle the problem properly: 

  In [1]: from bs4 import BeautifulSoup
   ...: 
   ...: data = """
   ...: <html>
   ...:     <head>
   ...:         <meta name="description" content="content">
   ...:         <script>
   ...:             var i = 0;
   ...:         </script>
   ...:     </head>
   ...:     <body>
   ...:         <div id="content">content</div>
   ...:     </body>
   ...: </html>"""
   ...: 

In [2]: BeautifulSoup(data, 'html.parser').find(attrs={'name': 'description'})
Out[2]: <meta content="content" name="description">\n<script>\n            var i = 0;\n        </script>\n</meta>

In [3]: BeautifulSoup(data, 'html5lib').find(attrs={'name': 'description'})
Out[3]: <meta content="content" name="description"/>

In [4]: BeautifulSoup(data, 'lxml').find(attrs={'name': 'description'})
Out[4]: <meta content="content" name="description"/>
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/42348899)
 Using https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions: 

  >>> html = '''
... <meta property="og:video:tag" content="Official">
... <meta property="og:video:tag" content="Trailer"> 
... <meta property="og:video:tag" content="Movie">
... <meta property="og:video:tag" content="Clip">
... '''
>>> 
>>> from bs4 import BeautifulSoup
>>> soup = BeautifulSoup(html, 'lxml')
>>> [tag['content'] for tag in soup.findAll("meta", {"property":"og:video:tag"})]
['Official', 'Trailer', 'Movie', 'Clip']
# maps Tag elements to their content attributes
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/29241768)
 Description is Case-Sensitive.So, we need to look for both 'Description' and 'description'. 

 Case1: 'Description' in http://view-source:http://www.flipkart.com/ 

 Case2: 'description' in http://view-source:http://www.snapdeal.com/ 

  from bs4 import BeautifulSoup
import requests

url= 'https://www.flipkart.com'
page3= requests.get(url)
soup3= BeautifulSoup(page3.text)
desc= soup3.find(attrs={'name':'Description'})
if desc == None:
    desc= soup3.find(attrs={'name':'description'})
try:
    print desc['content']
except Exception as e:
    print '%s (%s)' % (e.message, type(e))
  



