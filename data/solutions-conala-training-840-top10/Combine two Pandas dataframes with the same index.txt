Query: Combine two Pandas dataframes with the same index
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/15990537)
 This is a doc example: http://pandas.pydata.org/pandas-docs/stable/merging.html#more-concatenating-with-group-keys 

  In [9]: df1 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))

In [10]: df2 = pd.DataFrame(np.random.randn(3,2),columns=list('AB'),index=pd.date_range('20000101',periods=3))

In [11]: df1
Out[11]: 
                   A         B
2000-01-01  0.129994  1.189608
2000-01-02 -1.126812  1.087617
2000-01-03 -0.930070  0.253098

In [12]: df2
Out[12]: 
                   A         B
2000-01-01  0.535700 -0.769533
2000-01-02 -1.698531 -0.456667
2000-01-03  0.451622 -1.500175

In [13]: pd.concat(dict(df1 = df1, df2 = df2),axis=1)
Out[13]: 
                 df1                 df2          
                   A         B         A         B
2000-01-01  0.129994  1.189608  0.535700 -0.769533
2000-01-02 -1.126812  1.087617 -1.698531 -0.456667
2000-01-03 -0.930070  0.253098  0.451622 -1.500175
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/51025004)
 Here are three possibilities: 

 
  Use  concat/groupby : First concatenate both DataFrames vertically. Then group by the index and select the first row in each group.  
  Use  combine_first : Make a new index which is the union of  df1  and  df2 . Reindex  df1  using the new index. Then use  combine_first  to fill in NaNs with values from  df2 .  
  Use manual construction: We could use  df2.index.difference(df1.index)  to find exactly which rows need to be added to  df1 . So we could manually select those rows from  df2  and concatenate them on to  df1 .  
 

 For small DataFrames,  using_concat  is faster. For larger DataFrames,  using_combine_first  appears to be slightly faster than the other options: 

  import numpy as np
import pandas as pd
import perfplot

def make_dfs(N):
    df1 = pd.DataFrame(np.random.randint(10, size=(N,2)))
    df2 = pd.DataFrame(np.random.randint(10, size=(N,2)), index=range(N//2,N//2 + N))
    return df1, df2

def using_concat(dfs):
    df1, df2 = dfs
    result = pd.concat([df1,df2], sort=False)
    n = result.index.nlevels
    return result.groupby(level=range(n)).first()

def using_combine_first(dfs):
    df1, df2 = dfs
    index = df1.index.union(df2.index)
    result = df1.reindex(index)
    result = result.combine_first(df2)
    return result

def using_manual_construction(dfs):
    df1, df2 = dfs
    index = df2.index.difference(df1.index)
    cols = df2.columns.difference(df1.columns)
    result = pd.concat([df1, df2.loc[index]], sort=False)
    result.loc[df2.index, cols] = df2
    return result

perfplot.show(
    setup=make_dfs,
    kernels=[using_concat, using_combine_first, 
             using_manual_construction],
    n_range=[2**k for k in range(5,21)],
    logx=True,
    logy=True,
    xlabel='len(df)')
  

 https://i.stack.imgur.com/B531w.png 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/49919394)
 . To maintain index, you will need use  reset_index  before and  set_index  after the marge. 

  res = df2.reset_index()\
         .merge(df1, how='left')\
         .set_index('index')\
         .loc[:, ['a', 'b', 'c', 'd']]

print(res)

#        a   b         c    d
# index                      
# A      1  21  1.135899  5.5
# A      1  21  1.135899  3.3
# A      1  21  1.135899  2.1
# B      2  22  1.093204  0.8
# B      2  22  1.093204  0.5
# C      3  23  2.035373  1.3
# C      3  23  2.035373  6.5
# C      3  23  2.035373  7.1
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/46755362)
 You could use  merge  with  index  as well. 

  In [2313]: df1.merge(df2, left_on='accountname', right_index=True).reset_index()
Out[2313]:
            ip accountname      name  gsm
0  192.168.1.1        aaaa  john doe  850
1  192.168.1.2        bbbb  jane doe  860
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/47507314)
  Option 1  
You could concatenate the two dataframes and group by columns. 

  pd.concat([df1, df2], 1).dropna().mean(axis=1, level=0)

          A    B
apple   0.0  7.5
banana  2.5  7.5
  

 If it's just  A  you want, then this should suffice -  

  pd.concat([df1, df2], 1).dropna()['A'].mean(axis=1, level=0)

          A
apple   0.0
banana  2.5
  

 

  Option 2  
An alternative would be to find the intersecting indices with  index.intersection  and index with  loc  - 

  i = df1.index.intersection(df2.index)

df1.loc[i, ['A']].add(df2.loc[i, ['A']]).div(2)

          A
Name       
apple   0.0
banana  2.5
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/39379720)
 maybe this solution too could solve your problem: 

  df3 =  pd.concat([df1,df2]).sort_index()

print df3
Out[42]: 
         A   B   C   D
DATE1  a1  b1  c1  d1
DATE1  f1  g1  h1  i1
DATE2  a2  b2  c2  d2
DATE2  f2  g2  h2  i2
DATE3  a3  b3  c3  d3
DATE3  f3  g3  h3  i3
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/43857143)
 You can use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.combine_first.html, also if  dtype  of some index is  object  convert http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.to_datetime.html which works nice if always  df1.index  is in  df.index : 

  print (df.index.dtype)
object

print (df1.index.dtype)
object

df.index = pd.to_datetime(df.index)
df1.index = pd.to_datetime(df1.index)

df = df1.combine_first(df)
#if necessary int columns
#df = df1.combine_first(df).astype(int)
print (df)
            value
period           
2000-01-01  100.0
2000-04-01  200.0
2000-07-01  350.0
2000-10-01  450.0
2001-01-01  550.0
2001-04-01  600.0
2001-07-01  700.0
  

 If not, then is necessary filter by http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Index.intersection.html first: 

  df = df1.loc[df1.index.intersection(df.index)].combine_first(df)
  

 

 Another solution with https://docs.scipy.org/doc/numpy/reference/generated/numpy.setdiff1d.html and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html 

  df = pd.concat([df.loc[np.setdiff1d(df.index, df1.index)], df1])
print (df)
            value
period           
2000-01-01    100
2000-04-01    200
2000-07-01    350
2000-10-01    450
2001-01-01    550
2001-04-01    600
2001-07-01    700
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/48837588)
 Did you try  combine_first  with  A  as the index? 

  df1.set_index('A').combine_first(df2.set_index('A')).reset_index()

    A   B   C
0  A1  B1  C1
1  A2  B2  C2
2  A3  B3  C3
3  A4  B4  C4
  



