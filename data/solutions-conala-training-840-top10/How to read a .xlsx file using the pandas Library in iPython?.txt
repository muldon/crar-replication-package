Query: How to read a .xlsx file using the pandas Library in iPython?
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/47044231)
  DataFrame's  read_excel  method is like  read_csv  method:  

  dfs = pd.read_excel(xlsx_file, sheetname="sheet1")


Help on function read_excel in module pandas.io.excel:

read_excel(io, sheetname=0, header=0, skiprows=None, skip_footer=0, index_col=None, names=None, parse_cols=None, parse_dates=False, date_parser=None, na_values=None, thousands=None, convert_float=True, has_index_names=None, converters=None, true_values=None, false_values=None, engine=None, squeeze=False, **kwds)
    Read an Excel table into a pandas DataFrame

    Parameters
    ----------
    io : string, path object (pathlib.Path or py._path.local.LocalPath),
        file-like object, pandas ExcelFile, or xlrd workbook.
        The string could be a URL. Valid URL schemes include http, ftp, s3,
        and file. For file URLs, a host is expected. For instance, a local
        file could be file://localhost/path/to/workbook.xlsx
    sheetname : string, int, mixed list of strings/ints, or None, default 0

        Strings are used for sheet names, Integers are used in zero-indexed
        sheet positions.

        Lists of strings/integers are used to request multiple sheets.

        Specify None to get all sheets.

        str|int -> DataFrame is returned.
        list|None -> Dict of DataFrames is returned, with keys representing
        sheets.

        Available Cases

        * Defaults to 0 -> 1st sheet as a DataFrame
        * 1 -> 2nd sheet as a DataFrame
        * "Sheet1" -> 1st sheet as a DataFrame
        * [0,1,"Sheet5"] -> 1st, 2nd & 5th sheet as a dictionary of DataFrames
        * None -> All sheets as a dictionary of DataFrames

    header : int, list of ints, default 0
        Row (0-indexed) to use for the column labels of the parsed
        DataFrame. If a list of integers is passed those row positions will
        be combined into a ``MultiIndex``
    skiprows : list-like
        Rows to skip at the beginning (0-indexed)
    skip_footer : int, default 0
        Rows at the end to skip (0-indexed)
    index_col : int, list of ints, default None
        Column (0-indexed) to use as the row labels of the DataFrame.
        Pass None if there is no such column.  If a list is passed,
        those columns will be combined into a ``MultiIndex``
    names : array-like, default None
        List of column names to use. If file contains no header row,
        then you should explicitly pass header=None
    converters : dict, default None
        Dict of functions for converting values in certain columns. Keys can
        either be integers or column labels, values are functions that take one
        input argument, the Excel cell content, and return the transformed
        content.
    true_values : list, default None
        Values to consider as True

        .. versionadded:: 0.19.0

    false_values : list, default None
        Values to consider as False

        .. versionadded:: 0.19.0

    parse_cols : int or list, default None
        * If None then parse all columns,
        * If int then indicates last column to be parsed
        * If list of ints then indicates list of column numbers to be parsed
        * If string then indicates comma separated list of column names and
          column ranges (e.g. "A:E" or "A,C,E:F")
    squeeze : boolean, default False
        If the parsed data only contains one column then return a Series
    na_values : scalar, str, list-like, or dict, default None
        Additional strings to recognize as NA/NaN. If dict passed, specific
        per-column NA values. By default the following values are interpreted
        as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',
    '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'nan'.
    thousands : str, default None
        Thousands separator for parsing string columns to numeric.  Note that
        this parameter is only necessary for columns stored as TEXT in Excel,
        any numeric columns will automatically be parsed, regardless of display
        format.
    keep_default_na : bool, default True
        If na_values are specified and keep_default_na is False the default NaN
        values are overridden, otherwise they're appended to.
    verbose : boolean, default False
        Indicate number of NA values placed in non-numeric columns
    engine: string, default None
        If io is not a buffer or path, this must be set to identify io.
        Acceptable values are None or xlrd
    convert_float : boolean, default True
        convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric
        data will be read in as floats: Excel stores all numbers as floats
        internally
    has_index_names : boolean, default None
        DEPRECATED: for version 0.17+ index names will be automatically
        inferred based on index_col.  To read Excel output from 0.16.2 and
        prior that had saved index names, use True.

    Returns
    -------
    parsed : DataFrame or Dict of DataFrames
        DataFrame from the passed in Excel file.  See notes in sheetname
        argument for more information on when a Dict of Dataframes is returned.
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/27557855)
 The Excel file output by the excelwriter command will appear in the same directory as the python file or ipython notebook (.ipynb).  

 To save the file you need to use the  Save  Command.  

  from pandas import ExcelWriter
import xlrd
import openpyxl
import pandas as pd

writer = pd.ExcelWriter('workbook_name.xlsx') #creates instance of an excel workbook
merged_data.to_excel(writer,'worksheet_name') #creates workbook 
writer.save() #saves workbook to file in python file directory
  

  Dependencies required  

 
 pandas 
 openpyxl 
 xlrd  
 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/16896091)
 I usually create a dictionary containing a  DataFrame  for every sheet: 

  xl_file = pd.ExcelFile(file_name)

dfs = {sheet_name: xl_file.parse(sheet_name) 
          for sheet_name in xl_file.sheet_names}
  

 

 Update: In pandas version 0.21.0+ you will get this behavior more cleanly by passing https://github.com/pandas-dev/pandas/issues/9930 to http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html: 

  dfs = pd.read_excel(file_name, sheet_name=None)
  

 

 In 0.20 and prior, this was  sheetname  rather than  sheet_name  (this is now deprecated in favor of the above): 

  dfs = pd.read_excel(file_name, sheetname=None)
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/36328021)
 How about using the FileLinks class from IPython? I use this to provide access to data directly from Jupyter notebooks. Assuming your data is in pandas dataframe p_df: 

  from IPython.display import FileLink, FileLinks

p_df.to_csv('/path/to/data.csv', index=False)
p_df.to_excel('/path/to/data.xlsx', index=False)

FileLinks('/path/to/')
  

 Run this as a notebook cell and the result will be a list of links to files downloadable directly from the notebook.  '/path/to'  needs to be accessible for the notebook user of course. 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/18312770)
  Update:  It seems that the  readline  thing that @PauloAlmeida mentioned is turned on by default in the 1.0 verison of IPython. So all you have to do is: 

 
  from numpy import array  
 Copy the cells from the spreadsheet 
 Hit  Alt+V  instead of  Ctrl+V  
 

 And you will get in IPython something like: 

  array([[1, 1], [2, 2]])
  

 Or you can use the pandas library  read_clipboard  method. 

<pre class="lang-py prettyprint-override"> import pandas as pd
pd.read_clipboard()            # If you have selected the headers
pd.read_clipboard(header=None) # If you haven't selected the headers
  

 This will return you a pandas DataFrame object which acts similarly to a spreadsheet. You can find more about it in their official http://pandas.pydata.org/pandas-docs/stable/. 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/48869859)
 You can use Pandas  pandas.read_excel  just like  pandas.read_csv : 

  import pandas as pd
file_errors_location = 'C:\\Users\\atheelm\\Documents\\python excel mission\\errors1.xlsx'
df = pd.read_excel(file_errors_location)
print(df)
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/44238149)
 I assume this is run with iPython or a jupyter notebook?
It might have worked before because the kernel remembers some state. Before making something into a seperate function instead of a straight script, I do a  restart kernel & run All  

 On the code itself, I would split the different parts of the code, so it becomes easier to test the individual parts 

 Imports 

  import pandas as pd
import datetime
import calendar

from IPython import get_ipython
get_ipython().magic('reset -sf')
  

 Read 'Sheet1' 

 get the data from the first worksheet and do the first processing 

  def read_melted(file_path):
    df1 = pd.read_excel(file_path, sheetname='Sheet1', parse_date["Date"])
    melted = pd.melt(df,id_vars="Date", var_name="id", value_name="Market_Cap")
    melted.id = melted.id.astype(int)
    melted.reset_index(inplace=True, drop=True)
    return melted
  

 Read 'Sheet2' 

  def read_id_to_spring(file_path):
    df2 = pd.read_excel(file_path, sheetname='Sheet2')
    id_to_string = id2.transpose()
    id_to_string.reset_index(level=0, inplace=True)
    id_to_string.rename(columns = {0: 'id'}, inplace=True)
    id_to_string.rename(columns = {"index": 'Ticker'}, inplace=True)
    return id_to_string
  

 Read 'hardcopy_return' 

  def read_hardcopy_return(file_path):
    df = pd.read_excel(file_path, sheetname='hardcopy_return', parse_date["Date"])
    return df.sort("Date", ascending=1)
  

  

  def reshape(df1, df2, df_hardcopy_return):
    merged = pd.merge(df1, df2, how="left", on="id").sort(["Date","Market_Cap"], ascending=[1,0])
    merged["Rank"] = merged.groupby(["Date"])["Market_Cap"].rank(ascending=True)  # what does this line do?
    merged_all = pd.merge(merged,df_hardcopy_return,  on=["Date", "id"]).set_index("Date") 
    return merged_all
  

 Calling everything 

  path="X:/TEMP/"
file_path =path+file

df1 = read_melted(file_path)
df2 = read_id_to_spring(file_path)
df_hardcopy_return = read_hardcopy_return(file_path)
reshape(df1, df2, df_hardcopy_return)
  

 The only thing that still strikes me as odd is the line  merged["Rank"] = merged.groupby(["Date"])["Market_Cap"].rank(ascending=True)  

 read_excel  sheetname  

  pandas.read_excel  also has a  sheetname  argument, which you can use to only open the excelfile once. Reading excel files can be slow sometimes, so this might make it faster too 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/39099338)
 With recent enough pandas use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html with an existing  ExcelWriter  object and pass sheet names: 

  from pandas.io.excel import ExcelWriter
import pandas

csv_files = ['my_file1.csv', 'my_file2.csv', ..., 'my_file5.csv']

with ExcelWriter('my_excel.xlsx') as ew:
    for csv_file in csv_files:
        pandas.read_csv(csv_file).to_excel(ew, sheet_name=csv_file)
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/35871652)
 IIUC, if you have an excel spreadsheet called 'Workbook.xlsx' like: 

  1 2
2 3
3 4
  

 you can read it with: 

  df = pd.read_excel('Workbook1.xlsx', header=None)
  

 the  header=None  option let you skip the first line as header keeping it as it is. This returns: 

     0  1
0  1  2
1  2  3
2  3  4
  

 Hope that helps. 



