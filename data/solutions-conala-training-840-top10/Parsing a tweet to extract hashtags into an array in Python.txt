Query: Parsing a tweet to extract hashtags into an array in Python
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/37598957)
 simple gist (better than chosen answer)
https://gist.github.com/mahmoud/237eb20108b5805aed5f
also work with unicode hashtags 


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/2527903)
 A simple regex should do the job: 

  >>> import re
>>> s = "I love #stackoverflow because #people are very #helpful!"
>>> re.findall(r"#(\w+)", s)
['stackoverflow', 'people', 'helpful']
  

 Note though, that as suggested in other answers, this may also find non-hashtags, such as a hash location in a URL: 

  >>> re.findall(r"#(\w+)", "http://example.org/#comments")
['comments']
  

 So another simple solution would be the following (removes duplicates as a bonus): 

  >>> def extract_hash_tags(s):
...    return set(part[1:] for part in s.split() if part.startswith('#'))
...
>>> extract_hash_tags("#test http://example.org/#comments #test")
set(['test'])
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/2528131)
 AndiDogs answer will screw up with links and other stuff, you may want to filter them out first. After that use this code: 

  UTF_CHARS = ur'a-z0-9_\u00c0-\u00d6\u00d8-\u00f6\u00f8-\u00ff'
TAG_EXP = ur'(^|[^0-9A-Z&/]+)(#|\uff03)([0-9A-Z_]*[A-Z_]+[%s]*)' % UTF_CHARS
TAG_REGEX = re.compile(TAG_EXP, re.UNICODE | re.IGNORECASE)
  

 It may seem overkill but this has been converted from here http://github.com/mzsanford/twitter-text-java.
It will handle like 99% of all hashtags in the same way that twitter handles them. 

 For more converted twitter regex check out this: http://github.com/BonsaiDen/Atarashii/blob/master/atarashii/usr/share/pyshared/atarashii/formatter.py 

  EDIT:  
Check out: http://github.com/BonsaiDen/AtarashiiFormat 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/48533260)
 You can add this to  result[]  by doing: 

  results = []
#Get the first 1000 items based on the search query and store it
for tweet in tweepy.Cursor(api.search, q='%23Trump').items(1000):
    results.append(tweet)
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/54492403)
 I am using this little loop for a similar situation (NLP on tweets) to extract the hashtag and the at references of a tweet. .  

  import re
tHash = []
tAt = []
for item in tweets:
    if re.search('^@.*', item):
       tAt.append(item)

    if re.search('^#.*', item):
       tHash.append(item)
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/37984637)
 Here is an example of the native Twitter's API user mentions parsing (using https://github.com/tweepy/tweepy : 

  import tweepy

consumer_key='put_key_here'
consumer_secret='put_secret_here'
access_token='put_key_here'
access_token_secret='put_secret_here'

auth = tweepy.OAuthHandler(consumer_key, consumer_secret
auth.set_access_token(access_token, access_token_secret
api = tweepy.API(auth

result = api.search(q='from:CNN', count=1, include_entities=True

print(result[0].text
print(result[0].entities
  

 This outputs the tweet itself : 

  RT @cnnbrk: Polls open in historic UK referendum; voters to decide if Britain stays in EU or becomes first country to exit bloc. https://t.â€¦
  

 And the entities (mentions, hashtags, urls, etc..., which I pretty-printed here for better understanding: 

  {
    "symbols": [], 
    "user_mentions": [
        {
        "indices": [
            3, 
            10
        ], 
        "screen_name": "cnnbrk", 
        "id": 428333, 
        "name": "CNN Breaking News", 
        "id_str": "428333"
        }
    ], 
    "hashtags": [], 
    "urls": [
        {
        "url": "[url_here]", 
        "indices": [
            139, 
            140
        ], 
        "expanded_url": "[url_here]", 
        "display_url": "[url_here]"
        }
    ]
}
  

 In your case, the interesting part is the  user_mentions  array in the JSON. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/23222366)
 The obvious change is to update the hashtags  inside  your loop: 

  for line in f:
    trends1 = api.trends_place(1)
    print trends1
    hashtags = [x['name'] for x in trends1[0]['trends'] if x['name'].startswith('#')]
    # print hashtags
    print hashtags[0]
    trend_hashtag = hashtags[0]
    api.update_status("{0} {1}".format(line, trend_hashtag)) # more modern format
    time.sleep(1800)
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/28591893)
 . 

  stream.filter(track=['#MySpecialHashtag', '#AlsoThisHashtag'])
  

 This will pick up only tweets that contain the hashtags you provide as part of the tweet text and save you from arbitrarily collecting tweets and checking if the hashtag field has your hashtag in it. 



