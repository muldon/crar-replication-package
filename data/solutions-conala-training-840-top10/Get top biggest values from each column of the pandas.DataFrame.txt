Query: Get top biggest values from each column of the pandas.DataFrame
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/20477862)
 Create a function to return the top three values of a series: 

  def sorted(s, num):
    tmp = s.sort_values(ascending=False)[:num]  # earlier s.order(..)
    tmp.index = range(num)
    return tmp
  

 Apply it to your data set: 

  In [1]: data.apply(lambda x: sorted(x, 3))
Out[1]:
   first  second  third
0     89      76     98
1     56      45     87
2     40      45     67
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/20477675)
 With numpy you can get array of top-3 values along columns like follows: 

  >>> import numpy as np
>>> col_ind = np.argsort(data.values, axis=0)[::-1,:]
>>> ind_to_take = col_ind[:3,:] + np.arange(data.shape[1])*data.shape[0]
>>> np.take(data.values.T, ind_to_take)
array([[89, 76, 98],
       [56, 45, 87],
       [40, 45, 67]], dtype=int64)
  

 You can convert back to DataFrame: 

  >>> pd.DataFrame(_, columns = data.columns, index=data.index[:3])
       first  second  third
One       89      76     98
Two       56      45     87
Three     40      45     67
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/49531030)
 You can vectorise this calculation via  numpy . 

 For example, for the 2 largest in each column:- 

  df = pd.DataFrame(np.sort(df.values, axis=0)[::-1][:2], columns=df.columns)
  

  

     sentiment_pos  sentiment_negative
0          0.451                 0.3
1          0.286                 0.1
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/30471284)
 The other solutions (at the time of writing this), sort the DataFrame with super-linear complexity  per column , but it can actually be done with linear time per column. 

 first, http://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.partition.html partitions the  k  smallest elements at the  k  first positions (unsorted otherwise). To get the  k  largest elements, we can use 

  import numpy as np

-np.partition(-v, k)[: k]
  

 Combining this with dictionary comprehension, we can use: 

  >>> pd.DataFrame({c: -np.partition(-data[c], 3)[: 3] for c in data.columns})
    first   second  third
0   89  76  98
1   56  45  87
2   40  45  67
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/42534615)
  >>> def foo(x):
...     r = []
...     for p in zip(list(x.index), list(x)):
...             r.extend(p)
...     return r
... 
>>> pd.DataFrame({n: foo(df.T[row].nlargest(k)) for n, row in enumerate(df.T)}).T
   0  1  2  3  4  5
0  A  7  C  5  B  2
1  A  3  B  3  C  1
2  C  6  B  2  D  1
3  D  9  B  6  A  3
  

 Or, using list comprehension: 

  >>> def foo(x):
...     return [j for i in zip(list(x.index), list(x)) for j in i]
... 
>>> pd.DataFrame({n: foo(df.T[row].nlargest(k)) for n, row in enumerate(df.T)}).T
   0  1  2  3  4  5
0  A  7  C  5  B  2
1  A  3  B  3  C  1
2  C  6  B  2  D  1
3  D  9  B  6  A  3
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/20480508)
 Here's how you get the indices for the top 3 days by sum: 

  In [1]: df.sum(axis=1).order(ascending=False).head(3)
Out[1]:
Banana    219
Grape     201
Apple     151
  

 And you can use that index to reference your original datset: 

  In [2]: idx = df.sum(axis=1).order(ascending=False).head(3).index

In [3]: df.ix[idx]
Out[3]:
        day1  day2  day3
Banana    56    76    87
Grape     89    45    67
Apple     40    13    98
  

  [EDIT]  

  order()  is now deprecated.  sort_values()  can be used here. 

  df.sum(axis=1).sort_values(ascending=False).head(3)
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/50304139)
  nlargest  function on the dataframe will do your work,  df.nlargest(#of rows,'column_to_sort')  

  import pandas
df = pd.DataFrame({'A':[1,1,1,2,2,2,2,3,4],'B':[1,2,3,1,2,3,4,1,1]})
df.nlargest(5,'B')
Out[13]: 
    A      B
6   2      4
2   1      3
5   2      3
1   1      2
4   2      2
# if you want only certain column in the output, the use

df.nlargest(5,'B')['A']
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/42536088)
 This does the job efficiently :  It uses argpartition that found the n biggest in O(n), then sort only them.  

  values=df.values
n,m=df.shape
k=4
I,J=mgrid[:n,:m]
I=I[:,:1]
if k<m: J=(-values).argpartition(k)[:,:k]
values=values[I,J]
names=np.take(df.columns,J)
J2=(-values).argsort()
names=names[I,J2]
values=values[I,J2]
names_and_values=np.empty((n,2*k),object)
names_and_values[:,0::2]=names
names_and_values[:,1::2]=values
result=pd.DataFrame(names_and_values)
  

  

     0  1  2  3  4  5
0  A  7  C  5  B  2
1  B  3  A  3  C  1
2  C  6  B  2  D  1
3  D  9  B  6  A  3
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/46874403)
 Use  double http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nlargest.html - first  for get  2  top values and then  sum  them first and then for another top 2 index values: 

  L = df.groupby('PrimaryName')['Value']
      .apply(lambda x: x.nlargest(2).sum())
      .nlargest(2)
      .index
      .tolist()
print (L)
['PN1', 'PN0']
  

  

  print (df.groupby('PrimaryName')['Value'].apply(lambda x: x.nlargest(2).sum()))
PrimaryName
PN0    11
PN1    13
PN2     5
Name: Value, dtype: int64
  

  

  L = df.sort_values('Value', ascending=False)
      .groupby('PrimaryName')['Value']
      .apply(lambda x: x.head(2).sum())
      .nlargest(2)
      .index
      .tolist()
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/42934452)
 consider the dataframe  df  

  np.random.seed([3,1415])
df = pd.DataFrame(
    np.random.randint(10, size=(10, 4)), list('abcdefghij'), list('ABCD'))

df

   A  B  C  D
a  0  2  7  3
b  8  7  0  6
c  8  6  0  2
d  0  4  9  7
e  3  2  4  3
f  3  6  7  7
g  4  5  3  7
h  5  9  8  7
i  6  4  7  6
j  2  6  6  5
  

 I'm going to use https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.argpartition.html to separate each column into the 5 smallest and  10 - 5  (also  5 ) largest 

  v = df.values
i = df.index.values

k = len(v) - 5
pd.DataFrame(
    i[v.argpartition(k, 0)[-k:]],
    np.arange(k), df.columns
)

   A  B  C  D
0  g  f  i  i
1  b  c  a  d
2  h  h  f  h
3  i  b  d  f
4  c  j  h  g
  



