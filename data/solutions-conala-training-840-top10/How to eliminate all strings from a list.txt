Query: How to eliminate all strings from a list
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/27054483)
 Try putting all the strings into a set after stripping them like so: 

  def myFilter(lines):
    strings = []
    for curLine in lines:
        strings.extend([curString.strip() for curString in curLine.split(";")])
    return set(strings);
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/27054510)
 You can use  str.split  and  set  

  >>> s = "15-105;ZH0311;TZZGJJ; ZH0311; ZH0311;DOC"
>>> ';'.join(s.split(";"))
'15-105;ZH0311;TZZGJJ; ZH0311; ZH0311;DOC'
>>> 
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/37004241)
 You need to use https://docs.python.g/3/library/functions.html#isinstance to filter out those elements that are string. Also don't name your variable  list  it will shadow the built in  list  

  >>> from numbers impt Real
>>> lst = ['hello', 1, 2, 3, 4, 'goodbye', 'help']
>>> [element f element in lst if isinstance(element, Real)]
[1, 2, 3, 4]
  

   

  >>> [element f element in lst if isinstance(element, int)]
[1, 2, 3, 4]
  

  

  >>> [element f element in lst if not isinstance(element, str)]
[1, 2, 3, 4]
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/40497594)
 Looks like those are simply string values going by my interpretation of the data you've provided so far. 

   Steps:   

 Concatenate them row-wise using http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.cat.htmlwith  sep=','  and  na_rep=''  which takes care of the  NaN  values interspersed with the other string chars by treating it as an empty char. 

 Then, remove unwanted whitespaces present among them and also eliminate empty strings using  filter(None,...)  after having taken the unique elements of the list using  set . 

 Finally, join the resulting list to make it a string representation of the list but excluding the brackets. 

  df['list_A&B'] = df['list_A'].str.cat(df['list_B'], ',','') \
                  .apply(lambda x: ', '.join(list(filter(None, set(re.sub(r"\s+", "", x) \
                  .split(','))))))

df                  # df.fillna('') to get back your desired output
  

 https://i.stack.imgur.com/HG68X.png 

 

 Starting  DF  used: 

  df = pd.DataFrame({'list_A': ['A, T, G', np.NaN, 'C, L, AG ', 'F, K'], 
                   'list_B': ['G, C', 'B, K', 'L, AG, K', np.NaN]})
df
  

 <a href="https://i.stack.imgur.com/vJn1r.png"  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/37004586)
 Either use list comprehension as @user3100115 or use the "lisp/lambda approach" 

  >> l = [1, 2, 'a', 'b']
>> list(filter(lambda a: isinstance(a, int), l))
[1, 2]
  

 By the way, do not name your variable  list . It is already a python function.  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/27054435)
  >>> a = "15-105;ZH0311;TZZGJJ; ZH0311; ZH0311;DOC"
>>> a = map(str.strip,a.split(';'))
>>> a
['15-105', 'ZH0311', 'TZZGJJ', 'ZH0311', 'ZH0311', 'DOC']
>>> a = sorted(set(a),key=lambda x:a.index(x))
>>> a
['15-105', 'ZH0311', 'TZZGJJ', 'DOC']
>>> ";".join(a)
'15-105;ZH0311;TZZGJJ;DOC'
  

 i have used split to split it  then strip to remove extra spaces. I have use set to remove duplication, but set dosent care about order. so i need to sort in the order as they are  

  >>> def remove_duplication(my_list):
...     my_newlist = []
...     for x in my_list:
...         x = map(str.strip,x.split(';'))
...         my_newlist.append(";".join(sorted(set(x),key=lambda y:x.index(y))))
...     return my_newlist
... 
>>> remove_duplication(a_list)
['15~105;~ PO185-400CT;NGG;DOC', '15~105;-1;NGG;DOC', '15~105;NGG;-10;DOC', '15~55;J205~J208;POI;DOC', '15-105;ZH0305~;WER /;TZZGJJ;DOC', '15-105;ZH0311;TZZGJJ;DOC', '15-115;PL026~ PL028;Dry;PTT']
  

 if your string is delimited by space: 

  >>> a="# -- coding: utf-8 --" 
>>> a= map(str.strip,a.split())
>>> a
['#', '--', 'coding:', 'utf-8', '--']
>>> a = " ".join(sorted(set(a),key=lambda x:a.index(x)))
>>> a
'# -- coding: utf-8'
  

  split  split the string on some delimiter, it may be space punchuatation or character or can be anything.  

 Go though all this documentation, you will understand. https://docs.python.org/2/library/stdtypes.html, 
https://docs.python.org/2/library/functions.html 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/19251026)
 Instead of if x, I would use if X != '' in order to just eliminate empty strings.  

  str_list = [x for x in str_list if x != '']
  

 This will preserve None data type within your list. Also, in case your list has integers and 0 is one among them, it will also be preserved. 

 For example, 

  str_list = [None, '', 0, "Hi", '', "Hello"]
[x for x in str_list if x != '']
[None, 0, "Hi", "Hello"]
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/26743214)
 First of all, I don't think that your intention is to actually use punctuation as delimiters in the split functions.  Your description suggests that you simply want to eliminate punctuation from the resultant strings. 

 I come across this pretty frequently, and my usual solution doesn't require re. 

 One-liner lambda function w/ list comprehension: 

 (requires  import string ): 

  split_without_punc = lambda text : [word.strip(string.punctuation) for word in 
    text.split() if word.strip(string.punctuation) != '']

# Call function
split_without_punc("Hey, you -- what are you doing?!")
# returns ['Hey', 'you', 'what', 'are', 'you', 'doing']
  

   

 Function (traditional) 

 As a traditional function, this is still only two lines with a list comprehension (in addition to  import string ): 

  def split_without_punctuation2(text):

    # Split by whitespace
    words = text.split()

    # Strip punctuation from each word
    return [word.strip(ignore) for word in words if word.strip(ignore) != '']

split_without_punctuation2("Hey, you -- what are you doing?!")
# returns ['Hey', 'you', 'what', 'are', 'you', 'doing']
  

 It will also naturally leave contractions and hyphenated words intact. You can always use  text.replace("-", " ")  to turn hyphens into spaces before the split. 

 General Function w/o Lambda or List Comprehension 

 For a more general solution (where you can specify the characters to eliminate), and without a list comprehension, you get: 

  def split_without(text: str, ignore: str) -> list:

    # Split by whitespace
    split_string = text.split()

    # Strip any characters in the ignore string, and ignore empty strings
    words = []
    for word in split_string:
        word = word.strip(ignore)
        if word != '':
            words.append(word)

    return words

# Situation-specific call to general function
import string
final_text = split_without("Hey, you - what are you doing?!", string.punctuation)
# returns ['Hey', 'you', 'what', 'are', 'you', 'doing']
  

 Of course, you can always generalize the lambda function to any specified string of characters as well. 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/3003411)
 If you put  list_2  into a  set , it should make the containment checking a lot quicker: 

  s = set(list_2)
[f for f in list_1 if not f in s]
  

 This is because  x in list  is an O(n) check, while  x in set  is constant-time.  

 Another way is to use set-difference: 

  list(set(list_1).difference(set(list_2)))
  

 However, this probably won't be faster than the first way - also, it'll eliminate duplicates from  list_1  which you may not want.  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/22331981)
 Looks like you have a bunch of unicode strings you want to eliminate. Just chose the alpha numeric characters in the list like so: 

  >>> filter( lambda m: m.isalnum()  ,p)
  

 That should eliminate the unicode stuff ... 

 The other option is to encode and decode the string directly ... 

  >>> ' '.join(p).decode('ascii', 'ignore').encode('ascii').split()
  

 This should do a much better job ... 



