Query: How do I calculate the md5 checksum of a file in Python?
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/26426051)
 The MD5 calculate by boto is the base 64 encode of checksum. The 'Content-MD5' in header for a given file to be uploaded/already uploaded can be calculated by: 

  import hashlib, base64
conn = S3Connection(access_key, secret_key)
bucket = conn.get_bucket('bucket_name')
#If you want to calculate MD5 of a file already uploaded
obj_key = bucket.get_key('file_name_in_s3')
content = obj_key.get_contents_as_string()
m = hashlib.md5()
m.update(content)
value = m.digest()
remote_md5 = base64.b64encode(value)

#To calculate md5 of a file to be uploaded to S3
cur_md5 = base64.b64encode(hashlib.md5(open('Local/Path/To/File').read()).digest())
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/14398938)
 The  set_contents_from_filename  method will automatically calculate the MD5 checksum for you.  There is an optional  md5  parameter to this method which allows you to pass in the MD5 if you have already calculated it for some reason in your application but if you don't pass a value in, boto will calculate it for you. 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/31691399)
 Use checksumdir python package available for calculating checksum/hash of directory. It's available at https://pypi.python.org/pypi/checksumdir/1.0.5 

   Usage :   

  import checksumdir
hash = checksumdir.dirhash("c:\\temp")
print hash
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/44104498)
 . You can get CRC because it was carefully precalculated for you when archive is created (it is used for integrity check). Any other checksum/hash has to be calculated from scratch and will require at least streaming of the archive content, i.e. unpacking. 

  UPD : Possibble implementations 

  libarchive : extra dependencies, supports many archive formats 

  import libarchive.public as libarchive
with libarchive.file_reader(fname) as archive:
    for entry in archive:
        md5 = hashlib.md5()
        for block in entry.get_blocks():
            md5.update(block)
        print(str(entry), md5.hexdigest())
  

 Native  zipfile : no dependencies, zip only 

  import zipfile

archive = zipfile.ZipFile(fname)
blocksize = 1024**2  #1M chunks
for fname in archive.namelist():
    entry = archive.open(fname)
    md5 = hashlib.md5()
    while True:
        block = entry.read(blocksize)
        if not block:
            break
        md5.update(block)
        print(fname, md5.hexdigest())
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/24847616)
 You may try to check https://docs.python.org/2/library/hashlib.html 

  import hashlib
[(fname, hashlib.md5(open(fname, 'rb').read()).digest()) for fname in fnamelst]
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/15119065)
 As @garnatt already said, the  set_contents_from_filename  method will automatically calculate the MD5 checksum for you. 

 If you look at the docs, there is a method called  compute_md5  which returns a tuple containing the MD5 checksum in a hexdigest (what your getting in the console using  md5sum ) and also base64 encoded which it sends to Amazon which is what your seeing in the headers. 

 The  md5  parameter in the  set_contents_from_filename  method takes the MD5 checksum in a tuple format, the same way  compute_md5  returns. If you need to calculate it manually, the best way is to use the  compute_md5  method. Otherwise you have to build a tuple in the correct format before passing it to the  md5  parameter. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/3431838)
 You can use http://docs.python.org/library/hashlib.html 

 Note that sometimes you won't be able to fit the whole file in memory. In that case, you'll have to read chunks of 4096 bytes sequentially and feed them to the Md5 function: 

  def md5(fname):
    hash_md5 = hashlib.md5()
    with open(fname, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()
  

  Note:   hash_md5.hexdigest()  will return the  hex string  representation for the digest, if you just need the packed bytes use  return hash_md5.digest() , so you don't have to convert back. 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/28191368)
 hashlib with  md5  might be of your interest. 

  import hashlib
hashlib.md5("Nobody inspects the spammish repetition").hexdigest()
  

 output:  

  bb649c83dd1ea5c9d9dec9a18df0ffe9
  

 Constructors for hash algorithms that are always present in this module are  md5(), sha1(), sha224(), sha256(), sha384(), and sha512() . 

 If you want more condensed result, then you may try  sha  series 

 output for  sha224 : 

  'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'
  

 For more details : https://docs.python.org/2/library/hashlib.html 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/16876405)
 In regards to your error and what's missing in your code. m is name which was not defined for getmd5() function. No offence, I know you are a beginner, but your code is all over the place. Let's look at your issues one by one :) First off, you are not using hashlib.md5.hexdigest() method correctly. Please find explanation on haslib functions http://docs.python.org/3.3/library/hashlib.html. The correct way to return md5 for provided <b>string</b> is to do something like this: 

  >>> import hashlib
>>> hashlib.md5("filename.exe").hexdigest()
'2a53375ff139d9837e93a38a279d63e5'
  

 However, you have bigger problem here. You are calculating MD5 on a <b>file name string</b>, where in reality MD5 is calculated based on file <b>contents</b>. You will need to basically read file contents and pipe it though md5. My next example is not very efficient, but something like that: 

  >>> import hashlib
>>> hashlib.md5(open('filename.exe','rb').read()).hexdigest()
'd41d8cd98f00b204e9800998ecf8427e'
  

 As you can clearly see second MD5 hash is totally different from the first one. The reason for that is that we are pushing contents of the file through, not just file name. A simple solution could be something like that: 

  # Import hashlib library (md5 method is part of it)
import hashlib    

# File to check
file_name = 'filename.exe'      

# Correct original md5 goes here
original_md5 = '5d41402abc4b2a76b9719d911017c592'  

# Open,close, read file and calculate MD5 on its contents 
with open(file_name) as file_to_check:
    # read contents of the file
    data = file_to_check.read()    
    # pipe contents of the file through
    md5_returned = hashlib.md5(data).hexdigest()

# Finally compare original MD5 with freshly calculated
if orginal_md5 == md5_returned:
    print "MD5 verified."
else:
    print "MD5 verification failed!."
  

 Please look at the post <b>https://stackoverflow.com/questions/3431825/python-generating-a-md5-checksum-of-a-file</b> it explains in detail couple of ways how it can be achieved efficiently. 

 . 


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/34919942)
 So I made it :) This way one hash sum is generated for a file list. 

  hash_obj = hashlib.md5(open(flist[0], 'rb').read())
for fname in flist[1:]:
    hash_obj.update(open(fname, 'rb').read())
checksum = hash_obj.digest()
  

 Thank you PM 2Ring for your input! 

 Note that md5 has been cracked so use it only for non security critical purposes. 



