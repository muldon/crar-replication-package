Query: Getting the length of an array
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/38214081)
 Use  np.in1d  on a new array created with  np.arange  from the length of  a : 

  >>> a = [10, 31, 30, 11, 17, 12, 22, 25, 85, 17, 21, 43]
>>> b = [0, 1, 4, 6]
>>> a = np.array(a)
>>> b = np.array(b)
>>> np.in1d(np.arange(len(a)), b)
array([ True,  True, False, False,  True, False,  True, False, False,
       False, False, False], dtype=bool)
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/40802197)
 Do you need it to be a list.  Since you want to use the indexing behavior of a numpy array, it would make better sense to other people that read your code if you actually use a numpy array.   

 Maybe try using an array with dtype='a'?  For example in the code below,  

  x = sp.array(['a', 'b', 'c'], dtype='a')
print(x)
print(x=='c')
print(x[x=='c']).
  

 This will return the following arrays,  

  ['a' 'b' 'c']
[False False  True]
['c'].
  

 Assignment will work as you would expect too,  

  x[x=='c'] = 'z'
print(x).  
  

 This will return the modified array,  

  ['a' 'b' 'z'].
  

 The only concern is that the elements of the array cannot be longer than the allocated length.  Here it is specified as one with dtype='a'. You can use dtype='a5' or dtype='aN' for any length you want.  All the elements of the array must be strings that are shorter than the maximum length. 

 If you pass a string that is too long it will chop off the end, as in the following example with dtype set to 'a2': 

  x = sp.array(['abc', 'bcd', 'cde'], dtype='a2')
print(x), 
  

  

  ['ab' 'bc' 'cd'].
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/19664216)
 SO thread 'https://stackoverflow.com/questions/19663013/multiply-two-arrays-element-wise-where-one-of-the-arrays-has-arrays-as-elements'  has an example of constructing an array from arrays.  If the subarrays are the same size, numpy makes a 2d array.  But if they differ in length, it makes an array with  dtype=object , and the subarrays retain their identity. 

 Following that, you could do something like this: 

  In [5]: result=np.array([np.zeros((1)),np.zeros((2))])

In [6]: result
Out[6]: array([array([ 0.]), array([ 0.,  0.])], dtype=object)

In [7]: np.append([result[0]],[1,2])
Out[7]: array([ 0.,  1.,  2.])

In [8]: result[0]
Out[8]: array([ 0.])

In [9]: result[0]=np.append([result[0]],[1,2])

In [10]: result
Out[10]: array([array([ 0.,  1.,  2.]), array([ 0.,  0.])], dtype=object)
  

 However, I don't offhand see what advantages this has over a pure Python list or lists.  It does not work like a 2d array.  For example I have to use  result[0][1] , not  result[0,1] .  If the subarrays are all the same length, I have to use  np.array(result.tolist())  to produce a 2d array. 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/21919462)
 One way is to use  numpy.binary_repr . It will result in a string, but you can easily convert that to an array of ints or floats (just change the  dtype  argument).  For example: 

  import numpy as np

k = 4
print np.array([list(np.binary_repr(x, k)) for x in range(2**k)], dtype=int)
  

  

  [[0 0 0 0]
 [0 0 0 1]
 [0 0 1 0]
 [0 0 1 1]
 [0 1 0 0]
 [0 1 0 1]
 [0 1 1 0]
 [0 1 1 1]
 [1 0 0 0]
 [1 0 0 1]
 [1 0 1 0]
 [1 0 1 1]
 [1 1 0 0]
 [1 1 0 1]
 [1 1 1 0]
 [1 1 1 1]]
  

 Or, if you wanted a more readable version: 

  def bitstrings(k):
    binary = [np.binary_repr(item, width=k) for item in range(2**k)]
    return np.array([list(item) for item in binary], dtype=int)
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/49879165)
 Since you mention matrices, you should use 3rd party library  numpy : 

  import numpy as np

matrix_1 = np.array([[1, 2], [3, 4], [5, 6]])

matrix_2 = np.array([[1, 3, 5], [2, 4, 6]])

res = np.array_equal(matrix_1, matrix_2.T)  # True
res = (matrix_1 == matrix_2.T).all()        # True
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/21336840)
 Use http://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html: 

  In [5]: import numpy as np

In [6]: a = np.arange(5)                                                                         

In [7]: b = np.arange(11)                                                                        

In [8]: np.concatenate((a, b))                                                                   
Out[8]: array([ 0,  1,  2,  3,  4,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])
  

 For 1-D arrays you can also use http://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html: 

  In [9]: np.hstack((a, b))                                                                       
Out[9]: array([ 0,  1,  2,  3,  4,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/21336836)
 You need to use http://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html instead of array addition 

  c = numpy.concatenate((a, b))
  

    

  import numpy as np
a = np.arange(53)
b = np.arange(82)
c = np.concatenate((a, b))
  

  Output  

  c.shape
(135, )
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/43562680)
 The result of  np.where  is a  tuple  containing  n  arrays, where  n  is the number of dimensions in your array. The good new is that each of these  n  arrays has the same length (each representing one "index" for every found item), so you could just use the length of any of them: 

  >>> len(data[0])  # or len(data[i]) where i < dimensions of your df7
  

 as already mentioned in the comments. However if you just want to know how many items satisfy the condition, you can use  np.count_nonzero : 

  >>> a = np.array([2,3,4,5])
>>> b = np.array([3,3,3,3])

>>> np.count_nonzero(a != b)
3
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/42370545)
 One approach with concatenation of the endpoints (0 and the length of array) on either sides of the indices array and then use diferentiation to get the interval lengths - 

  np.diff(np.concatenate(([0], inds, [arr.size])))
  

 Shorter alternative - 

  np.diff(np.r_[0, inds, arr.size])
  

 For performance we could use difference between  one-off shifted slices  to replace the differentiation with  np.diff  - 

  inds_ext = np.concatenate(([0], inds, [arr.size]))
out = inds_ext[1:] - inds_ext[:-1]
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/33256228)
 One approach using http://docs.scipy.org/doc/numpy/reference/generated/numpy.diff.html and http://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html - 

  # Append with `-1s` at either ends and get the differentiation
dfa = np.diff(np.hstack((-1,a,-1)))

# Get the positions of starts and stops of 1s in `a`
starts = np.where(dfa==2)[0]
stops = np.where(dfa==-2)[0]

# Get valid mask for pairs from starts and stops being of at least 3 in length
valid_mask = (stops - starts) >= 3

# Finally collect the valid pairs as the output
out = np.column_stack((starts,stops))[valid_mask].tolist()
  



