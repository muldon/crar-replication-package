Query: Python Pandas drop columns based on max value of column
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/35087667)
  

  In [255]:
df.loc[df['sq_resid']!=df['sq_resid'].max()]

Out[255]:
      p_rel      y_BET  sq_resid
1  0.069370  41.184996  0.292942
2  0.116405  43.101090  0.010953
3  0.173409  44.727748  0.036832
5  0.250682  46.980616  0.128191
6  0.294650  47.446113  0.132367
  

 or http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html#pandas.DataFrame.drop using http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.idxmax.html which will return the label row of the max value: 

  In [257]:
df.drop(df['sq_resid'].idxmax())

Out[257]:
      p_rel      y_BET  sq_resid
1  0.069370  41.184996  0.292942
2  0.116405  43.101090  0.010953
3  0.173409  44.727748  0.036832
5  0.250682  46.980616  0.128191
6  0.294650  47.446113  0.132367
7  0.322530  48.078038  0.235047
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/50209948)
 You can do this simply by using pandas drop duplicates function 

  df.drop_duplicates(['A','B'],keep= 'last')
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/47655169)
 You can do it with  drop_duplicates  as you wanted 

  # initialisation
d = pd.DataFrame({'A' : [1,1,2,3,3], 'B' : [2,2,7,4,4],  'C' : [1,4,1,0,8]})

d = d.sort_values("C", ascending=False)
d = d.drop_duplicates(["A","B"])
  

 If it's important to get the same order  

  d = d.sort_index()
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/32094006)
 I think groupby should work. 

  df.groupby(['A', 'B']).max()['C']
  

 If you need a dataframe back you can chain the reset index call. 

  df.groupby(['A', 'B']).max()['C'].reset_index()
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/26897730)
 Use the  df.max()  to index with. 

  In [19]: from pandas import DataFrame

In [23]: df = DataFrame(np.random.randn(3,3), columns=['a','b','c'])

In [36]: df
Out[36]: 
          a         b         c
0 -0.928912  0.220573  1.948065
1 -0.310504  0.847638 -0.541496
2 -0.743000 -1.099226 -1.183567


In [24]: df.max()
Out[24]: 
a   -0.310504
b    0.847638
c    1.948065
dtype: float64
  

 Next, we make a boolean expression out of this: 

  In [31]: df.max() > 0
Out[31]: 
a    False
b     True
c     True
dtype: bool
  

 Next, you can index df.columns by this (this is called boolean indexing): 

  In [34]: df.columns[df.max() > 0]
Out[34]: Index([u'b', u'c'], dtype='object')
  

 Which you can finally pass to DF: 

  In [35]: df[df.columns[df.max() > 0]]
Out[35]: 
          b         c
0  0.220573  1.948065
1  0.847638 -0.541496
2 -1.099226 -1.183567
  

 Of course, instead of 0, you use any value that you want as the cutoff for dropping. 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/30590457)
 I would suggest using  all  on the boolean condition on the entire df rather than use  apply : 

  In [122]:
col_to_drop = df.columns[(df==1).all()]
col_to_drop

Out[122]:
Index(['A'], dtype='object')

In [123]:    
df2.drop(col_to_drop, axis=1)
Out[123]:
          B         C
0  0.507605  0.134758
1  0.777054  0.285220
2  0.121124  0.430874
3  0.422746  0.775676
4  0.563303  0.659942
5  0.582580  0.437603
6  0.221917  0.339737
7  0.634779  0.172416
8  0.703110  0.730759
9  0.426673  0.923138
  

 call  all  on the boolean comparison returns a series with boolean values for each column: 

  In [124]:
(df==1).all()

Out[124]:
A     True
B    False
C    False
dtype: bool
  

 You can then use this to mask the columns to return which column you wish to drop from  df2  as shown above. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/42267533)
 You need http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.idxmax.html for indexes of max value of  value3  and thes select  DataFrame  by http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html: 

  print (df.groupby(['id1','id2','value1']).value3.idxmax())
id1  id2  value1
1    2    30        1
3    5    12        4
24   12   1         6
Name: value3, dtype: int64

df = df.loc[df.groupby(['id1','id2','value1']).value3.idxmax()]
print (df)
   id1  id2  value1  value2  value3   a
1    1    2      30      42    26.2 NaN
4    3    5      12      33    11.2 NaN
6   24   12       1      23     1.9 NaN
  

 Another possible solution is http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html by column  value3  and then  groupby  with http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.first.html: 

  df = df.sort_values('value3', ascending=False)
       .groupby(['id1','id2','value1'], sort=False)
       .first()
       .reset_index()
print (df)
   id1  id2  value1  value2  value3   a
0    1    2      30      42    26.2 NaN
1    3    5      12      33    11.2 NaN
2   24   12       1      23     1.9 NaN
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/32094352)
 You can do it using group by: 

  c_maxes = df.groupby(['A', 'B']).C.transform(max)
df = df.loc[df.C == c_maxes]
  

  c_maxes  is a  Series  of the maximum values of  C  in each group but which is of the same length and with the same index as  df . If you haven't used  .transform  then printing  c_maxes  might be a good idea to see how it works.  

 Another approach using  drop_duplicates  would be  

  df.sort('C').drop_duplicates(subset=['A', 'B'], take_last=True)
  

 Not sure which is more efficient but I guess the first approach as it doesn't involve sorting.  

  EDIT: 
From  pandas 0.18  up the second solution would be  

  df.sort_values('C').drop_duplicates(subset=['A', 'B'], keep='last')
  

 or, alternatively, 

  df.sort_values('C', ascending=False).drop_duplicates(subset=['A', 'B'])
  

 In any case, the  groupby  solution seems to be significantly more performing:  

  %timeit -n 10 df.loc[df.groupby(['A', 'B']).C.max == df.C]
10 loops, best of 3: 25.7 ms per loop

%timeit -n 10 df.sort_values('C').drop_duplicates(subset=['A', 'B'], keep='last')
10 loops, best of 3: 101 ms per loop
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/46463698)
 I think you need http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.agg.html of  max ,  min  and  size  (or  count  if need not count  NaN s). Then filter by http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing, remove column and last rename columns: 

  df = df.groupby('mac')['timestamp'].agg(['min','max', 'size'])
d = {'min':'t1','max':'t2'}
df = df[df['size'] > 1].drop('size', 1).rename(columns=d).reset_index()
#alternatively:
#df = df.query('size > 1').drop('size', 1).rename(columns=d).reset_index()

print (df)
  mac t1 t2
0   A  1  3
1   C  1  2
  

 Another solution is filter first with http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.duplicated.html: 

  df = df[df['mac'].duplicated(keep=False)]
d = {'min':'t1','max':'t2'}
df = df.groupby('mac')['timestamp'].agg(['min','max']).rename(columns=d).reset_index()
print (df)
  mac t1 t2
0   A  1  3
1   C  1  2
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/52619598)
    

  np.random.seed(0)  # Add seed to reproduce results. 
df = pd.DataFrame(np.random.randn(6,4), columns=list('ABCD'))
df['id'] = ['CA', 'CA', 'CA', 'FL', 'FL', 'FL']
df['technique'] = ['one', 'two', 'three', 'one', 'two', 'three']
  

 You could  melt , sort with  sort_values , and drop duplicates using  drop_duplicates : 

  (df.melt(['id', 'technique'])
   .sort_values(['id', 'value'], ascending=[True, False])
   .drop_duplicates('id')
   .drop('value', 1)
   .reset_index(drop=True)
   .rename({'variable': 'highest_prob'}, axis=1))

   id technique highest_prob
0  CA       one            D
1  FL       two            A
  

 

 Another solution is to use  melt  and  groupby : 

  v = df.melt(['id', 'technique'])
(v.iloc[v.groupby('id').value.idxmax()]
  .drop('value', 1)
  .reset_index(drop=True)
  .rename({'variable': 'highest_prob'}, axis=1))

   id technique highest_prob
0  CA       one            D
1  FL       two            A
  



