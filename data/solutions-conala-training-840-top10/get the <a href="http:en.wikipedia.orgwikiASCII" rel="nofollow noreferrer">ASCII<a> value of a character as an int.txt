Query: get the <a href="http://en.wikipedia.org/wiki/ASCII" rel="nofollow noreferrer">ASCII</a> value of a character as an int
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/39229882)
 Apparently, urllib can only handle ASCII requests, and converting your url to ascii gives a error on your special character.
Replacing ø with %C3%B8, the proper way to encode this special character in http, seems to do the trick. However, I can't find a method to do this automatically like your browser does. 

 example: 

  >>> f="https://no.wikipedia.org/wiki/Jonas_Gahr_St%C3%B8re"
>>> import urllib.request
>>> g=urllib.request.urlopen(f)
>>> text=g.read()
>>> text[:100]
b'<!DOCTYPE html>\n<html class="client-nojs" lang="nb" dir="ltr">\n<head>\n<meta charset="UTF-8"/>\n<title'
  

 The answer above doesn't work, because he is encoding after the request is processed, while you get an error during the request processing. 


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/50243316)
 Change your url from  "http://en.wikipedia.org"  to  "https://en.wikipedia.org" .  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/54529774)
 ... 

  Browsing context has been discarded
.
Failed to decode response from marionette
  

 ...implies that the communication between  GeckoDriver  and  Marionette  was broken. 

 Some more information regarding the binary version interms of: 

 
 Selenium Server/Client 
 GeckoDriver 
 Firefox 
 

 Additionally, your  code block  and the  error stack trace  would have given us some clues about whats wrong happening. However this issue can happen due to multiple factors as follows: 

 
 As per https://github.com/mozilla/geckodriver/issues/918 if you have used  driver.navigate().back();  when  Selenium's  focus was within an  <iframe>  this error is observed. 
 As per https://bugzilla.mozilla.org/show_bug.cgi?id=1401131 this issue can also occur due to  ctypes checks for NULL pointer derefs .

 
 You can find the  Selenium testcase  https://bug1401131.bmoattachments.org/attachment.cgi?id=8909692. Perhaps instead of panicking, it would have been better to handle this more gracefully by clearing any state and returning geckodriver to accept new connections again. 
  
 As per https://github.com/mozilla/geckodriver/issues/690 this issue can also occur if you are not using the complient version of the binaries. 
 

 https://firefox-source-docs.mozilla.org/testing/geckodriver/geckodriver/Support.html 

   


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/9270343)
 Simple urlparse.unquote with custom User-Agent header seems to do the job. 

  >>> s = 'http://en.wikipedia.org/wiki/M%C3%BCnster'
>>> import urllib2, urlparse
>>> headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.2; rv:9.0.1) Gecko/20100101 Firefox/9.0.1'}
>>> url = urlparse.unquote(s)
>>> req = urllib2.Request(url, None, headers)
>>> resp = urllib2.urlopen(req)
>>> print resp.code
200
>>> data = resp.read()
>>> print 'The last outstanding palace of the German baroque period is created according to plans by Johann Conrad Schlaun.' in data
True
  

 Don't decode byte string into unicode object, it causes  UnicodeEncodeError: 'ascii' codec can't encode character u'\xfc' in position 11: ordinal not in range(128)  in urlopen. 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/45186069)
 You can customize the theme, overriding the part that contains the  <title>  tag. See http://www.sphinx-doc.org/en/stable/templating.html in the Sphinx documentation for complete information. If you have the "basic" theme, you would need to override https://github.com/sphinx-doc/sphinx/blob/master/sphinx/themes/basic/layout.html#L130 

      <title>{{ title|striptags|e }}{{ titlesuffix }}</title>
  

 You can apply control structures in themes using http://jinja.pocoo.org/docs/2.9/templates/#if, in case you want to apply this feature for only one page and not others. 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/39229884)
 If using a library is an option, I would suggest the awesome http://docs.python-requests.org/ 

  # -*- coding: utf-8 -*-
import requests
r = requests.get('https://no.wikipedia.org/wiki/Jonas_Gahr_Støre')
print(r.text)
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/44746528)
 When you are taking links from  element, href attribute .You will almost always get link like /wiki/Main_Page.  

 Because the base url is always the same 'https://en.wikipedia.org'.
So what you need is to do is: 

  base_url = 'https://en.wikipedia.org'
search_url ="https://en.wikipedia.org/wiki/WKIK"
r  = requests.get(search_url)
data = r.content
soup = BeautifulSoup(data)

for link in soup.find_all('a', href=True):
    print ("Found the URL:", link['href'])
    if link['href'] != '#' and link['href'].strip() != '':
       final_url = base_url + link['href']
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/32394136)
 You can't scrape the desired job description content because, as you suggest, it is part of an  <iframe>  tag. The content of the  iframe  is set using JavaScript just after the page loads, and is therefore not returned as part of your  page = urllib2.urlopen(req)  request. To scrape content from an iFrame you will need to use a browser automation module such as Selenium http://docs.seleniumhq.org/docs/03_webdriver.jsp 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/6246905)
 XML data cannot contain certain characters. An easy workaround is to wrap the data inside your XML tag that is giving you the error with CDATA. For example: 

  <xmltag><![CDATA[Your content]]></xmltag>
  

 Or you can use numerical reference values ex  &amp;  for & 

 More information on this is available here: 

 http://en.wikipedia.org/wiki/XML#Characters_and_escaping
http://en.wikipedia.org/wiki/Numeric_character_reference
http://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references
http://en.wikipedia.org/wiki/CDATA 


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/37339086)
 This works pretty well with using optional matches (prints after  href= ) and gets the link only. Tested on http://pythex.org/ 

  (?:href=['"])([:/.A-z?<_&\s=>0-9;-]+)
  

 Oputput: 

 
   Match 1. /wiki/Main_Page 
  
   Match 2. /wiki/Portal:Contents 
  
   Match 3. /wiki/Portal:Featured_content 
  
   Match 4. /wiki/Portal:Current_events 
  
   Match 5. /wiki/Special:Random 
  
   Match 6. //donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en 
 



