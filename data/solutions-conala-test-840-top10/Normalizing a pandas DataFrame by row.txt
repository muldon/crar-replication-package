Query: Normalizing a pandas DataFrame by row
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/34821117)
 You can select all the rows and slice the df using  loc  and then call http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.div.html and pass the last row using  iloc[-1] : 

  In [58]:
df.loc[:,'C14-Cer_mean':] = df.loc[:,'C14-Cer_mean':].div(df.iloc[-1]['C14-Cer_mean':])
df

Out[58]:
      Sample_name C14-Cer_mean C16-Cer_mean C18-Cer_mean C18:1-Cer_mean
index                                                                  
0             1 1     0.305224     0.542487      66.4284        73.6153
1            1 10     0.814694      1.24617      73.8026        58.0646
2            1 13     0.556437     0.517383      50.5559        51.9137
3            1 14     0.314057      1.14875      56.1658        61.2622
4             1 5     0.499128     0.460814      40.1824        41.7711
5             1 6     0.300203     0.784066      47.3595         52.842
6             1 9     0.395581      1.08206      54.0198         58.773
7           Blank            1            1            1              1
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/18594595)
 To overcome the broadcasting issue, you can use the  div  method: 

  df.div(df.sum(axis=1), axis=0)
  

 See http://pandas.pydata.org/pandas-docs/stable/basics.html#matching-broadcasting-behavior 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/52007440)
 Use https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.div.html:  

  df= pd.DataFrame({"ID": ['1', '2', '3', '4'], "A": [1, 0, 10, 0], "B": [4, 0, 30, 0]})
df.set_index("ID", inplace=True)
df.div(df.sum(axis=1), axis=0).fillna(0)
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/52007424)
 You can use http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html 

  df= pd.DataFrame({"ID": ['1', '2', '3', '4'], "A": [1, 0, 10, 0], "B": [4, 0, 30, 0]})
df = df.set_index('ID')

from sklearn.preprocessing import Normalizer
df.iloc[:,:] = Normalizer(norm='l1').fit_transform(df)

print(df)

       A     B
ID            
1   0.20  0.80
2   0.00  0.00
3   0.25  0.75
4   0.00  0.00
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/52007429)
 Using  melt  with  crosstab  

  newdf=df.melt('ID')
pd.crosstab(index=newdf.ID,columns=newdf.variable,values=newdf.value,normalize='index',aggfunc='mean')
Out[447]: 
variable     A     B
ID                  
1         0.20  0.80
2         0.00  0.00
3         0.25  0.75
4         0.00  0.00
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/23585220)
 In case you are trying to normalize each row such that its magnitude is one (i.e. a row's unit length is one or the sum of the square of each element in a row is one): 

  import numpy as np

a = np.arange(0,27,3).reshape(3,3)

result = a / np.linalg.norm(a, axis=-1)[:, np.newaxis]
# array([[ 0.        ,  0.4472136 ,  0.89442719],
#        [ 0.42426407,  0.56568542,  0.70710678],
#        [ 0.49153915,  0.57346234,  0.65538554]])
  

  

  np.sum( result**2, axis=-1 )
# array([ 1.,  1.,  1.]) 
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/8904762)
 Broadcasting is really good for this: 

  row_sums = a.sum(axis=1)
new_matrix = a / row_sums[:, numpy.newaxis]
  

  row_sums[:, numpy.newaxis]  reshapes row_sums from being  (3,)  to being  (3, 1) . When you do  a / b ,  a  and  b  are broadcast against each other. 

 You can learn more about  broadcasting  http://docs.scipy.org/doc/numpy/reference/ufuncs.html#broadcasting or even better <a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html?highlight=broadcasting#numpy.doc.broadcasting" . 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/30271510)
 Here is a way to do it (from networkx.pagerank_scipy).  It uses scipy linear algebra functions instead of iterating over each row.  That will probably be faster for large graphs. 

  In [42]: G=nx.random_geometric_graph(5,0.5)

In [43]: M=nx.to_scipy_sparse_matrix(G, nodelist=G.nodes(), dtype=float)

In [44]: M.todense()
Out[44]: 
matrix([[ 0.,  1.,  0.,  1.,  1.],
        [ 1.,  0.,  0.,  0.,  1.],
        [ 0.,  0.,  0.,  1.,  1.],
        [ 1.,  0.,  1.,  0.,  1.],
        [ 1.,  1.,  1.,  1.,  0.]])

In [45]: S = scipy.array(M.sum(axis=1)).flatten()

In [46]: S[S != 0] = 1.0 / S[S != 0]

In [47]: Q = scipy.sparse.spdiags(S.T, 0, *M.shape, format='csr')

In [48]: (Q*M).todense()
Out[48]: 
matrix([[ 0.        ,  0.33333333,  0.        ,  0.33333333,  0.33333333],
        [ 0.5       ,  0.        ,  0.        ,  0.        ,  0.5       ],
        [ 0.        ,  0.        ,  0.        ,  0.5       ,  0.5       ],
        [ 0.33333333,  0.        ,  0.33333333,  0.        ,  0.33333333],
        [ 0.25      ,  0.25      ,  0.25      ,  0.25      ,  0.        ]])
  



