Query: How to remove ^M from a text file and replace it with the next line
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/11755305)
  

  >>> mystring = mystring.replace("\r", "").replace("\n", "")
  

 (where "mystring" contain your text) 


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/27917855)
 Replace  f.next()  to  next(f)  

  with open("test.csv",'r') as f, open("updated_test.csv",'w') as f1:
    next(f) # skip header line
    for line in f:
        f1.write(line)
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/46627794)
 Some things that I noticed that contribute to only some of the punctuation being removed. The line  for word in file:  should actually be  for line in file: . Python iterates over files by lines and not by words. The  strip  function only removes items from the beginning and end. You would use the  replace  function to remove characters from the middle. The way the program is currently written, it will only remove punctuation from the beginning and end of each line in the document. 

 The way I would remove all punctuation is like so. 

  from pathlib import Path
import string

filepath = Path(filename)
text = filepath.read_text()
text = text.replace(string.punctuation, "")
filepath.write_text(text )
  

 But you say that the replace function messes with the ebook functionality. . I don't see how replacing punctuation within each individual word is any different then replacing it all at once for the entire file? 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/2581032)
 Regex does the trick if you are needing to replace any text between "[%" and "%]". 

 The code would look something like this: 

  import re


newstring = re.sub("\[%.*?%\]",newtext,oldstring)
  

 The regex used here is lazy so it would match everything between an occurrence of "[%" and the next occurrence of "%]". You could make it greedy by removing the question mark. This would match everything between the first occurrence of of "[%" and the last occurrence of "%]" 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/39110)
 I guess something like this should do it. It basically writes the content to a new file and replaces the old file with the new file: 

  from tempfile import mkstemp
from shutil import move
from os import fdopen, remove

def replace(file_path, pattern, subst):
    #Create temp file
    fh, abs_path = mkstemp()
    with fdopen(fh,'w') as new_file:
        with open(file_path) as old_file:
            for line in old_file:
                new_file.write(line.replace(pattern, subst))
    #Remove original file
    remove(file_path)
    #Move new file
    move(abs_path, file_path)
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/11755403)
  ''.join(somestring.split(r'\r'))
  

  

  somestring.replace(r'\r','')
  

 This assumes you have carriage return characters in your string, and not the literal "^M". If it is the literal string "^M" then substiture r'\r' with "^M" 

 If you want the newlines gone then use r'\r\n' 

 This is very basic string manipulation in python and it is probably wth looking at some basic tutials http://mihirknows.blogspot.com.au/2008/05/string-manipulation-in-python.html  

 And as the first commenter said its always helpful to give some indication of what you have tried so far, and what you don't understand about the problem, rather than asking f an straight answer. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/29434912)
 You would need to remove from the list, you cannot   del  the line, the easiest way is to write to a temp file and copy after if you want to modify the file, if you just want to print ignoring the 38 line replace write with print: 

   with open('in.txt','r') as f,open('temp.txt','w') as temp:
    for line in f:
        if "phrase" in line:
            for i in range(38):
                next(f) # skip 38 lines
        else:
            temp.write(line)
  

 Then use shutil to move the file: 

  import shutil

shutil.move("temp.txt","in.txt")
  

 You can also use a  https://docs.python.org/2/library/tempfile.html#tempfile.NamedTemporaryFile: 

  from tempfile import NamedTemporaryFile

with open('file.txt','r') as f, NamedTemporaryFile(dir=".",delete=False) as  temp:
    for line in f:
        if "phrase" in line:
            for i in range(38):
                next(f)
        else:
            temp.write(line)

import shutil
shutil.move(temp.name,"file.txt")
  

 The only potential problem I see is if the phrase is in one of the 38 ignored lines and you should also remove the next 38 lines from there. 

  To ignore until a second phrase, keep looping in the inner loop until you find the second phrase then break:

with open('in.txt','r') as f, NamedTemporaryFile(dir=".", delete=False) as temp:
    for line in f:
        if "phrase" in line:
            for _line in f:
                if "phrase2" in _line:
                    break
        else:
            temp.write(line)
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/53077686)
 If it's a file, one thing you can do is load the file in and read line by line. 

 for everyline, you can use regex to find and replace. Then you can either overwrite the file or write onto a new file. 

 For example, 

  line.replace('$home', 'id')
  

 Alternatively, you can load the json python in and convert it into a string. Then replace the text using the regex. Finally, converts back to Python dictionary using json.load(). 
However, 10k line is too long. I think reading a file, line-by-line, would be a better solutions. 

 EDIT:
Here is the code sample. 

  from tempfile import mkstemp
from shutil import move
from os import fdopen, remove

def replace(file_path, pattern, subst):
    #Create temp file
    fh, abs_path = mkstemp()
    with fdopen(fh,'w') as new_file:
        with open(file_path) as old_file:
            for line in old_file:
                new_file.write(line.replace(pattern, subst))
    #Remove original file
    remove(file_path)
    #Move new file
    move(abs_path, file_path)

replace('./text.txt', '$home', 'id')
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/31519964)
 Simply look for  double new lines  and replace them with  single new lines : 

  In [1]: data = """[atRA]_0    [Cyp26A1_mRNA]_0    
   ...: 1   0   0
   ...: 
   ...: 1.999   0   0
   ...: 
   ...: 2.998   0   0
   ...: 
   ...: 3.997   0   0
   ...: 
   ...: 4.996   0   0"""

In[2]: print(data.replace('\n\n', '\n'))
[atRA]_0    [Cyp26A1_mRNA]_0    
1   0   0
1.999   0   0
2.998   0   0
3.997   0   0
4.996   0   0
  



