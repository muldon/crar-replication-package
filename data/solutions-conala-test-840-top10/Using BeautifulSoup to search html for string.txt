Query: Using BeautifulSoup to search html for string
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/8936232)
  text='Python'  searches for elements that have the exact text you provided: 

  import re
from BeautifulSoup import BeautifulSoup

html = """ exact text 
    almost exact text """
soup = BeautifulSoup(html)
print soup(text='exact text')
print soup(text=re.compile('exact text'))
  

 Output</h3>

  [u'exact text']
[u'exact text', u'almost exact text']
  

 "To see if the string 'Python' is located on the page http://python.org": 

  import urllib2
html = urllib2.urlopen('http://python.org').read()
print 'Python' in html # -> True
  

 If you need to find a position of substring within a string you could do  html.find('Python') . 


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/11294166)
 This works, but may not be very robust:  

  import re
r = re.compile('<HR>\s?<font size="\+1">(.+?)</font>\s?<BR>', re.IGNORECASE)
r.findall(html)
  

 You will be better off using a proper HTML parser.  BeautifulSoup is excellent and easy to use.  .   


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/34572901)
 When searching elements by name and text,  BeautifulSoup  checks the http://www.crummy.com/software/BeautifulSoup/bs4/doc/#string of an element to match a desired text. This confusing behavior is  actually covered in the http://www.crummy.com/software/BeautifulSoup/bs4/doc/#id18: 

 
   If you pass one of the find* methods both string and a tag-specific argument like name,  Beautiful Soup will search for tags that match your tag-specific criteria and whose  Tag.string  matches your value for string . It will not find the strings themselves. Previously, Beautiful Soup ignored the tag-specific arguments and looked for strings. 
 

   .string  of the  div  element is  None  - this is why you are not getting any results. Instead, find the text node directly: 

  soup.find(text=re.compile(r"Scientific"))
  

 And, if you would need the actual parent element, you can get it from the  .parent : 

  soup.find(text=re.compile(r"Scientific")).parent
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/24545901)
 The code you link to appears to be using a library called http://www.crummy.com/software/BeautifulSoup/ to parse the HTML. That loop is over a list of tag objects created by Beautiful Soup, not a list of the actual tag text. 

 Here's an example using <a href="http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html" v3 : 

  from BeautifulSoup import BeautifulSoup

html_doc = """
 
 
"""

soup = BeautifulSoup(html_doc)
html_img_tags = soup.findAll("img")

for tag in html_img_tags:
  print tag['src']
  

 The output is: 

  /images/icons/product/chrome-48.png
/images/icons/product/chrome-49.png
  

 Note that  tag  is  not  just a string, it's a BeautifulSoup tag object: 

  >>> type(html_img_tags[0])
<class 'BeautifulSoup.Tag'>
  

 If you print it, it will display as a nicely formatted tag: 

  >>> print html_img_tags[0]
 
  

 But that's only because BeautifulSoup makes sure that the object converts itself to that string for easy inspection. 

 

 Note: if you happen to have BS4 on your machine instead, the import line should be: 

  from bs4 import BeautifulSoup
  

 ...and the  findAll()  function is now  find_all() . 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/38910675)
 An example using  BeautifulSoup   combined with regex  instead: 

  from bs4 import BeautifulSoup
import re

string = '''
<a class='fooo123'>foo on its own 
<a class='123foo'>only foo 
'''

soup = BeautifulSoup(string, "lxml")
foo_links = soup.find_all(text=re.compile("^foo"))
print(foo_links)
# ['foo on its own']
  

 

 To   wrap   the found links with e.g.  mark , you can do the following: 

  from bs4 import BeautifulSoup
import re

string = '''
<a class='fooo123'>foo on its own 
<a class='123foo'>only foo 
'''

soup = BeautifulSoup(string, "lxml")
foo_links = soup.findAll('a', text=re.compile("^foo"))
for a in foo_links:
    mark = soup.new_tag('mark')
    a.wrap(mark)

print(soup.prettify())
  

 As well as the mandatory https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags link... 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/50917880)
 BeautifulSoup standardises the parse tree on input and converts tags to  lower-case  

  >>> soup.findAll('numberofbins')
[<numberofbins>991</numberofbins>, <numberofbins>991</numberofbins>]
>>> 
>>> soup.findAll('samplefreq')
[<samplefreq units="Hz">5.0000000000000000e+006</samplefreq>, <samplefreq units="Hz">5.0000000000000000e+006</samplefreq>]
>>> 
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/52122358)
 Avoid using  regex  to parse html data. Use something specially designed for this like  BeautifulSoup  

  >>> text = """<address>
...         113 N Michigan St Chicago, IL 60661
... </address>"""
>>> 
>>> from bs4 import BeautifulSoup
>>> soup = BeautifulSoup(text, "html.parser")
>>> 
>>> [addr.strip() for tag in soup.find_all('address') for addr in tag.strings]
['113 N Michigan St', 'Chicago, IL 60661']
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/17583157)
 if that is the html code then you should replace the  'a'  tag with a  'span'  tag.  It should look something like this... 

      ...
    price = soup.find('span',id="v4-27")
    print price #optional price.string will give you just the 15,00 EUR
                #instead of the entire html line
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/50135689)
 What  find  method does is searching for a tag. So when you do  soup.find('word')  you're asking BeautifulSoup to find all the  <word></word>  tags. . 

 There are several ways to perform what you're asking. You can use  re  module for searching with a regular expression like that: 

  import re

is_present = bool(re.search('word', response.text))
  

 But you can avoid importing extra modules, as you use Scrapy, which has a built-in methods for working with regular expressions. Just use  re  method on selector: 

  is_present = bool(response.xpath('//body').re('word'))
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/47479646)
 You might need to do the search it manually rather than relying on the regular expression: 

  from bs4 import BeautifulSoup

soup = BeautifulSoup(html, "html.parser")
header_title = "Unique Title 2"

for h4 in soup.find_all('h4'):
    if header_title in h4.text:
        ...
  



