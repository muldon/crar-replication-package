Query: Extracting words from a string, removing punctuation and returning a list with separated words in Python
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/7633312)
 Try to use  re : 

  >>> [w for w in re.split('\W', 'Hello world, my name is...James!') if w]
['Hello', 'world', 'my', 'name', 'is', 'James']
  

 Although I'm not sure that it will catch all your use cases. 

 If you want to solve it in another way, you may specify characters that you want to be in result: 

  >>> re.findall('[%s]+' % string.ascii_letters, 'Hello world, my name is...James!')
['Hello', 'world', 'my', 'name', 'is', 'James']
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/7633307)
 .All you need is a tokenizer. Have a look at http://www.nltk.org/ and especially at WordPunctTokenizer. 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/15740656)
 Assuming you consider wds as groups of characters separated by spaces: 

  >>> from string impt punctuation
>>> line = "Isn't ., stackoverflow the - best ?"
>>> ' '.join(wd.strip(punctuation) f wd in line.split() 
             if wd.strip(punctuation))
"Isn't stackoverflow the best"
  

  

  >>> line = "Isn't ., stackoverflow the - best ?"
>>> ' '.join(filter(None, (wd.strip(punctuation) f wd in line.split())))
"Isn't stackoverflow the best"
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/7633435)
 This has nothing to do with splitting and punctuation; you just care about the letters (and numbers), and just want a regular expression: 

  impt re
def getWds(text):
    return re.compile('\w+').findall(text)
  

  

  >>> re.compile('\w+').findall('Hello wld, my name is...James the 2nd!')
['Hello', 'wld', 'my', 'name', 'is', 'James', 'the', '2nd']
  

 If you don't care about numbers, replace  \w  with  [A-Za-z]  f just letters,   [A-Za-z']  to include contractions, etc. There are probably fancier ways to include alphabetic-non-numeric character classes (e.g. letters with accents) with other regex. 

 

 I almost answered this question here: https://stackoverflow.com/questions/1059559/python-strings-split-with-multiple-separats/5894804#5894804 

 But your question is actually under-specified: Do you want  'this is: an example'  to be split into: 

 
  ['this', 'is', 'an', 'example']  
   ['this', 'is', 'an', '', 'example'] ? 
 

 I assumed it was the first case. 

 

 
    [this', 'is', 'an', example'] is what i want. is there a method without impting regex? If we can just replace the non ascii_letters with '', then splitting the string into wds in a list, would that wk?  – James Smith 2 mins ago 
 

 The regexp is the most elegant, but yes, you could this as follows: 

  def getWds(text):
    """
        Returns a list of wds, where a wd is defined as a
        maximally connected substring of uppercase  lowercase
        alphabetic letters, as defined by "a".isalpha()

        >>> get_wds('Hello wld, my name is... Élise!')  # wks in python3
        ['Hello', 'wld', 'my', 'name', 'is', 'Élise']
    """
    return ''.join((c if c.isalnum() else ' ') f c in text).split()
  

   .isalpha()  

 

 Sidenote: You could also do the following, though it requires impting another standard library: 

  from itertools impt *

# groupby is generally always overkill and makes f unreadable code
# ... but is fun

def getWds(text):
    return [
        ''.join(chars)
            f isWd,chars in 
            groupby(' My name, is test!', lambda c:c.isalnum()) 
            if isWd
    ]
  

 

 If this is homewk, they're probably looking f an imperative thing like a two-state Finite State Machine where the state is "was the last character a letter" and if the state changes from letter -> non-letter then you output a wd. Don't do that; it's not a good way to program (though sometimes the abstraction is useful). 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/22351071)
 Rather than replacing the punctuation, you could  split  on spaces then  strip  punctuation at the start and end of each word: 

  >>> import string
>>> phrase = "'This has punctuation, and it's hard to remove!'"
>>> [word.strip(string.punctuation) for word in phrase.split(" ")]
['This', 'has', 'punctuation', 'and', "it's", 'hard', 'to', 'remove']
  

 This keeps apostrophes and hyphens within words, while removing punctuation at the start or end of words. 

 

 Note that standalone punctuation will be replaced by an empty string  "" : 

  >>> phrase = "This is - no doubt - punctuated"
>>> [word.strip(string.punctuation) for word in phrase.split(" ")]
['This', 'is', '', 'no', 'doubt', '', 'punctuated']
  

 This is easy to filter out, as the empty string evaluates  False : 

  filtered = [f for f in txt if f and f.lower() not in stopwords]
                            # ^ excludes empty string
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/13015996)
 Here is an alternative solution using a generator expression. 

  tot_str = ' '.join(word for word in prime if word not in stopw)
  

 To make this more efficient, turn  stopw  into a  set  using  stopw = set(stopw) . 

 You might be having issues with your current approach if sample.txt is not just a space separated file, for example if you have normal sentences with punctuation then splitting on space will leave the punctuation as a part of a word.  To fix this you can use the  re  module to split your string on whitespace or punctuation: 

  import re
prime = re.split(r'\W+', text_file.read())
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/18136232)
 This is a job for http://docs.python.org/2/library/re.html! 

 For example: 

  import re
file = open('screenplay.txt', 'r')
# .lower() returns a version with all upper case characters replaced with lower case characters.
text = file.read().lower()
file.close()
# replaces anything that is not a lowercase letter, a space, or an apostrophe with a space:
text = re.sub('[^a-z\ \']+', " ", text)
words = list(text.split())
print words
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/18136275)
 Try the algorithm from https://stackoverflow.com/a/17951315/284795, ie. split text on whitespace, then trim punctuation. This carefully removes punctuation from the edge of words, without harming apostrophes inside words such as  we're .  

  >>> text
"'Oh, you can't help that,' said the Cat: 'we're all mad here. I'm mad. You're mad.'"

>>> text.split()
["'Oh,", 'you', "can't", 'help', "that,'", 'said', 'the', 'Cat:', "'we're", 'all', 'mad', 'here.', "I'm", 'mad.', "You're", "mad.'"]

>>> [word.strip(string.punctuation) for word in text.split()]
['Oh', 'you', "can't", 'help', 'that', 'said', 'the', 'Cat', "we're", 'all', 'mad', 'here', "I'm", 'mad', "You're", 'mad']
  

 You might want to add a  .  



