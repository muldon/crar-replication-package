Query: How to subset a dataset in pandas dataframe?
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/47359927)
 Let's try  groupby  +  cumsum : 

  df = df.groupby('id', group_keys=False)\
       .apply(lambda x: x[x.status.cumsum().cumsum().le(1)])\
       .reset_index(drop=1)
df

   id  status
0   1       0
1   1       0
2   1       0
3   1       0
4   1       1
5   2       0
6   2       0
7   2       0
8   2       0
9   2       1
  

 

 Here's an alternative that performs a  groupby  to create a mask to be used as an indexer: 

  df = df[df.status.eq(1).groupby(df.id)\
          .apply(lambda x: x.cumsum().cumsum().le(1))]\
          .reset_index(drop=1)
df

   id  status
0   1       0
1   1       0
2   1       0
3   1       0
4   1       1
5   2       0
6   2       0
7   2       0
8   2       0
9   2       1
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/28557333)
 The following should work for you. Here I sample  remove_n  random row_ids from  df 's index. After that  df.drop  removes those rows from the data frame and returns the new subset of the old data frame. 

  import pandas as pd
import numpy as np
np.random.seed(10)

remove_n = 1
df = pd.DataFrame({"a":[1,2,3,4], "b":[5,6,7,8]})
drop_indices = np.random.choice(df.index, remove_n, replace=False)
df_subset = df.drop(drop_indices)
  

 DataFrame  df : 

      a   b
0   1   5
1   2   6
2   3   7
3   4   8
  

 DataFrame  df_subset : 

      a   b
0   1   5
1   2   6
3   4   8
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/51077812)
 I think need http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.apply.html, http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nlargest.html and  sum : 

  df = sns.load_dataset('flights')
df2 = df.groupby('year')['passengers'].apply(lambda x: x.nlargest(3).sum()).reset_index()
print (df2)
    year  passengers
0   1949         432
1   1950         498
2   1951         582
3   1952         690
4   1953         779
5   1954         859
6   1955        1026
7   1956        1192
8   1957        1354
9   1958        1431
10  1959        1579
11  1960        1763
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/45035966)
 It is called  subset  - passed list of columns in  [] : 

  dataset = pandas.read_csv('file.csv', names=names)

new_dataset = dataset[['A','D']]
  

  

  new_dataset = dataset.loc[:, ['A','D']]
  

 If need only filtered output add parameter  usecols  to http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html: 

  new_dataset = pandas.read_csv('file.csv', names=names, usecols=['A','D'])
  

 EDIT: 

 If use only: 

  new_dataset = dataset[['A','D']]
  

 and use some data manipulation, obviously get: 

 
   A value is trying to be set on a copy of a slice from a DataFrame. 
   .loc[row_indexer,col_indexer] = value instead 
 

 If you modify values in  new_dataset  later you will find that the modifications do not propagate back to the original data ( dataset ), and that Pandas does warning. 

 As pointed https://stackoverflow.com/questions/45035929/creating-new-pandas-dataframe-from-certain-columns-of-existing-dataframe#comment77045763_45035929 add http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html for remove warning: 

  new_dataset = dataset[['A','D']].copy()
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/29378443)
 if df is the sample dataframe: 

  s = set(df.) #unique keys
for k in s:
    print df[df.==k] #sub-dataframes
  

 result: 

      mukey       hzdept_r  hzdepb_r
0  422927  11090397         0        20
1  422927  11090397        20        71
2  422927  11090397        71       152
    mukey       hzdept_r  hzdepb_r
3  422927  11090398         0        18
4  422927  11090398        18       117
5  422927  11090398       117       152
  

 if you literally only want the first dataframe, let  k=df.iloc[0]. . 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/45488729)
 Make a list of the subset that you want (in this example it is A, B, and C), create an empty dataframe, then fill it with the desired values using a nested loop. 

  df = pd.DataFrame(np.random.randn(50, 7), columns=list('ABCDEFG'))

# initiate empty dataframe
corr = pd.DataFrame()
for a in list('ABC'):
    for b in list(df.columns.values):
        corr.loc[a, b] = df.corr().loc[a, b]

corr
Out[137]: 
          A         B         C         D         E         F         G
A  1.000000  0.183584 -0.175979 -0.087252 -0.060680 -0.209692 -0.294573
B  0.183584  1.000000  0.119418  0.254775 -0.131564 -0.226491 -0.202978
C -0.175979  0.119418  1.000000  0.146807 -0.045952 -0.037082 -0.204993

sns.heatmap(corr)
  

 https://i.stack.imgur.com/cJgPp.png 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/53397341)
 If order of rows doesn't mind, you can arrange them in place : 

  n=10**7
df=pd.DataFrame(arange(4*n).reshape(n,4))
indices=np.unique(randint(0,n,size=n//2))

from numba import njit
@njit
def _dropfew(values,indices):
    k=len(values)-1
    for ind in indices[::-1]:
            values[ind]=values[k]
            k-=1

def dropfew(df,indices):
    _dropfew(df.values,indices)
    return df.iloc[:len(df)-len(indices)]
  

  

  In [39]: %time df.iloc[df.index.drop(indices)]
Wall time: 1.07 s

In [40]: %time dropfew(df,indices)
Wall time: 219 ms
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/34888322)
 Rather than converting data types you can use  apply  with a  lambda  function which will be a bit faster.  

  df[~df.col3.apply(lambda x: 'nodata' in x)]
  

 Testing it on a larger dataset: 

  In [86]: df.shape
Out[86]: (5000, 3)   
  

 My solution: 

  In [88]: %timeit df[~df.col3.apply(lambda x: 'nodata' in x)]
         1000 loops, best of 3: 1.68 ms per loop
  

  

  In [87]: %timeit df[~df['col3'].astype(str).str.contains('nodata')]
         100 loops, best of 3: 7.8 ms per loop
  

 Arguably the first answer may be more readable though.  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/53253381)
 What you're trying to do will take a few steps. (The code below assumes use of the standard https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/d546eaee765268bf2f487608c537c05e22e4b221/iris.csv). 

 
  First, let's subset your  DataFrame  by only the columns we need. 

  df_subset = df[['sepal_length','species']]
   
  Next, use https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html#pandas.DataFrame.pivot (intead of  pandas.pivot_table ) to convert your  DataFrame  from "long" to "flat". 

  df_pivot = df_subset.pivot(columns='species',values='sepal_length')
   
  Now, we're close to what you wanted but because your three  species  columns run along the same index, the pivoted  DataFrame  returns  NaN s for two of the three columns for any given row. We can work around this by column-wise concatenating the  DataFrame  while re-indexing it. (Essentially creating three  DataFrames  - one for each species - and joining them along a new index). We can do this one of two ways: 

 
  The compact solution: 

  names = ['setosa','versicolor','virginica']

df_final = pd.concat(map(lambda name: df_pivot[name].dropna().reset_index().drop('index',axis=1), names), axis=1) 
   
  Which is equivalent to: 

  df_final = pd.concat([
    df_pivot['setosa'].dropna().reset_index().drop('index',axis=1),
    df_pivot['versicolor'].dropna().reset_index().drop('index',axis=1),
    df_pivot['virginica'].dropna().reset_index().drop('index',axis=1)],axis=1)
   
  
 



