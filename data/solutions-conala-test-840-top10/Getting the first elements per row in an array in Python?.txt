Query: Getting the first elements per row in an array in Python?
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/51151403)
 You need https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html to extract an array of integers to feed NumPy indexing: 

  x1[np.where(y1==1)[0], 1]
  

 To understand how this work, note that  y1 == 1  returns the following Boolean array: 

  array([[ True],
       [ True],
       [False],
       [ True],
       [False]], dtype=bool)
  

  numpy.where  extracts indices of the  True  elements in the first element of the tuple returned: 

  print(np.where(y1==1))
(array([0, 1, 3], dtype=int64), array([0, 0, 0], dtype=int64))
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/42246278)
 The basic problem is getting  j  unique elements for  1000  rows. We can't use  np.random.choice(.....replace=True)  directly there as then we won't have  j  unique elements. To solve our case, one vectorized approach would be to use a random matrix of shape  (1000,len(input_array)) , perform  argsort  along the second axis and get  j  unique indices per row, then index into the input array with it and finally sum along the second axis. 

 To implement it, we would have two approaches - 

  def app1(serie1, j, N=1000):
    idx = np.random.rand(N,serie1.size).argsort(1)[:,:j]
    return serie1[idx].sum(1)
  

 Using efficient  np.argpartition  for selecting random  j  elements and  then  np.take  for efficient indexing  - 

  def app2(serie1, j, N=1000):
    idx = np.random.rand(N,serie1.size).argpartition(j,axis=1)[:,:j]
    return np.take(serie1, idx).sum(1)
  

 Sample run to demo creating the indices  idx  - 

  In [35]: serie1 = np.random.randint(0,9,(20))

In [36]: idx = np.random.rand(1000,serie1.size).argsort(1)[:,:5]

In [37]: idx
Out[37]: 
array([[16, 13, 19,  0, 15],
       [ 7,  4, 13, 15, 14],
       [ 8,  3, 15,  1,  9],
       ..., 
       [11, 15, 17,  4, 19],
       [19,  0,  3,  7,  9],
       [10,  1, 19, 12,  6]])
  

  Verifying uniform random sampling -  

  In [81]: serie1 = np.arange(20)

In [82]: j = 5

In [83]: idx = np.random.rand(1000000,serie1.size).argsort(1)[:,:j]

In [84]: np.bincount(idx.ravel())
Out[84]: 
array([250317, 250298, 250645, 249544, 250396, 249972, 249492, 250512,
       249968, 250133, 249622, 250170, 250291, 250060, 250102, 249446,
       249398, 249003, 250249, 250382])
  

 Having fairly equal counts across the length of  20  elems in the input array, I think its pretty uniformly distributed. 

    

  In [140]: serie1 = np.random.randint(0,9,(20))

In [141]: j = 5

# @elcombato's soln
In [142]: %timeit [sum(sample(serie1, j)) for _ in range(1000)]
100 loops, best of 3: 10.7 ms per loop

# Posted solutions in this post
In [143]: %timeit app1(serie1, j, N=1000)
     ...: %timeit app2(serie1, j, N=1000)
     ...: 
1000 loops, best of 3: 943 µs per loop
1000 loops, best of 3: 870 µs per loop
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/26914273)
 I'd use broadcasting tricks, but this depends very much on the size of your arrays and the amount of RAM available to you: 

  M = g.reshape(g.shape+(1,)) - a.T.reshape((1,a.shape[1],a.shape[0]))
np.any(np.any(M == 0, axis=0), axis=1)
# returns:
# array([ True, False,  True,  True, False], dtype=bool)
  

 It's easier to explain with a piece of paper and a pen (and smaller test arrays) (see below), but basically you're making copies of each column in  g  (one copy for each row in  a ) and subtracting single elements taken from the corresponding column in  a  from these copies. Similar to the original algorithm, just vectorized. 

  Caveat : if any of the arrays  g  or  a  is 1D, you'll need to force it to become 2D, such that its shape is at least  (1,n) . 

  Speed gains :  

 
  based only on your arrays: a factor ~20 

 
 python for loops: 301us per loop 
 vectorized: 15.4us per loop 
  
  larger arrays: factor ~80 

  In [2]: a = np.random.random_integers(-2, 3, size=(4, 50))

In [3]: b = np.random.random_integers(-20, 30, size=(35, 50))

In [4]: %timeit np.any(np.any(b.reshape(b.shape+(1,)) - a.T.reshape((1,a.shape[1],a.shape[0])) == 0, axis=0), axis=1)
10000 loops, best of 3: 39.5 us per loop

In [5]: %timeit [np.any(np.in1d(b[:,i], a[:, i])) for i in range(a.shape[1])]
100 loops, best of 3: 3.13 ms per loop
   
 

 Image attached to explain broadcasting:
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/52247900)
 Maybe you figured out the answer but anyway here is my answer: 

 In 3d array the slicing syntax is denoted by [matrices, rows, columns] 

  import numpy as np

# Below we are creating a 3D matrix similar to your matrix where there are 
# 5 matrices each containing 3 rows and 4 columns

routine_matrix = np.arange(5*3*4).reshape((5,3,4))
print(routine_matrix) 
  

  

  [[[ 0  1  2  3]
  [ 4  5  6  7]
  [ 8  9 10 11]]

 [[12 13 14 15]
  [16 17 18 19]
  [20 21 22 23]]

 [[24 25 26 27]
  [28 29 30 31]
  [32 33 34 35]]

 [[36 37 38 39]
  [40 41 42 43]
  [44 45 46 47]]

 [[48 49 50 51]
  [52 53 54 55]
  [56 57 58 59]]]
  

 Now, As per your question you are interested in 1, 13, 25, 37, 49 that is first element of 0th row and 1st column of each internal matrix  

 So, in order to achieve that we do 

  print(routine_matrix[:, 0, 1])
  

 Understand slicing here: 

 
 ':' says that choose all the matrices 
 '0' says that choose only the 0th row of all the matrices 
 

 i.e:    [0 1 2 3], [12, 13, 14, 15], [24, 25, 26, 27], [36, 37, 38, 39], [48, 49, 50, 51] 

 
 '1' says that of all the rows selected above just choose the first column (Array index starts from 0 in python) 
 

 i.e: [1, 13, 25, 37, 49] 

 Hence the output: 

  [ 1 13 25 37 49]
  

 In your case it will be ['aa' 'bb' 'cc' 'dd' 'ee'] 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/45894382)
 As promised, this being the fourth day of the bounty period, here's my attempt at a vectorized solution. The steps involved are explained in some details below : 

 
  For easy reference, let's call the input array as  a . Generate unique indices per row that covers the range for row length. For this, we can simply generate random numbers of the same shape as the input array and get the  argsort  indices along each row, which would be those unique indices. This idea has been explored before in https://stackoverflow.com/a/45438143/3293881.  
  Index into each row of input array with those indices as columns indices. Thus, we would need https://docs.scipy.org/doc/numpy-1.10.1/reference/arrays.indexing.html#advanced-indexing here. Now, this gives us an array with each row being shuffled. Let's call it  b .   
  Since the shuffling is restricted to per row, if we simply use the boolean-indexing :  b[b!=0] , we would get the non-zero elements being shuffled and also being restricted to lengths of non-zeros per row. This is because of the fact that the elements in a NumPy array are stored in row-major order, so with boolean-indexing it would have selected shuffled non-zero elements on each row first before moving onto the next row. Again, if we use boolean-indexing similarly for  a , i.e.  a[a!=0] , we would have similarly gotten the non-zero elements on each row first before moving onto the next row and these would be in their original order. So, the final step would be to just grab masked elements  b[b!=0]  and assign into the masked places  a[a!=0] .  
 

 Thus, an implementation covering the above mentioned three steps would be - 

  m,n = a.shape
rand_idx = np.random.rand(m,n).argsort(axis=1) #step1
b = a[np.arange(m)[:,None], rand_idx]          #step2  
a[a!=0] = b[b!=0]                              #step3 
  

 A sample step-by-step run might make things clearer - 

  In [50]: a # Input array
Out[50]: 
array([[ 8,  5,  0, -4],
       [ 0,  6,  0,  3],
       [ 8,  5,  0, -4]])

In [51]: m,n = a.shape # Store shape information

# Unique indices per row that covers the range for row length
In [52]: rand_idx = np.random.rand(m,n).argsort(axis=1)

In [53]: rand_idx
Out[53]: 
array([[0, 2, 3, 1],
       [1, 0, 3, 2],
       [2, 3, 0, 1]])

# Get corresponding indexed array
In [54]: b = a[np.arange(m)[:,None], rand_idx]

# Do a check on the shuffling being restricted to per row
In [55]: a[a!=0]
Out[55]: array([ 8,  5, -4,  6,  3,  8,  5, -4])

In [56]: b[b!=0]
Out[56]: array([ 8, -4,  5,  6,  3, -4,  8,  5])

# Finally do the assignment based on masking on a and b
In [57]: a[a!=0] = b[b!=0]

In [58]: a # Final verification on desired result
Out[58]: 
array([[ 8, -4,  0,  5],
       [ 0,  6,  0,  3],
       [-4,  8,  0,  5]])
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/41920427)
 Splitting as such won't be an efficient solution, instead we could reshape, which effectively creates subarrays as rows of a  2D  array. These would be views into the input array, so no additional memory requirement there. Then, we would get argsort indices and select first five indices per row and finally sum those up for the desired output. 

 Thus, we would have an implementation like so - 

  N = 512 # Number of elements in each split array
M = 5   # Number of elements in each subarray for sorting and summing

b = a.reshape(-1,N)
out = b[np.arange(b.shape[0])[:,None], b.argsort(1)[:,:M]].sum(1)
  

  

  In [217]: a   # Input array
Out[217]: array([45, 19, 71, 53, 20, 33, 31, 20, 41, 19, 38, 31, 86, 34])

In [218]: N = 7 # 512 for original case, 7 for sample

In [219]: M = 5

# Reshape into M rows 2D array
In [220]: b = a.reshape(-1,N)

In [224]: b
Out[224]: 
array([[45, 19, 71, 53, 20, 33, 31],
       [20, 41, 19, 38, 31, 86, 34]])

# Get argsort indices per row
In [225]: b.argsort(1)
Out[225]: 
array([[1, 4, 6, 5, 0, 3, 2],
       [2, 0, 4, 6, 3, 1, 5]])

# Select first M ones
In [226]: b.argsort(1)[:,:M]
Out[226]: 
array([[1, 4, 6, 5, 0],
       [2, 0, 4, 6, 3]])

# Use fancy-indexing to select those M ones per row
In [227]: b[np.arange(b.shape[0])[:,None], b.argsort(1)[:,:M]]
Out[227]: 
array([[19, 20, 31, 33, 45],
       [19, 20, 31, 34, 38]])

# Finally sum along each row
In [228]: b[np.arange(b.shape[0])[:,None], b.argsort(1)[:,:M]].sum(1)
Out[228]: array([148, 142])
  

 Performance boost with https://docs.scipy.org/doc/numpy/reference/generated/numpy.argpartition.html - 

  out = b[np.arange(b.shape[0])[:,None], np.argpartition(b,M,axis=1)[:,:M]].sum(1)
  

  

  In [236]: a = np.random.randint(11,99,(512*512))

In [237]: N = 512

In [238]: M = 5

In [239]: b = a.reshape(-1,N)

In [240]: %timeit b[np.arange(b.shape[0])[:,None], b.argsort(1)[:,:M]].sum(1)
100 loops, best of 3: 14.2 ms per loop

In [241]: %timeit b[np.arange(b.shape[0])[:,None], \
                np.argpartition(b,M,axis=1)[:,:M]].sum(1)
100 loops, best of 3: 3.57 ms per loop
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/45519545)
 If you wish to do a per-row count, supply  axis=1  to  sum : 

  boolarr
# array([[False, False,  True],
#        [ True, False,  True],
#        [ True, False,  True]], dtype=bool)

boolarr.sum(axis=1)
# array([1, 2, 2])
  

 Similarly, with  np.count_nonzero : 

  np.count_nonzero(boolarr, axis=1)
# array([1, 2, 2])
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/2054479)
  import itertools
s = ((1, 23, 34),(2, 34, 44), (3, 444, 234))
print(next(itertools.izip(*s)))
  

  itertools.izip  returns an iterator. The  next  function returns the next (and in this case, first) element from the iterator.  

 In Python 2.x,  zip  returns a tuple.
 izip  uses less memory since iterators do not generate their contents until needed. 

 In Python 3,  zip  returns an iterator. 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/47443969)
 Here's one way - 

  N = 3 # number of points to be set as False per row

# Slice out the first N cols per row
k_idx = idx[:,:N]

# Initialize output array
out = np.ones(position.shape, dtype=bool)

# Index into output with k_idx as col indices to reset
out[np.arange(k_idx.shape[0])[:,None], k_idx] = 0
  

 The last step involves  advanced-indexing , which might be a big step if you are new to NumPy, but basically here we are using  k_idx  to index into columns and we are forming tuples of indexes to index into rows with the range array of  np.arange(k_idx.shape[0])[:,None] . More info on https://docs.scipy.org/doc/numpy-1.10.1/reference/arrays.indexing.html#advanced-indexing. 

 We could improve on performance by using https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.argpartition.html instead of  argsort , like so - 

  k_idx = np.argpartition(position, N)[:,:N]
  

 Sample input, output for a case to set lowest  3  elements per row as False - 

  In [227]: position
Out[227]: 
array([[36, 63,  3, 78, 98],
       [75, 86, 63, 61, 79],
       [21, 12, 72, 27, 23],
       [38, 16, 17, 88, 29],
       [93, 37, 48, 88, 10]])

In [228]: out
Out[228]: 
array([[False, False, False,  True,  True],
       [False,  True, False, False,  True],
       [False, False,  True,  True, False],
       [ True, False, False,  True, False],
       [ True, False, False,  True, False]], dtype=bool)
  



