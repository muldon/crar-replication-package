Query: Extracting specific src attributes from script tags
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/18733160)
 Get 'src' from script node. 

  import requests 
from bs4 import BeautifulSoup

r  = requests.get("http://rediff.com/")
data = r.text
soup = BeautifulSoup(data)
for n in soup.find_all('script'):
    print "src:", n.get('src') <==== 
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/18737726)
 This should work, you just filter to find all the script tags, then determine if they have a 'src' attribute. If they do then the URL to the javascript is contained in the src attribute, otherwise we assume the javascript is in the tag 

  #!/usr/bin/python

import requests 
from bs4 import BeautifulSoup

# Test HTML which has both cases
html = '<script type="text/javascript" src="http://example.com/something.js">'
html += '</script>  <script>some JS</script>'

soup = BeautifulSoup(html)

# Find all script tags 
for n in soup.find_all('script'):

    # Check if the src attribute exists, and if it does grab the source URL
    if 'src' in n.attrs:
        javascript = n['src']

    # Otherwise assume that the javascript is contained within the tags
    else:
        javascript = n.text

    print javascript
  

 This output of this is 

  http://example.com/something.js
some JS
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/18737759)
 It will get all the  src  values only if they are present. Or else it would skip that  <script>  tag 

  from bs4 import BeautifulSoup
import urllib2
url="http://rediff.com/"
page=urllib2.urlopen(url)
soup = BeautifulSoup(page.read())
sources=soup.findAll('script',{"src":True})
for source in sources:
 print source['src']
  

 I am getting following two   src  values as result 

  http://imworld.rediff.com/worldrediff/js_2_5/ws-global_hm_1.js
http://im.rediff.com/uim/common/realmedia_banner_1_5.js
  

 I guess this is what you want. Hope this is useful. 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/18304693)
 I believe your example is very close. You need to use findAll() instead of find() and when you iterate, you switch from src to link. In the below example I switched it to  tag  

 This code is working for me with BeautifulSoup4: 

  url = 'http://www.imdb.com/title/tt%s/' % (id,)
soup = BeautifulSoup(urllib2.urlopen(url).read())
print "before FOR"
for tag in soup.findAll(itemprop="image"): 
    print "inside FOR"
    print(tag['src'])
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/31639516)
 If you only need to get tag(s) with attribute(s), you can use lambda: 

  soup = bs4.BeautifulSoup(YOUR_CONTENT)
  

 
 Tags with attribute 
 



  tags = soup.find_all(lambda tag: 'src' in tag.attrs)
  

  

  tags = soup.find_all(lambda tag: tag.has_attr('src'))
  

 
 Specific tag with attribute 
 



  tag = soup.find(lambda tag: tag.name == 'script' and 'src' in tag.attrs)
  

 
 Etc ... 
 

 Thought it might be useful. 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/19357602)
  from BeautifulSoup import BeautifulSoup
soup = BeautifulSoup(html_string)
for link in soup.findAll('a')
    link['src'] = 'New src'
html_string = str(soup)
  

 I don't particularly like BeautifulSoup but it does the job for you. Try to not over-do your solution if you don't have to, this being one of the simpler things you can do to solve a general issue. 

 That sad, building for the future is equally important but all your 6 requirements can be put down into one,  "I want to change 'src' or all links to X"  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/51024244)
 Check this XPath:  '//a[@class="tag11 tag12"]/@href ' 

  from lxml import html

page = "<div class=\"tag1\"> <div> <a class=\"tag11 tag12\" href=\"http://www.example.com/file1\" title=\"file1\"> linktext  <span class=\"tag3\">.</span> </div> <div> <a class=\"tag11 tag12\" href=\"http://www.example.com/file2\" title=\"file2\"> linktext  <span class=\"tag3\">.</span> </div>"
tree = html.fromstring(page)
links = tree.xpath('//a[@class="tag11 tag12"]/@href')

for link in links:
    print(link)
  

 Output: 

  http://www.example.com/file1
http://www.example.com/file2
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/30994054)
 http://www.crummy.com/software/BeautifulSoup/bs4/doc/#attributes: 

 
   A tag may have any number of attributes. You can access a tagâ€™s
  attributes by treating the tag like a dictionary. 
 

  from bs4 import BeautifulSoup

soup = BeautifulSoup(data)
div = soup.find("div", class_="myself", title=True)
print(div["title"])
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/39055066)
 You don't need any lambdas to filter by attribute, you simply need to set  src=True  etc.. 

  soup = bs4.BeautifulSoup(html)

# Find all with a specific attribute

tags = soup.find_all(src=True)
tags = soup.select("[src]")

# Find all meta with either name or http-equiv attribute.

soup.select("meta[name],meta[http-equiv]")

# find any tags with any name or source attribute.

soup.select("[name], [src]")

# find first/any script with a src attribute.

tag = soup.find('script', src=True)
tag = soup.select_one("script[src]")

# find all tags with a name attribute beginning with foo
# or any src beginning with /path
soup.select("[name^=foo], [src^=/path]")

# find all tags with a name attribute that contains foo
# or any src containing with whatever
soup.select("[name*=foo], [src*=whatever]")

# find all tags with a name attribute that endwith foo
# or any src that ends with  whatever
soup.select("[name$=foo], [src$=whatever]")
  

 You can also use re with find/find_all etc.. 

  import re
# starting with
soup.find_all("script", src=re.compile("^whatever"))
# contains
soup.find_all("script", src=re.compile("whatever"))
# ends with 
soup.find_all("script", src=re.compile("whatever$"))
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/28147382)
 Find the link, for example, by title and get the http://www.crummy.com/software/BeautifulSoup/bs4/doc/#next-sibling-and-previous-sibling: 

  from bs4 import BeautifulSoup


data = """
<div class="...">
 link1.htmltext1
 link2.htmlimportant text to extract
 link3.htmltext3
...
</div>
"""

soup = BeautifulSoup(data)
print soup.find('a', title='title2').next_sibling
  

  

  important text to extract
  



