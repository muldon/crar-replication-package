Query: Strip random characters from url
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/41133442)
 If you just want the last part after the last  & , it's easy: 

  url.split('&')[-1].replace('=', '') + '.html'
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/12262833)
 Python's strip is a little unusual. It removes any characters that match any of those in the argument from either end. 

 I think you need 2  . . One to strip from the beginning and one to strip from the end 

  irb(main):001:0> 'asdf/asdf'.sub(/^[\/]*/, '').sub(/[\/]*$/, '')
=> "asdf/asdf"
irb(main):002:0> 'asdf/asdf'.sub(/^[\/f]*/, '').sub(/[\/f]*$/, '')
=> "asdf/asd"
irb(main):003:0> ' asdf/asdf'.sub(/^[ ]*/, '').sub(/[ ]*$/, '')
=> "asdf/asdf"
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/45297094)
 There are two ways to accomplish what you want. 

 If you know how the string ends:</h3>

 In your example, if You know that the string ends with  .  then all you need to do is: 

  my_string.split('?')[0]
  

 If you don't know how the string ends:</h3>

 In this case you can use urlparse and take everything but the parameters. 

  from urlparse import urlparse

for url is urls:
    p = urlparse(url)
    print p.scheme + p.netloc + p.path
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/41133541)
 You could use https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse to parse the URL and then the query part. Benefit of this approach is that it will work the same if order of query parts are changed or new parts are added: 

  from urllib import parse

urls = [
    'www.example.com?search?q=Term&page=0',
    'www.example.com?search?q=Term&page=1',
    'www.example.com?search?q=Term&page=2'
]

for url in urls:
    parts = parse.urlparse(url)
    query = parse.parse_qs(parts.query)
    print('page{}.html'.format(query['page'][0]))
  

 Output: 

  page0.html
page1.html
page2.html
  

 In above https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse returns  ParseResult  object that contains URL components: 

  >>> from urllib import parse
>>> parts = parse.urlparse('www.example.com/search?q=Term&page=0')
>>> parts
ParseResult(scheme='', netloc='', path='www.example.com/search', params='', query='q=Term&page=0', fragment='')
  

 Then https://docs.python.org/3/library/urllib.parse.html#urllib.parse.parse_qs will return  dict  of query parameters where values are lists: 

  >>> query = parse.parse_qs(parts.query)
>>> query
{'page': ['0'], 'q': ['Term']}
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/11892398)
 Your example JSON doesn't need the comma after the "c_url" k-v pair. 

  >>> import json
>>> st = '{"A":"A value","B":{ "B1":"B1 value", "B2":"B2 value" },"C":{ "c
_url":"http:\/\/someurl:someport\/somefolder\/somefile" }}'
>>> json.loads(st)
{u'A': u'A value', u'C': {u'c_url': u'http://someurl:someport/somefolder/somefile'}, u'B': {u'B1': u
'B1 value', u'B2': u'B2 value'}}
  

 And to get just the 'somefile' part of the URL: 

  url.split('/')[url.count('/')]
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/30507683)
 You can use following regex : 

  \d+_([\w-]+){22}
  

  \w  will match any word character contain alphabetical characters and letters and character  _ .So  [\w-]+  will match any combinations of  \w  and  -  with length 1 or more.  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/21062817)
 To get lines of a file use: 

  lines = open(path,"r").readlines()
  

 To select a random element from, let's say, an array of lines: 

  import random #preferably at the top of the script
myline = random.choice(lines)
  

 To strip the line of harmful newlines and spaces: 

  cleanline = line.strip()
  

 To repeat your task: 

  br=mechanize.Browser()
br.set_handle_robots(False)

def open_page(url,agent,proxy):
    changeuseragent(agent.strip()) # pass br here, or move above lines out
    addproxy(proxy.strip()) # into the global scope
    changecookie()

    return br.open(url)

# if script is executed, not imported. This line below is common magic.
if __name__=="__main__": 
    # TODO: open your files
    somelines = file(path,"r").readlines()
    #
    running = True
    while running:
        # TODO: select a line
        oneline = random.choice(lines)
        secondline = random.choice(otherlines)
        #
        f = open_page(your_url,agentline,proxyline)
        print f.read() #<or do whatever you wish
        f.close() #<not necessary

        running = raw_input("x and enter to exit: ").lower().startswith("x")
    # And on it goes.
  

 Edit: I've added some pseudocode. You need to modify more-or-less-obvious lines. 

 On topic: Loop like above is very common in interactive console scripts. 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/22741099)
 The  strip()  method takes whatever string you have and removes trailing whitespaces and newline characters 

  >>> '   asdfadsf '.strip()
'asdfadsf'

>>> '\nblablabla\n'.strip()
'blablabla'

>>> a = []
>>> a.append('   \n asdf \n    '.strip())
>>> a
['asdf']

>>> words = [' a ', '   b    ', '\nc\n']
>>> words = [word.strip() for word in words]
>>> words
['a', 'b', 'c']
  

 Updated Answer to Updated Question 

  from urllib import urlopen

WORD_URL = 'http://learncodethehardway.org/words.txt'
WORDS = []
word_list = urlopen(WORD_URL)
word_list = word_list.readlines()
print word_list                      # before strip()
for word in word_list:
    WORDS.append(word.strip())
print WORDS                          # after strip(), so you get an idea of what strip() does
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/33295089)
  import random


r = random.SystemRandom()


def generate_password(words, top=2000, k=4, numbers=None, characters=None,
                      first_upper=True):
    """Return a random password based on a sorted word list."""
    elements = r.sample(words[:top], k)

    if numbers:
        elements.insert(r.randint(1, len(elements)), r.choice(numbers))
    if characters:
        elements.insert(r.randint(1, len(elements)), r.choice(characters))
    if first_upper:
        elements[0] = elements[0].title()

    return ''.join(elements)


if __name__ == '__main__':
    with open('./google-10000-english-usa.txt') as f:
        words = [w.strip() for w in f]
    print(generate_password(words, numbers='0123456789', characters='!@#$%'))
  

 
 Generates passwords that you can remember 
 Uses  os.urandom()  
 Handles real-world rules like adding numbers, uppercase, characters. 
 

 Sure it can be improved, but this is what I use. 


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/4298271)
 Just because no one used  map  yet: 

  import random
''.join(map(lambda x:x+' '*random.randint(0,1), s)).strip()
  



