Query: Delete every non utf-8 symbols froms string
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/41477808)
 Example to handle no utf-8 characters 

  import string

test=u"\n\n\n\n\n\n\n\n\n\n\n\n\n\nHi <<First Name>>\nthis is filler text \xa325 more filler.\nadditilnal filler.\n\nyet more\xa0still more\xa0filler.\n\n\xa0\n\n\n\n\nmore\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfiller.\x03\n\t\t\t\t\t\t    almost there \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nthe end\n\n\n\n\n\n\n\n\n\n\n\n\n"

print ''.join(x for x in test if x in string.printable)
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/26549192)
 Try below code line instead of last two lines.  

  line=line.decode('utf-8','ignore').encode("utf-8")
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/43650015)
 For python 3, as mentioned in a comment in this thread, you can do: 

  line = bytes(line, 'utf-8').decode('utf-8', 'ignore')
  

 The 'ignore' parameter prevents an error from being raised if any characters are unable to be decoded. 

 If your line is already a bytes object (e.g.  b'my string' ) then you just need to decode it with  decode('utf-8', 'ignore') . 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/43956444)
 I had a similar problem (Python 3). You could try something like this. 

  text = u'aweerwq\u0645\u0631\u062d\u0628\u0627\u043c\u0438\u0440'
stripped_text = ''
for c in text:
   stripped_text += c if len(c.encode(encoding='utf_8'))==1 else ''
print(stripped_text)
aweerwq
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/32812416)
 You can try to decode the file as UTF-8 ignoring any errors, and then re-encoding it in UTF-8. 

  string.decode('utf-8', errors='ignore').encode('utf-8')
  

 Or you could replace the characters with an appropriate sequence (which can then be removed), see also https://stackoverflow.com/questions/3220031/how-to-filter-or-replace-unicode-characters-that-would-take-more-than-3-bytes: 

  string.decode('utf-8', errors='replace').encode('utf-8')
  

 But you should really determine which encoding your data is in, and convert it appropriately.  iconv  might help. 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/25138321)
 
   What I'm trying to do is print utf-8 card symbols (♠,♥,♦,♣) from a python module to a windows console 
 

 UTF-8 is a byte encoding of Unicode characters. ♠♥♦♣ are Unicode characters which can be reproduced in a variety of encodings and UTF-8 is one of those encodings—as a UTF, UTF-8 can reproduce any Unicode character. But there is nothing specifically “UTF-8” about those characters. 

 Other encodings that can reproduce the characters ♠♥♦♣ are Windows http://en.wikipedia.org/wiki/Code_page_850 and http://en.wikipedia.org/wiki/Code_page_437, which your console is likely to be using under a Western European install of Windows. You can print ♠ in these encodings but you are not using UTF-8 to do so, and you won't be able to use other Unicode characters that are available in UTF-8 but outside the scope of these code pages. 

  print(u'♠')
UnicodeEncodeError: 'charmap' codec can't encode character '\u2660'
  

 In Python 3 this is the same as the  print('♠')  test you did above, so there is something different about how you are invoking the script containing this  print , compared to your  py -3.4 . What does  sys.stdout.encoding  give you from the script? 

 To get  print  working correctly you would have to make sure Python picks up the right encoding. If it is not doing that adequately from the terminal settings you would indeed have to set  PYTHONIOENCODING  to  cp437 . 

  >>> text = '♠'
>>> print(text.encode('utf-8'))
b'\xe2\x99\xa0'
  

  print  can only print Unicode strings. For other types including the  bytes  string that results from the  encode()  method, it gets the literal representation ( repr ) of the object.  b'\xe2\x99\xa0'  is how you would write a Python 3 bytes literal containing a UTF-8 encoded ♠. 

 If what you want to do is bypass  print 's implicit encoding to PYTHONIOENCODING and substitute your own, you can do that explicitly: 

  >>> import sys
>>> sys.stdout.buffer.write('♠'.encode('cp437'))
  

 This will of course generate wrong output for any consoles not running code page 437 (eg non-Western-European installs). Generally, for apps using the C stdio, like Python does, getting non-ASCII characters to the Windows console is just too unreliable to bother with. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/1789319)
 This does work for me: 

  pdf = pisa.pisaDocument(StringIO.StringIO(html.encode("UTF-8")), result, encoding='UTF-8')
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/33329202)
 
   addresse1=unicodedata.normalize('NFKD', addresse1).encode('utf-8','ignore')  
 

 You probably meant  .encode('ascii', 'ignore') , to remove non-ASCII characters. UTF-8 contains all characters, so encoding to it doesn't get rid of any, and an encode-decode cycle with it is a no-op. 

 
    
 

 . 

 If you only want to remove diacritical marks and not lose all other non-ASCII characters, you could read  unicodedata.category  for each character after NFKD-normalising and remove those in category M. 

 If you want to transliterate to ASCII that becomes a language-specific question that requires custom replacements (for example in German  ö  becomes  oe , but not in Swedish). 

 If you just want to fudge a string into ASCII because having non-ASCII characters in it causes some code to break, it is of course much better to fix that code to work properly with all Unicode characters than to mangle good data. The letter  è  is not encodable in ASCII, but neither are 99.9989% of all characters so that hardly makes it “special”. Code that only supports ASCII is lame. 

 The Google Geocoding API can work with Unicode perfectly well so there is no obvious reason you should need to do any of this. 

 ETA: 

  url2= 'maps.googleapis.com/maps/api/geocode/json?address=' + addresse1 ...
  

 Ah, you need to URL-encode any data you inject into a URL. That's not just for Unicode — the above will break for many ASCII punctuation symbols too. Use  urllib.quote  to encode a single string, or  urllib.encode  to convert multiple parameters: 

  params = dict(
    address=address1.encode('utf-8'),
    key=googlekey
)
url2 = '...?' + urllib.urlencode(params)
  

 (in Python 3 it's  urllib.parse.quote  and  urllib.parse.encode  and they automatically choose UTF-8 so you don't have to manually encode there.) 

  data2 = urllib.request.urlopen(url2).read().decode('utf-8')
data3=json.loads(data2)
  

  json.loads  reads byte strings so you should be safe to omit the UTF-8 decode. Anyway  json.load  will read directly from a file-like object so you shouldn't have to load the data into a string at all: 

  data3 = json.load(urllib.request.urlopen(url2))
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/1637287)
  

  pdf = pisa.pisaDocument(StringIO.StringIO(html.encode("UTF-8")), result)
  

  

  pdf = pisa.pisaDocument(StringIO.StringIO(html), result, encoding='UTF-8')
  

 Or checkout this answer to https://stackoverflow.com/questions/1377446/html-to-pdf-for-a-django-site/1377652#1377652 


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/13078030)
 In order to convert it to UTF-8, you need to know what encoding it's in.  Based on your description, I'm guessing that it's in one of the Latin-1 variants, ISO 8859-1 or Windows-1252.  If that's the case, then you could convert it to UTF-8 like so: 

  data = 'Copyright \xA9 2012'  # \xA9 is the copyright symbol in Windows-1252

# Convert from Windows-1252 to UTF-8
encoded = data.decode('Windows-1252').encode('utf-8')

# Prints "Copyright © 2012"
print encoded
  



