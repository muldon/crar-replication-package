Query: Python pandas: check if any value is NaN in DataFrame
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/47377251)
 To find out which rows have NaNs in a specific column: 

  nan_rows = df[df['name column'].isnull()]
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/29530303)
  df.isnull().any().any()  should do it. 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/37442692)
 If you need to know how many rows there are with "one or more  NaN s": 

  df.isnull().T.any().T.sum()
  

 Or if you need to pull out these rows and examine them: 

  nan_rows = df[df.isnull().T.any().T]
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/47066932)
 Just using
https://docs.python.org/3/library/math.html#math.isnan, Return True if x is a NaN (not a number), and False otherwise. 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/45829208)
 Adding to Hobs brilliant answer, I am very new to Python and Pandas so please point out if I am wrong. 

 To find out which rows have NaNs: 

  nan_rows = df[df.isnull().any(1)]
  

 would perform the same operation without the need for transposing by specifying the axis of any() as 1 to check if 'True' is present in rows.  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/52043227)
 Here is another interesting way of finding null and replacing with a calculated value 

      #Creating the DataFrame

    testdf = pd.DataFrame({'Tenure':[1,2,3,4,5],'Monthly':[10,20,30,40,50],'Yearly':[10,40,np.nan,np.nan,250]})
    >>> testdf2
       Monthly  Tenure  Yearly
    0       10       1    10.0
    1       20       2    40.0
    2       30       3     NaN
    3       40       4     NaN
    4       50       5   250.0

    #Identifying the rows with empty columns
    nan_rows = testdf2[testdf2['Yearly'].isnull()]
    >>> nan_rows
       Monthly  Tenure  Yearly
    2       30       3     NaN
    3       40       4     NaN

    #Getting the rows# into a list
    >>> index = list(nan_rows.index)
    >>> index
    [2, 3]

    # Replacing null values with calculated value
    >>> for i in index:
        testdf2['Yearly'][i] = testdf2['Monthly'][i] * testdf2['Tenure'][i]
    >>> testdf2
       Monthly  Tenure  Yearly
    0       10       1    10.0
    1       20       2    40.0
    2       30       3    90.0
    3       40       4   160.0
    4       50       5   250.0
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/49229688)
 For those search because wish to know on the question title:  

 
   Check if all columns in rows value is NaN 
 

 A simple approach would be: 

  df[[list_of_cols_to_check]].isnull().apply(lambda x: all(x), axis=1) 
  

 

  import pandas as pd
import numpy as np


df = pd.DataFrame({'movie': [np.nan, 'thg', 'mol', 'mol', 'lob', 'lob'],
                  'rating': [np.nan, 4., 5., np.nan, np.nan, np.nan],
                  'name':   ['John', np.nan, 'N/A', 'Graham', np.nan, np.nan]}) 
df.head()
  

 https://i.stack.imgur.com/On8y8.png 

 

 To check if all columns is NaN:  

  cols_to_check = df.columns
df['is_na'] = df[cols_to_check].isnull().apply(lambda x: all(x), axis=1) 
df.head() 
  

 <a href="https://i.stack.imgur.com/21meZ.png"  

 

 To check if columns 'name', 'rating' are NaN: 

  cols_to_check = ['name', 'rating']
df['is_na'] = df[cols_to_check].isnull().apply(lambda x: all(x), axis=1) 
df.head()  
  

 <a href="https://i.stack.imgur.com/WErgC.png"  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/48727544)
 You can use built in pandas functionality for this. To illustrate: 

  import pandas as pd
import numpy as np

df = pd.DataFrame({'col1': np.random.rand(100),
              'col2': np.random.rand(100)})

# create a nan value in the 10th row of column 2
df.loc[10, 'col2'] = np.nan

pd.isnull(df.loc[10, :]) # will give true for col2
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/29530559)
 You have a couple of options.  

  import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randn(10,6))
# Make a few areas have NaN values
df.iloc[1:3,1] = np.nan
df.iloc[5,3] = np.nan
df.iloc[7:9,5] = np.nan
  

 Now the data frame looks something like this: 

            0         1         2         3         4         5
0  0.520113  0.884000  1.260966 -0.236597  0.312972 -0.196281
1 -0.837552       NaN  0.143017  0.862355  0.346550  0.842952
2 -0.452595       NaN -0.420790  0.456215  1.203459  0.527425
3  0.317503 -0.917042  1.780938 -1.584102  0.432745  0.389797
4 -0.722852  1.704820 -0.113821 -1.466458  0.083002  0.011722
5 -0.622851 -0.251935 -1.498837       NaN  1.098323  0.273814
6  0.329585  0.075312 -0.690209 -3.807924  0.489317 -0.841368
7 -1.123433 -1.187496  1.868894 -2.046456 -0.949718       NaN
8  1.133880 -0.110447  0.050385 -1.158387  0.188222       NaN
9 -0.513741  1.196259  0.704537  0.982395 -0.585040 -1.693810
  

 
  Option 1 :  df.isnull().any().any()  - This returns a boolean value 
 

 You know of the  isnull()  which would return a dataframe like this: 

         0      1      2      3      4      5
0  False  False  False  False  False  False
1  False   True  False  False  False  False
2  False   True  False  False  False  False
3  False  False  False  False  False  False
4  False  False  False  False  False  False
5  False  False  False   True  False  False
6  False  False  False  False  False  False
7  False  False  False  False  False   True
8  False  False  False  False  False   True
9  False  False  False  False  False  False
  

 If you make it  df.isnull().any() , you can find just the columns that have  NaN  values: 

  0    False
1     True
2    False
3     True
4    False
5     True
dtype: bool
  

   .any()  will tell you if any of the above are  True  

  > df.isnull().any().any()
True
  

 
  Option 2 :  df.isnull().sum().sum()  - This returns an integer of the total number of  NaN  values: 
 

 This operates the same way as the  .any().any()  does, by first giving a summation of the number of  NaN  values in a column, then the summation of those values: 

  df.isnull().sum()
0    0
1    2
2    0
3    1
4    0
5    2
dtype: int64
  

 Finally, to get the total number of NaN values in the DataFrame: 

  df.isnull().sum().sum()
5
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/52884094)
 Or (check for NaN's with  isnull , then use  ~  to make the opposite to no NaN's): 

  df=df[~df['EPS'].isnull()]
  

  

  print(df)
  

  

                   STK_ID  EPS  cash
STK_ID RPT_Date
600016 20111231  600016  4.3   NaN
601939 20111231  601939  2.5   NaN
  



