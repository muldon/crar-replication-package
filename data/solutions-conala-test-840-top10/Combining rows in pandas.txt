Query: Combining rows in pandas
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/46695138)
  

  df = df.apply(lambda x: x.str.strip()).replace('',np.nan)

df.groupby(df.col_1.ffill())\
  .agg({'col_2': lambda x: ' '.join(x) ,'col_3':'first'})\
  .reset_index()
  

 Output: 

         col_1                                             col_2   col_3
0  Non-Saved  www.google.com www.facebook.com www.linkedin.com  20,567
1      Saved                       www.Quora.com www.gmail.com   6,337
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/39883694)
 Use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.combine_first.html: 

  print (df1.combine_first(df2))
       A      B      C      D
0   22.0   23.0   24.0   25.0
1    2.0    4.0    6.0    8.0
2   56.0   58.0   59.0   60.0
3  100.0  101.0  102.0  103.0
  

 Or http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html: 

  print (df1.fillna(df2))
       A      B      C      D
0   22.0   23.0   24.0   25.0
1    2.0    4.0    6.0    8.0
2   56.0   58.0   59.0   60.0
3  100.0  101.0  102.0  103.0
  

 Or http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.update.html: 

  df1.update(df2)
print (df1)
       A      B      C      D
0   22.0   23.0   24.0   25.0
1    2.0    4.0    6.0    8.0
2   56.0   58.0   59.0   60.0
3  100.0  101.0  102.0  103.0
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/51999667)
 You could use  str.cat ,  iloc  slicing and  rename  

  In [1008]: df.iloc[2:].rename(columns=df.iloc[:2].apply(lambda x: x.str.cat(sep=' ')))
Out[1008]:
    A D    B      E    C F
2   one  two  three   four
3  five  six    sev  egght
  

 

  

  In [1012]: df.iloc[:2].apply(lambda x: x.str.cat(sep=' '))
Out[1012]:
0    A D
1      B
2      E
3    C F
dtype: object
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/51998886)
 You can select first 2 rows by http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html and replace  NaN s by http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html. 

 Then join by space, but need remove trailing whitespaces by http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.strip.html: 

  cols = df.iloc[:2].fillna('')
df.columns = (cols.iloc[0] + ' ' + cols.iloc[1]).str.strip()

df = df.iloc[2:]
print (df)
    A D    B      E    C F
2   one  two  three   four
3  five  six    sev  egght
  

 Or better join all non  NaN s values with http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html: 

  df.columns = df.iloc[:2].apply(lambda x: ' '.join(x.dropna()))
df = df.iloc[2:]
print (df)
    A D    B      E    C F
2   one  two  three   four
3  five  six    sev  egght
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/40274752)
 If you read your file in with  pd.read_excel  and pass  header=None , the blank rows should be included: 

  In [286]: df = pd.read_excel("test.xlsx", header=None)

In [287]: df
Out[287]:
           0     1      2
0        NaN   NaN    NaN
1        NaN   NaN    NaN
2  something   NaN    NaN
3        NaN   NaN    NaN
4       name  date  other
5          1     2      3
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/39883697)
 Use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.combine_first.html 

  df1.combine_first(df2)
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/39257573)
  xdf = extras_table.set_index(['main_id', 'col_label']) \
    .unstack().value.reset_index('main_id')

main_table.merge(xdf, left_on='id', right_on='main_id').drop('main_id', axis=1)
  

 https://i.stack.imgur.com/uPy0S.png 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/43539969)
 we can use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.nlargest.html method: 

  In [31]: new = df.nlargest(3, columns='count')

In [32]: new = pd.concat(
    ...:         [new,
    ...:          pd.DataFrame({'character':['others'],
    ...:                        'count':df.drop(new.index)['count'].sum()})
    ...:         ], ignore_index=True)
    ...:

In [33]: new
Out[33]:
  character  count
0         c    210
1         e    189
2         a    104
3    others     60
  

  

  In [16]: new = df.nlargest(3, columns='count')

In [17]: new.loc[len(new)] = ['others', df.drop(new.index)['count'].sum()]

In [18]: new
Out[18]:
  character  count
2         c    210
4         e    189
0         a    104
3    others    100
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/46699201)
 If the previous https://stackoverflow.com/a/46695138/6361531, then let's try this one: 

  l = lambda x: ' , '.join(x.unique())

df = df.apply(lambda x: x.str.strip()).replace('',np.nan)

print(df.groupby(df.col_1.ffill())\
  .agg({'col_2': l,'col_3': l, 'col_4':'first'})\
  .reset_index())
  

 Output: 

         col_1                                              col_2  \
0  Non-Saved  www.google.com , www.facebook.com , www.linked...   
1      Saved                      www.Quora.com , www.gmail.com   

                col_3   col_4  
0  POST , GET , OTHER  20,567  
1          POST , GET   6,337  
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/41128243)
 Could try something as this, you need to drop missing values before using the  join  function: 

  df.groupby(["ID", "name", "Town"], as_index=False).agg(lambda col: ','.join(col.dropna()))

#   ID  name    Town    s1     s2    s3    s4
#0  21   Joe    Bonn    rd  fd,hg    kk    aa
#1  22   Ann    Oslo    jg     hg    zt    uz
#2  29   Mya    Rome    rd     fd          aa
  



