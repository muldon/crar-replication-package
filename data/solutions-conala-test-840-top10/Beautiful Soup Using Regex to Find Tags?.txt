Query: Beautiful Soup Using Regex to Find Tags?
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/24748460)
 yes see docs... 

 http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html 

  import re

soup.findAll(re.compile("^a$|(div)"))
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/47091570)
 Note that you can also use regular expressions to search  in attributes of tags . For example: 

  import re
from bs4 import BeautifulSoup

soup.find_all('a', {'href': re.compile(r'crummy\.com/')})
  

 This example finds all  <a>  tags that link to a website containing the substring  'crummy.com' . 

 (I know this is a very old post, but hopefully someone will find this additional information useful.) 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/24748491)
 http://www.crummy.com/software/BeautifulSoup/bs4/doc/ is the most favored method in the Beautiful Soup search API.  

 You can pass a variation of filters. Also, pass a http://www.crummy.com/software/BeautifulSoup/bs4/doc/#a-list to find multiple tags: 

  >>> soup.find_all(['a', 'div']) 
  

  Example : 

  >>> from bs4 import BeautifulSoup
>>> soup = BeautifulSoup('<html><body><div>asdfasdf</div> <a>foo  </body></html>')
>>> soup.find_all(['a', 'div'])
[<div>asdfasdf</div>, <a>foo ]
  

 Or you can use a http://www.crummy.com/software/BeautifulSoup/bs4/doc/#a-regular-expression to find tags that contain  a  or  div : 

  >>> import re
>>> soup.find_all(re.compile("(a|div)"))
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/36108895)
 You don't have to specify any arguments to  find_all()  - in this case,  BeautifulSoup  would find you every tag in the tree, recursively.  

  >>> from bs4 import BeautifulSoup
>>>
>>> html = """<div>something</div>
... <div>something else</div>
... <div class='magical'>hi there</div>
...  ok """
>>> soup = BeautifulSoup(html, "html.parser")
>>> [tag.name for tag in soup.find_all()]
[u'div', u'div', u'div', u'p']
>>> [str(tag) for tag in soup.find_all()]
['<div>something</div>', '<div>something else</div>', '<div class="magical">hi there</div>', ' ok ']
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/11924175)
 Know your documentation 

 http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html 

  soup.findAll(id=re.compile("para$"))
# [<p id="firstpara" align="center">This is paragraph <b>one</b>. ,
#  <p id="secondpara" align="blah">This is paragraph <b>two</b>. ]
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/11924161)
 You can use regular expressions (this example matches on the tag names, you need to adjust it so it matches on an element's id): 

  import re
for tag in soup.find_all(re.compile("^value_xxx_c_1_f_8_a_")):
    print(tag.name)
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/13024215)
 You should try to see the  repr  of the string: 

  >>> a=r""" <a href=\"/accurate-data/210-0023.prd?pageLevel=&amp;skuId=210-0023\">more-accurate-data  """
>>> print repr(a)
' <a href=\\"/accurate-data/210-0023.prd?pageLevel=&amp;skuId=210-0023\\">more-accurate-data  '
  

 And the regex works with this representation: 

  >>> regex = re.compile(r""" <a href=\\"/accurate(.*?)\\">""")
>>> regex.match(a)
<_sre.SRE_Match object at 0x20fbf30>
  

 The problem is that the result from beautiful soup is different, because you did not print its repr. When dealing with regexes it's a good idea to check the  repr  of the strings involved to avoid things like this. 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/8934072)
 Just pass it as an argument of  findAll : 

  >>> from BeautifulSoup import BeautifulSoup
>>> soup = BeautifulSoup("""
... <html>
... <head><title>My Title!</title></head>
... <body><table>
... <tr><td>First!</td>
... <td valign="top">Second!</td></tr>
... </table></body><html>
... """)
>>>
>>> soup.findAll('td')
[<td>First!</td>, <td valign="top">Second!</td>]
>>>
>>> soup.findAll('td', valign='top')
[<td valign="top">Second!</td>]
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/45062691)
 Filter by regular expression: 

  soup.find_all(re.compile('^h[1-6]$'))
  

 This regex finds all tags that start with  h , have a digit after the  h , and then end after the digit. 


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/42555257)
 I would search for a  td  object then use a  regex  pattern to filter the data that you need, instead of using  re.compile  in the  find_all  method.  

  

  import re
from bs4 import BeautifulSoup

example = """<td><b>First Type :</b>W <b>Second Type :</b>65 <b>Third 
Type :</b>3</td>
<td><b>First Type :</b> <b>Second Type :</b>69 <b>Third Type :</b>6</td>"""

soup = BeautifulSoup(example, "html.parser")

for o in soup.find_all('td'):
    match = re.findall(r'</b>\s*(.*?)\s*(<br|</br)', str(o))
    print ("%s,%s,%s" % (match[0][0],match[1][0],match[2][0]))
  

 This pattern finds all text between the  </b>  tag and     or     tags. The     tags are added when converting the soup object to string. 

 This example outputs: 

 
   
     
       W,65,3 
      
       ,69,6 
     
   
 

 Just an example, you can alter to return an empty string if one of the regex matches is empty. 



