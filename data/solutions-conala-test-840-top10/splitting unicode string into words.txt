Query: splitting unicode string into words
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/14498531)
 try adding  'u'  to the  '\u2013'  as  metatry['content']  is a unicode string: 

  u"Samsung Galaxy Note II \u2013 Latest Smartphone in India ".split(u'\u2013')
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/7286969)
 You're actually getting the stuff you expect in the unicode case. You only think you are not because of the weird escaping due to the fact that you're looking at the  reprs  of the strings, not not printing their unescaped values. (This is just how lists are displayed.) 

  >>> words = [u'\u0440\u0430\u0437', u'\u0434\u0432\u0430', u'\u0442\u0440\u0438'] 
>>> for w in words:
...     print w # This uses the terminal encoding -- _only_ utilize interactively
... 
раз
два
три
>>> u'раз' == u'\u0440\u0430\u0437'
True
  

 Don't miss my remark about printing these unicode strings. Normally if you were going to send them to screen, a file, over the wire, etc. you need to manually encode them into the correct encoding. When you use  print , Python tries to leverage your terminal's encoding, but it can only do that if there is a terminal. Because you don't generally know if there is one, you should only rely on this in the interactive interpreter, and always encode to the right encoding explicitly otherwise. 

 In this simple splitting-on-whitespace approach, you might not want to use regex at all but simply to use the  unicode.split  method. 

  >>> u"раз два три".split()
[u'\u0440\u0430\u0437', u'\u0434\u0432\u0430', u'\u0442\u0440\u0438']
  

 Your top (bytestring) example does not work because  re  basically assumes all bytestrings are ASCII for its semantics, but yours was not. Using unicode strings allows you to get the right semantics for your alphabet and locale. As much as possible, textual data should always be represented using  unicode  rather than  str . 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/8928687)
 You can use a regular expression with enabled Unicode matching: 

  >>> re.split(r'(?u)\s', u'a\u200bc d')
[u'a', u'c', u'd']
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/8928710)
  Edit  

 It turns out that \u200b is not technically defined as whitespace , and so python does not recognize it as matching \s even with the unicode flag on. So it must be treated as an non-whitespace character. 

<p 

<p 

  import re

re.split(ur"[\u200b\s]+", "some string", flags=re.UNICODE)
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/8928705)
 You can use http://docs.python.org/library/re.html#re.split, like this: 

  import re
re.split(u'\s|\u200b', your_string)
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/8928714)
 Can you use something like this? 

  re.split(r'\s+', your_string, re.UNICODE)
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/8930959)
 Here is a Unicode-aware version: 

  re.findall(r"\w+|[^\w\s]", text, re.UNICODE)
  

 The first alternative catches sequences of word characters (as defined by unicode, so "résumé" won't turn into  ['r', 'sum'] ); the second catches individual non-word characters, ignoring whitespace. 

 Note that, unlike the top answer, this treats the single quote as separate punctuation (e.g. "I'm" ->  ['I', "'", 'm'] ). This appears to be standard in NLP, so I consider it a feature. 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/51310232)
 You can use regex to group the characters. Here is a sample code for doing so: 

  import re
pattern = re.compile(r'(\w[\u02F3\u1D53\u0300\u2013\u032E\u208D\u203F\u0311\u0323\u035E\u031C\u02FC\u030C\u02F9\u0328\u032D:\u02F4\u032F\u0330\u035C\u0302\u0327\u03572\u0308\u0351\u0304\u02F2\u0352\u0355\u00B7\u032C\u030B\u2019\u0339\u00B4\u0301\u02F1\u0303\u0306\u030A7\u0325\u0307\u0354`\u02F0]+|\w|\W)', re.UNICODE | re.IGNORECASE)
  

 In case you had some accents missing, add them the pattern. 

 Then, you can split words into characters as follows. 

  print(list(pattern.findall('šnjiwgetit')))
['š', 'n', 'j', 'i', 'w', 'g', 'e', 't', 'i', 't'
print(list(pattern.findall('h̭ɛ̮ŋkkɐᴅ')))
['h̭', 'ɛ̮', 'ŋ', 'k', 'k', 'ɐ', 'ᴅ']
  

 If you are using Python2, add  from __future__ import unicode_literals  at the beginning of the file. 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/8929085)
 Just use  split : 

  >>> u'\u200b'.isspace()
True
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/8928590)
 You can use the 're' module and pass a separator to 'split': http://docs.python.org/library/re.html#re.split 



