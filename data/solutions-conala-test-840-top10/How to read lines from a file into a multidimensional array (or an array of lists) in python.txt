Query: How to read lines from a file into a multidimensional array (or an array of lists) in python
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/1532899)
 Batteries included: 

  >>> import csv
>>> array = list( csv.reader( open( r'./urls-eu.csv' ) ) )
>>> array[0]
['a', '3', '4', '2', '1']
>>> array[1]
['3', '2', '1', 'a', '2']
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/1532816)
  

  arr = [line.split(',') for line in open('./urls-eu.csv')]
  

 it iteratively process file line by line, splits each line by comma and accumulates resulting lists into a list of lists. you can drop opening mode ( 'r' ) since it's a default one. 


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/11941028)
 In python there is no need to declare list size on forehand.  

 an example of reading lines to a file could be this: 

  file_name = "/path/to/file"
list = []

with open(file_name) as file:
  file.readline
  if criteria:
    list.append(line)
  

 For multidimensional lists. create the inner lists in a function on and return it to the append line.  

  def returns_list(line):
  multi_dim_list = []
  #do stuff
  return multi_dim_list
  

 exchange the last row in the first code with 

  list.append(returns_list(line))
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/18010155)
 If you don't need a human-readable output, another option you could try is to save the array as a MATLAB  .mat  file, which is a structured array. I despise MATLAB, but the fact that I can both read and write a  .mat  in very few lines is convenient.  

 Unlike Joe Kington's answer, the benefit of this is that you  don't need to know the original shape of the data  in the  .mat  file, i.e. no need to reshape upon reading in. And, unlike using  pickle , a  .mat  file can be read by MATLAB, and probably some other programs/languages as well.  

 Here is an example: 

  import numpy as np
import scipy.io

# Some test data
x = np.arange(200).reshape((4,5,10))

# Specify the filename of the .mat file
matfile = 'test_mat.mat'

# Write the array to the mat file. For this to work, the array must be the value
# corresponding to a key name of your choice in a dictionary
scipy.io.savemat(matfile, mdict={'out': x}, oned_as='row')

# For the above line, I specified the kwarg oned_as since python (2.7 with 
# numpy 1.6.1) throws a FutureWarning.  Here, this isn't really necessary 
# since oned_as is a kwarg for dealing with 1-D arrays.

# Now load in the data from the .mat that was just saved
matdata = scipy.io.loadmat(matfile)

# And just to check if the data is the same:
assert np.all(x == matdata['out'])
  

 If you forget the key that the array is named in the  .mat  file, you can always do: 

  print matdata.keys()
  

 And of course you can store many arrays using many more keys. 

 So yes â€“ it won't be readable with your eyes, but only takes 2 lines to write and read the data, which I think is a fair trade-off. 

 Take a look at the docs for http://docs.scipy.org/doc/scipy/reference/generated/scipy.io.savemat.html
and http://docs.scipy.org/doc/scipy/reference/generated/scipy.io.loadmat.html
and also this tutorial page: http://docs.scipy.org/doc/scipy/reference/tutorial/io.html 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/19056145)
 Use a list comprehension and  str.split : 

  with open("textFile.txt") as textFile:
    lines = [line.split() for line in textFile]
  

    

  >>> with open("textFile.txt") as textFile:
        lines = [line.split() for line in textFile]
...     
>>> lines
[['Hello', 'World'], ['How', 'are', 'you?'], ['Bye', 'World']]
  

 http://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files: 

 
   It is good practice to use the  with  keyword when dealing with file
  objects. This has the advantage that the file is properly closed after
  its suite finishes, even if an exception is raised on the way. It is
  also much shorter than writing equivalent try-finally blocks. 
 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/33557897)
 The following code will give you the results you want: 

  import re

dim3 = []
dim2 = []
f = open ('inputfile.txt', 'r')
for s in f.readlines():
    s = s.strip()
    if s == '':
        dim3.append(dim2)
        dim2 = []
    else:
        dim1 = re.split('\s+', s)
        dim2.append(dim1)
if len(dim2) > 0:
    dim3.append(dim2)
f.close()

print(dim3)
  

 It basically maintains  dim2/3  dimension variables to hold the values, and the  dim1  dimension variable to handle each line. 

 For each non-blank line, we calculate the array  dim1  and add it to the current  dim2 . If we find a blank line, we add the current  dim2  to  dim3  and reset  dim2 . 

 At the end, we handle any leftover  dim2  and the resultant  dim3  is the multi-dimensional array that you desired (formatted for readability): 

  [[['6'  , '5.9'], ['6.3', '5.9'], ['6.6', '6.3']],
 [['7.8', '7.5'], ['7.8', '7.3'], ['7.5', '7.6']],
 [['8.3', '8'  ], ['8.5', '8'  ], ['8.2', '8.3']],
 [['9.2', '8.5'], ['9'  , '8.5'], ['9.2', '8.9']]]
  

 The code is such that it will handle arbitrary dimension sizes, in the sense that it allows any quantity of numbers-per-line, lines-per-group and groups-per-file. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/19744744)
 This can be handled much more elegantly using  split  without any arguments for each line: 

  f = open('Sample Data.txt',"r")
num = 0
for line_number, line in enumerate(f):
    if (line_number < 109):
        #jump over lines at the beginning
        continue
    # now split the line everywhere there are one or more whitespaces:
    numbers_as_strings = line.split()
    # and convert the numbers to floats
    numbers = list(map(float, numbers_as_strings))
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/33557862)
 First you read the data from the file 1 line at a time.  Then for every empty line you start a new array.  Otherwise you split the current array on  spaces  and append it to the return value. 

 You can use this code: 

  ret = []                                 #return value
with open('data.txt', 'r') as f:         #open file
    curArray = []                        #start current array
    for line in f:                       #loop through the lines
        line = line.rstrip()             #get rid of \n
        if len(line) == 0:               #if its an empty line
            ret.append(curArray)         #  append curArray to ret
            curArray = []                #  reset curArray
        else:
            numbers = line.split(' ')    #split array on spaces
            curArray.append(numbers)     #append new array to the curArray
print ret
  

 This code assumes each line should be an array and each time there is an empty line (with only a newline character) a new array is started. 

 To get the sum of a column across all arrays write a function that takes the array and the index of the column you want to sum: 

  def sumColumn(arr3d, index):
    sum = 0
    for arr in arr3d:
        for arr2 in arr:
            sum+=float(arr2[index])
    return sum

#now print the sum of the first column using the initial data file.
print sumColumn(ret, 0)    # the columns are 0 indexed, so 0 is the first column
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/34672109)
 The simplest solution by far is to skip all the intermediate steps of reading the file of your own and converting the lines to lists of lists and just use http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html. The values will be of float type by default, so you won't have to do anything more. 

  import numpy as np

dat = np.loadtxt('test.txt')
  



