Query: JSON to pandas DataFrame
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/48614386)
 Using the json module you can parse the json into a python object, then create a dataframe from that: 

  import json
import pandas as pd
with open('C:/Users/Alberto/nutrients.json', 'r') as f:
    data = json.load(f)
df = pd.DataFrame(data)
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/35625446)
 I'm not sure about pandas read_json but IIUC you could do that with  astype(str) ,  str.split ,  str.strip : 

  d = {
    "testvalues": [
        [1424754000000, 0.7413],
        [1424840400000, 0.7375],
        [1424926800000, 0.7344],
        [1425013200000, 0.7375],
        [1425272400000, 0.7422],
        [1425358800000, 0.7427]
    ]
}

df = pd.DataFrame(d)
res = df.testvalues.astype(str).str.strip('[]').str.split(', ', expand=True)


In [112]: df
Out[112]:
                testvalues
0  [1424754000000, 0.7413]
1  [1424840400000, 0.7375]
2  [1424926800000, 0.7344]
3  [1425013200000, 0.7375]
4  [1425272400000, 0.7422]
5  [1425358800000, 0.7427]

In [113]: res
Out[113]:
               0       1
0  1424754000000  0.7413
1  1424840400000  0.7375
2  1424926800000  0.7344
3  1425013200000  0.7375
4  1425272400000  0.7422
5  1425358800000  0.7427
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/18120700)
 with pandas 0.12: 

  import pandas as pd

d = pd.read_json('JSON File')
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/35625559)
 You can use list comprehension with  DataFrame  contructor: 

  import pandas as pd

df = pd.read_json('file.json')
print df
                testvalues
0  [1424754000000, 0.7413]
1  [1424840400000, 0.7375]
2  [1424926800000, 0.7344]
3  [1425013200000, 0.7375]
4  [1425272400000, 0.7422]
5  [1425358800000, 0.7427]

print pd.DataFrame([x for x in df['testvalues']], columns=['a','b'])
               a       b
0  1424754000000  0.7413
1  1424840400000  0.7375
2  1424926800000  0.7344
3  1425013200000  0.7375
4  1425272400000  0.7422
5  1425358800000  0.7427
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/39563662)
 As of Pandas 0.19,  read_json  has native support for http://pandas-docs.github.io/pandas-docs-travis/io.html#io-jsonl: 

  pd.read_json(jsonfile, lines=True)
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/36051289)
 Pandas DataFrames have a to_json method that will do it for you:
http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_json.html 

 If you want each row in its own file you can iterate over the index (and use the index to help name them): 

  for i in df.index:
    df.loc[i].to_json("row{}.json".format(i))
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/48243632)
 To get each row of the dataframe as a https://docs.python.org/3/tutorial/datastructures.html#dictionaries, you can use https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_dict.html: 

 Code:</h3>

  df = pd.DataFrame(np.random.randn(10, 4), columns=list('ABCD'))
for jdict in df.to_dict(orient='records'):
    print(jdict)
  

 Results:</h3>

  {'A': -0.81155648424969018, 'B': 0.54051722275060621, 'C': 2.1858014972680886, 'D': -0.92089743800379931}
{'A': -0.051650790117511704, 'B': -0.79176498452586563, 'C': -0.9181773278020231, 'D': 1.1698955805545324}
{'A': -0.59790963665018559, 'B': -0.63673166723131003, 'C': 1.0493603533698836, 'D': 1.0027811601157812}
{'A': -0.20909149867564752, 'B': -1.8022674158328837, 'C': 1.0849019267782165, 'D': 1.2203116471260997}
{'A': 0.33798033123267207, 'B': 0.13927004774974402, 'C': 1.6671536830551967, 'D': 0.29193412587056755}
{'A': -0.079327003827824386, 'B': 0.58625181818942929, 'C': -0.42365912798153349, 'D': -0.69644626255641828}
{'A': 0.33849577559616656, 'B': -0.42955248285258169, 'C': 0.070860788937864225, 'D': 1.4971679265264808}
{'A': 1.3411846077264038, 'B': -0.20189961315847924, 'C': 1.6294881274421233, 'D': 1.1168181183218009}
{'A': 0.61028134135655399, 'B': 0.48445766812257018, 'C': -0.31117315672299928, 'D': -1.7986688463810827}
{'A': 0.9181074339928279, 'B': 0.84151139156427757, 'C': -1.111794854210024, 'D': -0.7131446510569609}
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/43440304)
 If you want an array of dictionaries, you can use  orient='records' : 

  >>> import pandas as pd
>>> df = pd.DataFrame({
...     'Date': ['2017-02-03', '2015-02-04'],
...     'Text': ['Sample Text 1', 'Sample Text 2']
... })
>>> df.to_json(orient='records')
'[{"Date":"2017-02-03","Text":"Sample Text 1"},{"Date":"2015-02-04","Text":"Sample Text 2"}]'
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/33113390)
 You should be able to just put the data on separate lines. 

  

  f = open('test.json', 'w')
df.to_json(f)
print >> f
json.dump(metadata, f)
  

  

  f = open('test.json')
df = pd.read_json(next(f))
metdata = json.loads(next(f))
  



