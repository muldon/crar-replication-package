Query: How to drop rows of Pandas DataFrame whose value in certain columns is NaN
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/45466263)
 You can use this: 

  df.dropna(subset=['EPS'], how='all', inplace = True)
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/52884094)
 Or (check for NaN's with  isnull , then use  ~  to make the opposite to no NaN's): 

  df=df[~df['EPS'].isnull()]
  

  

  print(df)
  

  

                   STK_ID  EPS  cash
STK_ID RPT_Date
600016 20111231  600016  4.3   NaN
601939 20111231  601939  2.5   NaN
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/34082664)
 You could use dataframe method http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.notnull.html or inverse of http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.isnull.html, or http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.isnan.html: 

  In [332]: df[df.EPS.notnull()]
Out[332]:
   STK_ID  RPT_Date  STK_ID.1  EPS  cash
2  600016  20111231    600016  4.3   NaN
4  601939  20111231    601939  2.5   NaN


In [334]: df[~df.EPS.isnull()]
Out[334]:
   STK_ID  RPT_Date  STK_ID.1  EPS  cash
2  600016  20111231    600016  4.3   NaN
4  601939  20111231    601939  2.5   NaN


In [347]: df[~np.isnan(df.EPS)]
Out[347]:
   STK_ID  RPT_Date  STK_ID.1  EPS  cash
2  600016  20111231    600016  4.3   NaN
4  601939  20111231    601939  2.5   NaN
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/43530064)
 yet another solution which uses the fact that  np.nan != np.nan : 

  In [149]: df.query("EPS == EPS")
Out[149]:
                 STK_ID  EPS  cash
STK_ID RPT_Date
600016 20111231  600016  4.3   NaN
601939 20111231  601939  2.5   NaN
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/47455251)
    

  filtered_df = df[df['EPS'].notnull()]
  

 
   The above solution is way better than using np.isfinite() 
 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/13413845)
 Don't  drop . Just take rows where  EPS  is  finite : 

  df = df[np.isfinite(df['EPS'])]
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/52806308)
 you can use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html 

  Example   

 Drop the rows where at least one element is missing. 

  df=df.dropna()
  

 Define in which columns to look for missing values. 

  df=df.dropna(subset=['column1', 'column1'])
  

 See http://pandas.pydata.org/pandas-docs/stable/missing_data.html#missing-data for more examples 

 
   Note: axis parameter of dropna is deprecated since version 0.23.0: 
 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/30923956)
 You can use a conditional list comprehension: 

  >>> dff[[c for c in dff if dff[c].isnull().sum() < 2]]
          A         B
0 -0.819004  0.919190
1  0.922164  0.088111
2  0.188150  0.847099
3       NaN -0.053563
4  1.327250 -0.376076
5  3.724980  0.292757
6 -0.319342       NaN
7 -1.051529  0.389843
8 -0.805542 -0.018347
9 -0.816261 -1.627026
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/43279089)
 To expand Hitesh's answer if you want to drop rows where 'x' specifically is nan, you can use the subset parameter. His answer will drop rows where other columns have nans as well 

  dat.dropna(subset=['x'])
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/30925185)
 There is a  thresh  param for http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna, you just need to pass the length of your df - the number of  NaN  values you want as your threshold: 

  In [13]:

dff.dropna(thresh=len(dff) - 2, axis=1)
Out[13]:
          A         B
0  0.517199 -0.806304
1 -0.643074  0.229602
2  0.656728  0.535155
3       NaN -0.162345
4 -0.309663 -0.783539
5  1.244725 -0.274514
6 -0.254232       NaN
7 -1.242430  0.228660
8 -0.311874 -0.448886
9 -0.984453 -0.755416
  

 So the above will drop any column that does not meet the criteria of the length of the df (number of rows) - 2 as the number of non-Na values. 



