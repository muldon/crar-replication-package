Query: Python: unescape special characters without splitting data
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/20878934)
 You can refer this https://stackoverflow.com/q/753052/2284418.  

 And edit  html_to_text  function for you want. 

  from HTMLParser import HTMLParser
n = " I <3s U &amp; you luvz me "

class MLStripper(HTMLParser):
    def __init__(self):
        self.reset()
        self.fed = []
    def handle_data(self, d):
        self.fed.append(d)
    def handle_entityref(self, name):
        self.fed.append('&%s;' % name)
    def get_data(self):
        return ''.join(self.fed)

def html_to_text(html):
    s = MLStripper()
    s.feed(html)
    return HTMLParser().unescape(s.get_data())

print html_to_text(n)
  

 Output: 

  I <3s U & you luvz me
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/20876107)
 Join the list of strings using http://docs.python.org/2/library/stdtypes#str.join: 

  >>> ''.join(['I ', u'<', '3s U ', u'&', ' you luvz me'])
u'I <3s U & you luvz me'
  

 Alternatively, you can use external libraries, like http://lxml.de: 

  >>> import lxml.html
>>> n = " I <3s U &amp; you luvz me "
>>> root = lxml.html.fromstring(n)
>>> root.text_content()
'I <3s U & you luvz me'
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/20878666)
 Remember that the purpose of HTMLParser is to let you build a document tree from an input. If you don't care at all about the document's structure, then the  str.join  solution @falsetru gives will be fine. You can be certain that all element tags and comments will be filtered out. 

 However, if you do need the structure for more complex scenarios then you have to build a document tree. The  handle_starttag  and  handle_endtag  methods are here for this. 

 First we need a basic tree that can hold some information. 

  class Element:
    def __init__(self, parent, tag, attrs=None):
        self.parent = parent
        self.tag = tag
        self.children = []
        self.attrs = attrs or []
        self.data = ''
  

 Now you need to make the HTMLParser make a new node on every  handle_starttag  and move up the tree on every  handle_endtag . We also pass the parsed data to the current node instead of holding it in the parser. 

  class MyHTMLParser(HTMLParser):
    def __init__(self):
        super().__init__()
        self.root = Element(NONE, '__DOCROOT__') # Special root node for us
        self.current = self.root

    def handle_starttag(self, tag, attrs):
        newel = Element(self.current tag, attrs)
        self.current.children.append(newel)
        self.current = newel

    def handle_endtag(self, tag):
        self.current = self.current.parent

    def handle_data(self, data):
        self.current.data += data

    def handle_charref(self, ref): # No changes here
        self.handle_entityref('#' + ref)

    def handle_entityref(self, ref): # No changes here either
        self.handle_data(self.unescape("&%s" % ref))
  

 Now you can access the tree on  MyHTMLParser.root  to get the data from any element as you like. For example 

  n = ' I <3s U &amp; you luvz me '
p = MyHTMLParser()
p.feed(n)
p.close()

def print_tree(node, indent=0):
    print('    ' * indent + node.tag)
    print('    ' * indent + '  ' + node.data)
    for c in node.children:
        print_tree(c, indent + 1)

print_tree(p.root)
  

 This will give you 

  __DOCROOT__

    strong
      I <3s U & you luvz me
  

 If instead you parsed  n = <html><head><title>Test</title></head><body> I <3s U &amp; you luvz me </body></html>  You would get. 

  __DOCROOT__

    html

        head

            title
              Test
        body

            h1
              I <3s U & you luvz me
  

 Next up is to make the tree building robust and handle cases like mismatched or implicit endtags. You will also want to add some nice  find('tag')  like methods on  Element  for traversing the tree. Do it well enough and you'll have made the next http://www.crummy.com/software/BeautifulSoup/. 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/13736888)
 You can use  urllib2.unquote  like this: 

  >>> import urllib2
>>> print urllib2.unquote('%B9%F3%D6%DD%C3%A9%CC%A8').decode('gbk')
贵州茅台
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/21882672)
 The edited version of Henry's answer with Python3 compatibility, tests and fix some issues: 

  def split_unescape(s, delim, escape='\\', unescape=True):
    """
    >>> split_unescape('foo,bar', ',')
    ['foo', 'bar']
    >>> split_unescape('foo$,bar', ',', '$')
    ['foo,bar']
    >>> split_unescape('foo$$,bar', ',', '$', unescape=True)
    ['foo$', 'bar']
    >>> split_unescape('foo$$,bar', ',', '$', unescape=False)
    ['foo$$', 'bar']
    >>> split_unescape('foo$', ',', '$', unescape=True)
    ['foo$']
    """
    ret = []
    current = []
    itr = iter(s)
    for ch in itr:
        if ch == escape:
            try:
                # skip the next character; it has been escaped!
                if not unescape:
                    current.append(escape)
                current.append(next(itr))
            except StopIteration:
                if unescape:
                    current.append(escape)
        elif ch == delim:
            # split! (add current to the list and reset it)
            ret.append(''.join(current))
            current = []
        else:
            current.append(ch)
    ret.append(''.join(current))
    return ret
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/22726482)
 At some point you will run into issues when you encounter special characters like Chinese characters or emoticons in a string you want to decode i.e. errors that look like this: 

  UnicodeEncodeError: 'ascii' codec can't encode characters in position 109-123: ordinal not in range(128)
  

 For my case (twitter data processing), I decoded as follows to allow me to see all characters with no errors 

  >>> s = '\u003cfoo\u003e'
>>> s.decode( 'unicode-escape' ).encode( 'utf-8' )
>>> <foo>
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/2360644)
 I am not sure if this is a built in library or not but it looks like what you need and supports 3.1. 

 From: http://docs.python.org/3.1/library/xml.sax.utils.html?highlight=html%20unescape 

 xml.sax.saxutils.unescape(data, entities={})
Unescape '&', '<', and '>' in a string of data. 


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/27403159)
 Python cannot decode ' é ' (' \xe9 ') using the ASCII codec because this character is not 7-bit ASCII. 

 Your problem (condensed): 

  import HTMLParser
parser = HTMLParser.HTMLParser()
input = 'Rudimental &amp; Emeli Sand\xe9'
output = parser.unescape(input)
  

  

  Traceback (most recent call last):
  File "problem.py", line 4, in <module>
    output = parser.unescape(input)
  File "/usr/lib/python2.7/HTMLParser.py", line 475, in unescape
    return re.sub(r"&(#?[xX]?(?:[0-9a-fA-F]+|\w{1,8}));", replaceEntities, s)
  File "/usr/lib/python2.7/re.py", line 151, in sub
    return _compile(pattern, flags).sub(repl, string, count)
UnicodeDecodeError: 'ascii' codec can't decode byte 0xe9 in position 11: ordinal not in range(128)
  

  HTMLParser.unescape()  returns a  unicode  object, and therefore has to convert your input  str . So it asks for the default encoding (which in your case is ASCII) and fails to interpret ' \xe9 ' as an ASCII character (because it isn't). I guess your file encoding is ISO-8859-1 where ' \xe9 ' is ' é '. 

 There are two easy solutions. Either you do the conversion manually: 

  import HTMLParser
parser = HTMLParser.HTMLParser()
input = 'Rudimental &amp; Emeli Sand\xe9'
input = input.decode('iso-8859-1')
output = parser.unescape(input)
  

 or you use  codecs.open()  instead of  open()  whenever you are working with files: 

  import codecs
import HTMLParser
parser = HTMLParser.HTMLParser()
input = codecs.open("import.txt", encoding="iso-8859-1").readline()
output = parser.unescape(input)
  



