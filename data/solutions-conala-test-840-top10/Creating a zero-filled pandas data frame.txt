Query: Creating a zero-filled pandas data frame
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/40431978)
 It's best to do this with numpy in my opinion 

  import numpy as np
import pandas as pd
d = pd.DataFrame(np.zeros((N_rows, N_cols)))
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/38676865)
 If you already have a dataframe, this is the fastest way: 

  In [1]: columns = ["col{}".format(i) for i in range(10)]
In [2]: orig_df = pd.DataFrame(np.ones((10, 10)), columns=columns)
In [3]: %timeit d = pd.DataFrame(np.zeros_like(orig_df), index=orig_df.index, columns=orig_df.columns)
10000 loops, best of 3: 60.2 µs per loop
  

  

  In [4]: %timeit d = pd.DataFrame(0, index = np.arange(10), columns=columns)
10000 loops, best of 3: 110 µs per loop

In [5]: temp = np.zeros((10, 10))
In [6]: %timeit d = pd.DataFrame(temp, columns=columns)
10000 loops, best of 3: 95.7 µs per loop
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/46380718)
 Similar to @Shravan, but without the use of numpy: 

    height = 10
  width = 20
  df_0 = pd.DataFrame(0, index=range(height), columns=range(width))
  

  

  post_instantiation_fcn = lambda x: str(x)
df_ready_for_whatever = df_0.applymap(post_instantiation_fcn)
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/40281810)
 Assuming having a template DataFrame, which one would like to copy with zero values filled here... 

 If you have no NaNs in your data set, multiplying by zero can be significantly faster: 

  In [19]: columns = ["col{}".format(i) for i in xrange(3000)]                                                                                       

In [20]: indices = xrange(2000)

In [21]: orig_df = pd.DataFrame(42.0, index=indices, columns=columns)

In [22]: %timeit d = pd.DataFrame(np.zeros_like(orig_df), index=orig_df.index, columns=orig_df.columns)
100 loops, best of 3: 12.6 ms per loop

In [23]: %timeit d = orig_df * 0.0
100 loops, best of 3: 7.17 ms per loop
  

 Improvement depends on DataFrame size, but never found it slower. 

  

  In [24]: %timeit d = orig_df * 0.0 + 1.0
100 loops, best of 3: 13.6 ms per loop

In [25]: %timeit d = pd.eval('orig_df * 0.0 + 1.0')
100 loops, best of 3: 8.36 ms per loop
  

  

  In [24]: %timeit d = orig_df.copy()
10 loops, best of 3: 24 ms per loop
  

    

 Assuming you have a frame using float64, this will be the fastest by a huge margin! It is also able to generate any value by replacing 0.0 to the desired fill number. 

  In [23]: %timeit d = pd.eval('orig_df > 1.7976931348623157e+308 + 0.0')
100 loops, best of 3: 3.68 ms per loop
  

 Depending on taste, one can externally define nan, and do a general solution, irrespective of the particular float type: 

  In [39]: nan = np.nan
In [40]: %timeit d = pd.eval('orig_df > nan + 0.0')
100 loops, best of 3: 4.39 ms per loop
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/42636920)
 Since you are trying to make a copy, it might be better to simply create a new data frame with values as 0, and columns and index from the original data frame: 

  pd.DataFrame(0, columns=df.columns, index=df.index)
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/50916835)
 Here is one way using  pd.DataFrame.apply  +  pd.Series.apply : 

  df = pd.DataFrame([[1, 0, 1, 2], [2, 0, 0, 3], [3, 0, 0, 0], [4, 1, 0, 0]],
                  columns=['index', 'A', 'B', 'C'])

def formatter(x):
    x = x[x > 0]
    return (x.index[1:].astype(str) + '-' + x[1:].astype(str))

df['Positives'] = df.apply(formatter, axis=1).apply(', '.join)

print(df)

   index  A  B  C  Positives
0      1  0  1  2   B-1, C-2
1      2  0  0  3        C-3
2      3  0  0  0          
3      4  1  0  0        A-1
  

 If you need to filter out zero-length strings, you can use the fact that empty strings evaluate to  False  with  bool : 

  res = df[df['Positives'].astype(bool)]

print(res)

   index  A  B  C  Positives
0      1  0  1  2   B-1, C-2
1      2  0  0  3        C-3
3      4  1  0  0        A-1
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/30589698)
 It's because your mean calculation is wrong in the filled example, (you use axis=0 instead of 1). If I use the  fill_values  from the first example it looks okay, 

  import numpy as np
import pandas as pd
df = pd.DataFrame({'A' : [np.nan, 1,2], 
                                  'B' : [3, np.nan, 4], 
                                  'C': [5,6,np.nan]}).T
mask = np.isnan(df)
masked_df = np.ma.masked_array(df, mask)
fill_value = pd.DataFrame({col: df.mean(axis=1) for col in df.columns})
df = masked_df.filled(fill_value)
print(df)
  

 outputs: 

  [[ 1.5  1.   2. ]
 [ 3.   3.5  4. ]
 [ 5.   6.   5.5]]
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/49562143)
  df=pd.DataFrame(data=mice.complete(d), columns=d.columns, index=d.index)
  

 The  np.array  that is returned by the  .complete()  method of the fancyimpute object (be it mice or KNN) is fed as the content  (argument data=)  of a pandas dataframe whose cols and indexes are the same as the original data frame. 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/43004513)
 Your  pandas.DataFrame.select_dtypes  approach is good; you've just got to cross the finish line: 

  >>> df = pd.DataFrame({'A': [np.nan, 'string', 'string', 'more string'], 'B': [np.nan, np.nan, 3, 4], 'C': [4, np.nan, 5, 6]})
>>> df
             A    B    C
0          NaN  NaN  4.0
1       string  NaN  NaN
2       string  3.0  5.0
3  more string  4.0  6.0
  

 Don't try to perform the in-place  fillna  here (there's a time and place for  inplace=True , but here is not one). You're right in that what's returned by  select_dtypes  is basically a view. Create a new dataframe called  filled  and join the filled (or "fixed") columns back with your original data:  

  >>> filled = df.select_dtypes(include=['int', 'float']).fillna(0)
>>> filled
     B    C
0  0.0  4.0
1  0.0  0.0
2  3.0  5.0
3  4.0  6.0
>>> df = df.join(filled, rsuffix='_filled')
>>> df
             A    B    C  B_filled  C_filled
0          NaN  NaN  4.0       0.0       4.0
1       string  NaN  NaN       0.0       0.0
2       string  3.0  5.0       3.0       5.0
3  more string  4.0  6.0       4.0       6.0
  

 Then you can drop whatever original columns you had to keep only the "filled" ones: 

  >>> df.drop([x[:x.find('_filled')] for x in df.columns if '_filled' in x], axis=1, inplace=True)
>>> df
             A  B_filled  C_filled
0          NaN       0.0       4.0
1       string       0.0       0.0
2       string       3.0       5.0
3  more string       4.0       6.0
  



