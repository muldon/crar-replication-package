Query: Replacing characters in a file
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/10562903)
 Works fine here. 

  >>> import codecs
>>> contents = codecs.open('foo.txt', encoding='utf-8').read()
>>> print contents
This is a message.

>>> print contents.replace('s', '3')
Thi3 i3 a me33age.
  

  Note:  If you want the second replace to work, you should do it on  newcontents : 

  newcontents = contents.replace('a','e')
newcontents = newcontents.replace('s', '3')
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/10562812)
 Replace this: 

  newcontents = contents.replace('a','e')
newcontents = contents.replace('s', '3')
  

  

  newcontents = contents.replace('a','e')
newcontents = newcontents.replace('s', '3')
  

  

  newcontents = contents.replace('a','e').replace('s', '3')
  

 Your code only appears to attempt replacing 'a' with 'e', not 'e' with 'a'.  For that, you need the following: 

  import string
newcontents = contents.translate(string.maketrans("aes", "ea3"))
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/10562862)
  >>> strs="this is a message"
>>> strs="".join(['a' if x=='e' else 'e' if x=='a' else '3' if x=='s' else x for x in strs])
>>> print(strs)
thi3 i3 e ma33ega
  

  or as Robert suggested , use a dictionary 

  >>> strs="this is a message"
>>> dic={'a':'e','e':'a','s':'3'}
>>> strs="".join((dic.get(x,x) for x in strs))
>>> print(strs)
thi3 i3 e ma33ega
  

    

  >>> strs="this is a message"
>>> dic={'a':'e','e':'a','s':'3'}
>>> new_strs=''
>>> for x in strs:
     if x in dic:
        new_strs += dic[x]
     else:
        new_strs += x
>>> print(new_strs)

thi3 i3 e ma33ega
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/16763473)
 Use the http://docs.python.org/2/library/fileinput.html, which handles files correctly when replacing data, with the  inplace  flag set: 

  import sys
import fileinput

for line in fileinput.input('my_text_file.txt', inplace=True):
    x = process_result(line)
    if x:
        line = line.replace('something', x)

    sys.stdout.write(line)
  

 When you use the  inplace  flag, the original file is moved to a backup, and anything your write to  sys.stdout  is written to the original filename (so, as a new file). Make sure you include all lines, altered or not. 

 You  have  to rewrite the complete file whenever your replacement data is not  exactly  the same number of bytes as the parts that you are replacing. 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/46627794)
 Some things that I noticed that contribute to only some of the punctuation being removed. The line  for word in file:  should actually be  for line in file: . Python iterates over files by lines and not by words. The  strip  function only removes items from the beginning and end. You would use the  replace  function to remove characters from the middle. The way the program is currently written, it will only remove punctuation from the beginning and end of each line in the document. 

 The way I would remove all punctuation is like so. 

  from pathlib import Path
import string

filepath = Path(filename)
text = filepath.read_text()
text = text.replace(string.punctuation, "")
filepath.write_text(text )
  

 But you say that the replace function messes with the ebook functionality. . I don't see how replacing punctuation within each individual word is any different then replacing it all at once for the entire file? 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/49686349)
 Here's my aestric file( aestricks.txt ), which contains: 

  ************
  

 And pattern file ( pattern.txt ), which contains: 

      -
   /-\
  /---\
 /-----\
/-------\
  

 And here's  the code .  

  file1 = open("aestricks.txt","r")

file1 = file1.read()

t_c = len(file1)

form = open("pattern.txt","r")

form = form.read()

form1 = form

count = 0

for ch in form1:
    if ch in ['-','/', '\\']:
        form = form.replace(ch, '*', 1)
        count += 1

    if count == t_c:
        break

for ch in form1:
    if ch in ['-','/', '\\']:
        form = form.replace(ch, '')

print(form)
  

  OUTPUT:  

     *
  ***
 *****
***
  


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/44997040)
  

  import os
directory = os.getcwd()
for filename in os.listdir(directory):
  if "-" in filename:
    os.rename(os.path.join(directory,filename),os.path.join(directory,filename.replace("-","-")))
  

  New solution to replace characters inside a file  

  u2212  is unicode character for minus and  u2014  for en-dash.  

  import os
directory = os.getcwd()
import fnmatch

def _changefiletext(fileName):
  with open(fileName,'r') as file:
    str = file.read()
    str = str.decode("utf-8").replace(u"\u2212",u"\u2014").encode("utf-8")
  with open(fileName,'wb') as file:
    file.write(str)

# Filter the files on which you want to run the replace code (*.txt in this case)    

matches = []
for root, dirnames, filenames in os.walk(directory):
    for filename in fnmatch.filter(filenames, '*.txt'):
        matches.append(os.path.join(root, filename))

for filename in matches:
  print "Converting file %s" %(filename)
  _changefiletext(filename)
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/17140947)
 You can do the replacement like this 

  f1 = open('file1.txt', 'r')
f2 = open('file2.txt', 'w')
for line in f1:
    f2.write(line.replace('old_text', 'new_text'))
f1.close()
f2.close()
  


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/41498450)
 The problem may not be so much about  replac ing or  strip ping extra characters as it is about what gets returned when you run  subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) . The latter actually returns  bytes , which may not play so nicely with writing each line to the file. You should be able to convert the  bytes  to  string  before writing the lines to the file with the following: 

  import subprocess
cmd = 'tasklist'
proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
file = open("Process_list.txt", "r+")
for line in proc.stdout:
        file.write(line.decode('ascii')) # to have each output in one line

file.close()
  

 If you don't want to have each output in one line, then you can strip the newline characters with  file.write(line.decode('ascii'). . 

 Moreover, you could have actually used  subprocess.getoutput  to get an output of string characters and save the outputs to your file: 

  cmd = 'tasklist'
proc = subprocess.getoutput(cmd)
file.write(proc)
file.close()
  

 I hope this proves useful. 


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/17066215)
 To read a file encoded in utf-8 that has non-ascii characters in it and that literally has  \ ,  u ,  0 ,  0 ,  e ,  9  character sequences that you also want to decode: 

  import codecs
import re

repl = lambda m: m.group().encode('ascii', 'strict').decode('unicode-escape')
with codecs.open(filename, encoding='utf-8') as file:
    text = re.sub(r'\\u[0-9a-f]{4}', repl, file.read())
  

 Note: normally, non-ascii characters and Unicode escapes ( \uxxxx ) should not be mixed in a single file. Use one or another but not both simultaneously. 

 
   The file to read/write are encoded in UTF-8 so I added the utf-8 declaration above my script  
 

 The utf-8 declaration in your Python source affects only character encoding of your Python source e.g., it allows to use non-ascii characters in bytestring and unicode literals. It  has no effect  on character encoding of the files that you read. 

 
   but in the end every bad characters (like \u00e9) are being replaced by litte square. 
 

 "litte square" might be an artifact of printing to console. Try this in a console to see whether squares are present: 

  >>> s = "\u00e9" # 6 bytes in a bytestring
>>> len(s)
6
>>> u = u"\u00e9" # unicode escape in a Unicode string
>>> len(u)
1
>>> print s
\u00e9
>>> print u
é
>>> b = "é" # non-ascii char in a bytestring
>>> len(b) # note: it is 2 bytes 
2
>>> ub = u"é"  # non-ascii char in a Unicode string
>>> len(ub)
1
>>> print b
é
>>> print ub
é
>>> se = u.encode('ascii', 'backslashreplace') # non-ascii chars are escaped
>>> len(se)
4
>>> (s.decode('unicode-escape') == u == b.decode('utf-8') == ub == 
     se.decode('unicode-escape') == unichr(0xe9))
True
  



