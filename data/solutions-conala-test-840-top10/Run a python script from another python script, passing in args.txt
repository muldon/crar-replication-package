Query: Run a python script from another python script, passing in args
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/32154453)
 You need to pass those arguments to the  parser.parse_args()  method: 

  args = parser.parse_args(argv)
  

 From the https://docs.python.org/2/library/argparse.html#argparse.ArgumentParser.parse_args: 

 
    ArgumentParser.parse_args(args=None, namespace=None)      
  
   [...] 
  
   By default, the argument strings are taken from  sys.argv  [...] 
 

 Note the  args  argument there. You may want to make the  argv  argument to your  argHandler()  function default to  None  as well; that way you don't  have  to pass in an argument and end up with the same default  None  value: 

  def argHandler(argv=None):
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/9317747)
  

  args = parser.parse_args(["-t"])
  

 is passing the command line arguments ["-t"] to the parser. You want to work with the actual command line arguments, so change the line to 

  args = parser.parse_args()
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/3781901)
 SubProcess module: 
http://docs.python.org/dev/library/subprocess.html#using-the-subprocess-module 

  import subprocess
subprocess.Popen("script2.py 1", shell=True)
  

 With this, you can also redirect stdin, stdout, and stderr. 


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/15368321)
 Simply add: 

  parser.add_argument('directory',help='directory to use',action='store')
  

 before your  args = parser.parse_args()  line.  A simple test from the commandline shows that it does the right thing (printing  args  at the end of the script): 

  $ python test.py /foo/bar/baz
Namespace(directory='/foo/bar/baz', dump=False, fake=False, verbose=False)
$ python test.py
usage: test.py [-h] [-v] [-d] [-f] directory
test.py: error: too few arguments
  


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/3781916)
 If os.system isn't powerful enough for you, there's http://docs.python.org/library/subprocess.html#module-subprocess. 


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/3781869)
 Try using http://docs.python.org/library/os.html#os.system: 

  os.system("script2.py 1")
  

  execfile  is different because it is designed to run a sequence of Python statements in the  current  execution context. That's why  sys.argv  didn't change for you. 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/47336073)
 You are not passing the arguments to your classes correctly. You want to use  multiprocessing.Process  or  threading.Thread . Specify your  target  and  args  separately from each other. The following example demonstrates running ten processes in parallel followed by ten threads in parallel: 

  #! /usr/bin/env python3
import multiprocessing
import threading


def main():
    for executor in multiprocessing.Process, threading.Thread:
        engines = []
        for _ in range(10):
            runner = executor(target=for_loop, args=(0, 10000000, 1))
            runner.start()
            engines.append(runner)
        for runner in engines:
            runner.join()


def for_loop(start, stop, step):
    accumulator = start
    while accumulator < stop:
        accumulator += step


if __name__ == '__main__':
    main()
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/26625982)
 I think the good practice may be something like this;  

  import subprocess
cmd = 'python script.py'

p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)
out, err = p.communicate() 
result = out.split('\n')
for lin in result:
    if not lin.startswith('#'):
        print(lin)
  

 according to documentation 
The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. This module intends to replace several older modules and functions: 

  os.system
os.spawn*
os.popen*
popen2.*
commands.*
  

 Use communicate() rather than .stdin.write, .stdout.read or .stderr.read to avoid deadlocks due to any of the other OS pipe buffers filling up and blocking the child process.
https://docs.python.org/2/library/subprocess.html#replacing-os-system 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/3781960)
 This is inherently the wrong thing to do. If you are running a Python script from another Python script, you should communicate through Python instead of through the OS: 

  import script1
  

 In an ideal world, you will be able to call a function inside  script1  directly: 

  for i in range(whatever):
    script1.some_function(i)
  

 If necessary, you can hack  sys.argv . There's a neat way of doing this using a context manager to ensure that you don't make any permanent changes. 

  import contextlib
@contextlib.contextmanager
def redirect_argv(num):
    sys._argv = sys.argv[:]
    sys.argv=[str(num)]
    yield
    sys.argv = sys._argv

with redirect_argv(1):
    print(sys.argv)
  

 I think this is preferable to passing all your data to the OS and back; that's just silly. 



