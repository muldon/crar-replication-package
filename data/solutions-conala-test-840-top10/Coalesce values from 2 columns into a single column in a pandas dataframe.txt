Query: Coalesce values from 2 columns into a single column in a pandas dataframe
-----------------------------------------------------------------------

Rank:1 (https://stackoverflow.com/questions/38152458)
 use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.combine_first.html: 

  In [16]: df = pd.DataFrame(np.random.randint(0, 10, size=(10, 2)), columns=list('ab'))

In [17]: df.loc[::2, 'a'] = np.nan

In [18]: df
Out[18]:
     a  b
0  NaN  0
1  5.0  5
2  NaN  8
3  2.0  8
4  NaN  3
5  9.0  4
6  NaN  7
7  2.0  0
8  NaN  6
9  2.0  5

In [19]: df['c'] = df.a.combine_first(df.b)

In [20]: df
Out[20]:
     a  b    c
0  NaN  0  0.0
1  5.0  5  5.0
2  NaN  8  8.0
3  2.0  8  2.0
4  NaN  3  3.0
5  9.0  4  9.0
6  NaN  7  7.0
7  2.0  0  2.0
8  NaN  6  6.0
9  2.0  5  2.0
  


-------------------------------------next answer-------------------------------------

Rank:2 (https://stackoverflow.com/questions/38153693)
 .. easier to remember:  

  df['c'] = np.where(df["a"].isnull(), df["b"], df["a"] )
  

 This is slighty faster:   df['c'] = np.where(df["a"].  

  %timeit df['d'] = df.a.combine_first(df.b)
1000 loops, best of 3: 472 µs per loop


%timeit  df['c'] = np.where(df["a"].isnull(), df["b"], df["a"] )
1000 loops, best of 3: 291 µs per loop
  


-------------------------------------next answer-------------------------------------

Rank:3 (https://stackoverflow.com/questions/34962518)
 For a single column better to use  map() , like this: 

  df = pd.DataFrame([{'a': 15, 'b': 15, 'c': 5}, {'a': 20, 'b': 10, 'c': 7}, {'a': 25, 'b': 30, 'c': 9}])

    a   b  c
0  15  15  5
1  20  10  7
2  25  30  9



df['a'] = df['a'].map(lambda a: a / 2.)

      a   b  c
0   7.5  15  5
1  10.0  10  7
2  12.5  30  9
  


-------------------------------------next answer-------------------------------------

Rank:4 (https://stackoverflow.com/questions/44969932)
 You could use  lreshape  to coalesce the  thing  and  qty  columns: 

  In [10]: pd.lreshape(df, {'thing':['thing_0','thing_1','thing_2',], 'qty':['qty_0','qty_1','qty_2']})
Out[10]: 
   ts  thing  qty
0   1    dog    5
1   2  house    6
2   1    cat    3
3   2    dog    4
4   1  mouse    1
5   2    cat    2
  

 Then  pivot  to create the desired DataFrame: 

  import pandas as pd

df = pd.DataFrame({'qty_0': [5, 6], 'qty_1': [3, 4], 'qty_2': [1, 2], 'thing_0': ['dog', 'house'], 'thing_1': ['cat', 'dog'], 'thing_2': ['mouse', 'cat'], 'ts': [1, 2]})

reshaped = pd.lreshape(df, {'thing':['thing_0','thing_1','thing_2',], 
                            'qty':['qty_0','qty_1','qty_2']})

result = reshaped.pivot(index='ts', columns='thing', values='qty')
print(result)
  

  

  thing  cat  dog  house  mouse
ts                           
1      3.0  5.0    0.0    1.0
2      2.0  4.0    6.0    0.0
  

 

 I think https://stackoverflow.com/a/44969883/190597 is better since it takes advantage of the regularity of the column names you wish to coalesce.  df.columns.str.split('_', expand=True)  is more general and less repetitive than  

  {'thing':['thing_0','thing_1','thing_2',], 
 'qty':['qty_0','qty_1','qty_2']}
  

  lreshape  might be helpful in situations where the column names you wish to coalesce
are irregular. 


-------------------------------------next answer-------------------------------------

Rank:5 (https://stackoverflow.com/questions/43177739)
 I think you need http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.bfill.html with selecting first column by http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html: 

  df['D'] = df.bfill(axis=1).iloc[:,0]
print (df)
     A     B   C    D
0  1.0   NaN   5  1.0
1  2.0  10.0  10  2.0
2  NaN   NaN   7  7.0
  

 same as: 

  df['D'] = df.fillna(method='bfill',axis=1).iloc[:,0]
print (df)
     A     B   C    D
0  1.0   NaN   5  1.0
1  2.0  10.0  10  2.0
2  NaN   NaN   7  7.0
  


-------------------------------------next answer-------------------------------------

Rank:6 (https://stackoverflow.com/questions/37636326)
  import pandas as pd
df = pd.DataFrame({'A': ['a', 'a', 'a', 'a', 'c', 'c', 'v'],
                   'B': ['d', 'd', 'h', 'i', 'i', 'g', 'g'],
                   'C': ['ii', 'g', 'g', 'k', 'k', 'ii', 'p'],
                   'D': ['domain', 'domain', 'domain', 'motif', 
                         'motif', 'motif', 'domain']})

melted = pd.melt(df, id_vars='A')
count = melted.groupby(['A', 'value'])['value'].count()
result = count.unstack(fill_value=0)
result['A'] = df.groupby('A')['A'].count()
print(result)
  

  

  value  d  domain  g  h  i  ii  k  motif  p  A
A                                            
a      2       3  2  1  1   1  1      1  0  4
c      0       0  1  0  1   1  1      2  0  2
v      0       1  1  0  0   0  0      0  1  1
  

 

  Explanation : 

 
  Use http://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html to coalesce all the columns (except the  A  column) into a single column: 

  In [517]: melted = pd.melt(df, id_vars='A'); melted
Out[517]: 
    A variable   value
0   a        B       d
1   a        B       d
2   a        B       h
3   a        B       i
4   c        B       i
...
   
  Then you can http://pandas.pydata.org/pandas-docs/stable/groupby.html the  A  and  value  columns: 

  In [520]: count = melted.groupby(['A', 'value'])['value'].count(); count
Out[520]: 
A  value 
a  d         2
   domain    3
   g         2
   h         1
...
   
  http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html moves the  value  index level into a column index level: 

  In [522]: count.unstack('value', fill_value=0)
Out[522]: 
value  d  domain  g  h  i  ii  k  motif  p
A                                         
a      2       3  2  1  1   1  1      1  0
c      0       0  1  0  1   1  1      2  0
v      0       1  1  0  0   0  0      0  1
   
 


-------------------------------------next answer-------------------------------------

Rank:7 (https://stackoverflow.com/questions/37233930)
 You could use  pd.lreshape : 

  import pandas as pd

df = pd.DataFrame([['1/1/15', '5/22/14', '7/12/13', 5, 6, 3]], 
                  columns=['DATE1', 'DATE2', 'DATE3', 'AMOUNT1', 'AMOUNT2', 'AMOUNT3'])

result = pd.lreshape(df, {'AMOUNT': ['AMOUNT1', 'AMOUNT2', 'AMOUNT3'],
                          'DATE': ['DATE1', 'DATE2', 'DATE3']})
print(result)
  

  

        DATE  AMOUNT
0   1/1/15       5
1  5/22/14       6
2  7/12/13       3
  

 The second argument to  pd.lreshape  is a dict of key/value pairs. Each key is
the name of a desired column, and each value is a list of columns from  df 
which you wish to coalesce into one column. 

 See the docstring,  help(pd.lreshape) , for a little more on  pd.lreshape . 

 

 Alternatively, you could use  pd.melt  to coalesce all the columns into one column, and use  str.extract  to separate the text-part from the numeric-part of the column names. Then use  pivot  to obtain the desired result: 

  result = pd.melt(df)
result[['variable', 'num']] = result['variable'].str.extract('(\D+)(\d+)', expand=True)
result = result.pivot(index='num', columns='variable', values='value')
print(result)
  

  

  variable AMOUNT     DATE
num                     
1             5   1/1/15
2             6  5/22/14
3             3  7/12/13
  


-------------------------------------next answer-------------------------------------

Rank:8 (https://stackoverflow.com/questions/37735822)
 http://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html can coalesce multiple columns into one value column (and one variable column). You could use it once to coalesce the  num1  and  num2  columns, and an second time to coalesce the  phone1  and  phone2  columns: 

  import pandas as pd
df = pd.DataFrame({'phone1':[4567890876, 4567890876, 9178889999, 3237800876],
                   'phone2':[4567890876, 4567890876, 9178889999, 2139990000],
                   'num1':[1,2,3,3],
                   'num2':[5,2,3,1]})

melted = pd.melt(df, id_vars=['phone1', 'phone2'], var_name='numvar', value_name='num')
melted = pd.melt(melted, id_vars=['numvar', 'num'], value_name='phone')
melted = melted[['num', 'phone']]
melted = melted.drop_duplicates()
print(melted)
  

  

      num       phone
0     1  4567890876
1     2  4567890876
2     3  9178889999
3     3  3237800876
4     5  4567890876
7     1  3237800876
11    3  2139990000
15    1  2139990000
  

 

  Explanation : Use  id_vars  to prevent the  phone1  and  phone2  columns from being melted. Below shows the result of melting the  num1  and  num2  columns: 

  In [166]: melted = pd.melt(df, id_vars=['phone1', 'phone2'], var_name='numvar', value_name='num'); melted
Out[166]: 
       phone1      phone2 numvar  num
0  4567890876  4567890876   num1    1
1  4567890876  4567890876   num1    2
2  9178889999  9178889999   num1    3
3  3237800876  2139990000   num1    3
4  4567890876  4567890876   num2    5
5  4567890876  4567890876   num2    2
6  9178889999  9178889999   num2    3
7  3237800876  2139990000   num2    1
  

 Then apply  pd.melt  again to combine the  phone1  and  phone2  columns into one: 

  In [168]: pd.melt(melted, id_vars=['numvar', 'num'], value_name='phone')
Out[168]: 
   numvar  num variable       phone
0    num1    1   phone1  4567890876
1    num1    2   phone1  4567890876
2    num1    3   phone1  9178889999
3    num1    3   phone1  3237800876
4    num2    5   phone1  4567890876
5    num2    2   phone1  4567890876
6    num2    3   phone1  9178889999
7    num2    1   phone1  3237800876
8    num1    1   phone2  4567890876
9    num1    2   phone2  4567890876
10   num1    3   phone2  9178889999
11   num1    3   phone2  2139990000
12   num2    5   phone2  4567890876
13   num2    2   phone2  4567890876
14   num2    3   phone2  9178889999
15   num2    1   phone2  2139990000
  

 Drop duplicates, and drop the  numvar  and  variable  columns and you get the desired result (albeit in a different order). 


-------------------------------------next answer-------------------------------------

Rank:9 (https://stackoverflow.com/questions/43180501)
 Another way is to explicitly fill column D with A,B,C in that order. 

  df['D'] = np.nan
df['D'] = df.D.fillna(df.A).fillna(df.B).fillna(df.C)
  


-------------------------------------next answer-------------------------------------

Rank:10 (https://stackoverflow.com/questions/37284548)
  Spark >= 2.4  

 You can use  concat  function (https://issues.apache.org/jira/browse/SPARK-23736): 

  from pyspark.sql.functions import col, concat 

df.select(concat(col("tokens"), col("tokens_bigrams"))).show(truncate=False)

# +---------------------------------+                                             
# |concat(tokens, tokens_bigrams)   |
# +---------------------------------+
# |[one, two, two, one two, two two]|
# |null                             |
# +---------------------------------+
  

 To keep data when one of the values is  NULL  you can  coalesce  with  array : 

  from pyspark.sql.functions import array, coalesce      

df.select(concat(
    coalesce(col("tokens"), array()),
    coalesce(col("tokens_bigrams"), array())
)).show(truncate = False)

# +--------------------------------------------------------------------+
# |concat(coalesce(tokens, array()), coalesce(tokens_bigrams, array()))|
# +--------------------------------------------------------------------+
# |[one, two, two, one two, two two]                                   |
# |[three]                                                             |
# +--------------------------------------------------------------------+
  

  Spark < 2.4  

 Unfortunately to concatenate  array  columns in general case you'll need an UDF, for example like this: 

  from itertools import chain
from pyspark.sql.functions import col, udf
from pyspark.sql.types import *


def concat(type):
    def concat_(*args):
        return list(chain.from_iterable((arg if arg else [] for arg in args)))
    return udf(concat_, ArrayType(type))
  

 which can be used as: 

  df = spark.createDataFrame(
    [(["one", "two", "two"], ["one two", "two two"]), (["three"], None)], 
    ("tokens", "tokens_bigrams")
)

concat_string_arrays = concat(StringType())
df.select(concat_string_arrays("tokens", "tokens_bigrams")).show(truncate=False)

# +---------------------------------+
# |concat_(tokens, tokens_bigrams)  |
# +---------------------------------+
# |[one, two, two, one two, two two]|
# |[three]                          |
# +---------------------------------+
  



